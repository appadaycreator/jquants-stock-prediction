#!/usr/bin/env python3
"""
ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–åŠ¹æœæ¸¬å®šãƒ†ã‚¹ãƒˆ
AdvancedMemoryOptimizerã®çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã¸ã®é©ç”¨åŠ¹æœã‚’æ¤œè¨¼
"""

import pandas as pd
import numpy as np
import time
import psutil
import gc
from typing import Dict, Any
import logging
from unified_system import UnifiedSystem

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class MemoryOptimizationTester:
    """ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–åŠ¹æœæ¸¬å®šã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.system = UnifiedSystem("MemoryOptimizationTester")
        self.results = {}

    def create_test_dataframe(self, rows: int = 100000, cols: int = 50) -> pd.DataFrame:
        """ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ä½œæˆ"""
        logger.info(f"ğŸ“Š ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ: {rows}è¡Œ x {cols}åˆ—")

        # å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ä½œæˆ
        data = {f"col_{i}": np.random.randn(rows) for i in range(cols)}

        # æ„å›³çš„ã«éåŠ¹ç‡ãªãƒ‡ãƒ¼ã‚¿å‹ã‚’ä½¿ç”¨
        df = pd.DataFrame(data)

        # ãƒ‡ãƒ¼ã‚¿å‹ã‚’éåŠ¹ç‡ã«è¨­å®š
        for col in df.columns:
            if col.startswith("col_") and int(col.split("_")[1]) % 2 == 0:
                df[col] = df[col].astype("float64")
            else:
                df[col] = df[col].astype("int64")

        logger.info(f"âœ… ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆå®Œäº†: {df.shape}")
        return df

    def measure_memory_usage(self, df: pd.DataFrame, operation: str) -> Dict[str, Any]:
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æ¸¬å®š"""
        # ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        gc.collect()

        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å–å¾—
        process = psutil.Process()
        memory_info = process.memory_info()
        memory_mb = memory_info.rss / 1024 / 1024

        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
        df_memory_mb = df.memory_usage(deep=True).sum() / 1024 / 1024

        return {
            "operation": operation,
            "total_memory_mb": memory_mb,
            "dataframe_memory_mb": df_memory_mb,
            "timestamp": time.time(),
        }

    def test_memory_optimization_effectiveness(self):
        """ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã®åŠ¹æœæ¸¬å®šãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸš€ ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–åŠ¹æœæ¸¬å®šãƒ†ã‚¹ãƒˆé–‹å§‹")

        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
        test_df = self.create_test_dataframe(rows=50000, cols=30)

        # æœ€é©åŒ–å‰ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¸¬å®š
        before_metrics = self.measure_memory_usage(test_df, "before_optimization")
        logger.info(
            f"ğŸ“Š æœ€é©åŒ–å‰ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {before_metrics['total_memory_mb']:.1f}MB"
        )
        logger.info(
            f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {before_metrics['dataframe_memory_mb']:.1f}MB"
        )

        # çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚‹ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–
        logger.info("ğŸ”§ çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚‹ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–å®Ÿè¡Œ")
        optimized_df = self.system.auto_apply_memory_optimization(test_df)

        # æœ€é©åŒ–å¾Œã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¸¬å®š
        after_metrics = self.measure_memory_usage(optimized_df, "after_optimization")
        logger.info(
            f"ğŸ“Š æœ€é©åŒ–å¾Œãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {after_metrics['total_memory_mb']:.1f}MB"
        )
        logger.info(
            f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {after_metrics['dataframe_memory_mb']:.1f}MB"
        )

        # åŠ¹æœã®è¨ˆç®—
        total_memory_saved = (
            before_metrics["total_memory_mb"] - after_metrics["total_memory_mb"]
        )
        df_memory_saved = (
            before_metrics["dataframe_memory_mb"] - after_metrics["dataframe_memory_mb"]
        )

        # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸è¨ˆç®—
        total_memory_reduction_percent = (
            total_memory_saved / before_metrics["total_memory_mb"]
        ) * 100
        df_memory_reduction_percent = (
            df_memory_saved / before_metrics["dataframe_memory_mb"]
        ) * 100

        # çµæœã®è¨˜éŒ²
        self.results["memory_optimization"] = {
            "before_total_memory_mb": before_metrics["total_memory_mb"],
            "after_total_memory_mb": after_metrics["total_memory_mb"],
            "total_memory_saved_mb": total_memory_saved,
            "total_memory_reduction_percent": total_memory_reduction_percent,
            "before_df_memory_mb": before_metrics["dataframe_memory_mb"],
            "after_df_memory_mb": after_metrics["dataframe_memory_mb"],
            "df_memory_saved_mb": df_memory_saved,
            "df_memory_reduction_percent": df_memory_reduction_percent,
        }

        # çµæœã®è¡¨ç¤º
        logger.info("ğŸ‰ ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–åŠ¹æœæ¸¬å®šçµæœ:")
        logger.info(
            f"  ğŸ’¾ ç·ãƒ¡ãƒ¢ãƒªç¯€ç´„: {total_memory_saved:.1f}MB ({total_memory_reduction_percent:.1f}%)"
        )
        logger.info(
            f"  ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¡ãƒ¢ãƒªç¯€ç´„: {df_memory_saved:.1f}MB ({df_memory_reduction_percent:.1f}%)"
        )

        return self.results["memory_optimization"]

    def test_large_dataset_processing(self):
        """å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸš€ å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‡¦ç†ãƒ†ã‚¹ãƒˆé–‹å§‹")

        # ã‚ˆã‚Šå¤§ããªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆ
        large_df = self.create_test_dataframe(rows=200000, cols=50)

        # å‡¦ç†å‰ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
        before_metrics = self.measure_memory_usage(large_df, "before_large_processing")

        # çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿å‡¦ç†æœ€é©åŒ–
        logger.info("ğŸ”§ çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚‹å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿å‡¦ç†æœ€é©åŒ–å®Ÿè¡Œ")
        optimized_df = self.system.optimize_data_processing(large_df)

        # å‡¦ç†å¾Œã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
        after_metrics = self.measure_memory_usage(
            optimized_df, "after_large_processing"
        )

        # åŠ¹æœã®è¨ˆç®—
        memory_saved = (
            before_metrics["total_memory_mb"] - after_metrics["total_memory_mb"]
        )
        memory_reduction_percent = (
            memory_saved / before_metrics["total_memory_mb"]
        ) * 100

        # çµæœã®è¨˜éŒ²
        self.results["large_dataset_processing"] = {
            "before_memory_mb": before_metrics["total_memory_mb"],
            "after_memory_mb": after_metrics["total_memory_mb"],
            "memory_saved_mb": memory_saved,
            "memory_reduction_percent": memory_reduction_percent,
            "data_rows": len(large_df),
            "data_cols": len(large_df.columns),
        }

        logger.info("ğŸ‰ å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‡¦ç†çµæœ:")
        logger.info(
            f"  ğŸ’¾ ãƒ¡ãƒ¢ãƒªç¯€ç´„: {memory_saved:.1f}MB ({memory_reduction_percent:.1f}%)"
        )
        logger.info(f"  ğŸ“Š å‡¦ç†ãƒ‡ãƒ¼ã‚¿: {len(large_df)}è¡Œ x {len(large_df.columns)}åˆ—")

        return self.results["large_dataset_processing"]

    def test_memory_limit_handling(self):
        """ãƒ¡ãƒ¢ãƒªåˆ¶é™å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸš€ ãƒ¡ãƒ¢ãƒªåˆ¶é™å‡¦ç†ãƒ†ã‚¹ãƒˆé–‹å§‹")

        # ãƒ¡ãƒ¢ãƒªåˆ¶é™ã‚’ä½ãè¨­å®šã—ã¦ãƒ†ã‚¹ãƒˆ
        if self.system.memory_optimizer:
            original_limit = self.system.memory_optimizer.memory_limit_mb
            self.system.memory_optimizer.memory_limit_mb = 100  # 100MBã«åˆ¶é™

            try:
                # å¤§ããªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å‡¦ç†
                test_df = self.create_test_dataframe(rows=100000, cols=20)

                # ãƒ¡ãƒ¢ãƒªåˆ¶é™ãƒã‚§ãƒƒã‚¯
                is_within_limit = self.system.memory_optimizer.check_memory_limit()
                logger.info(
                    f"ğŸ“Š ãƒ¡ãƒ¢ãƒªåˆ¶é™ãƒã‚§ãƒƒã‚¯: {'âœ… åˆ¶é™å†…' if is_within_limit else 'âš ï¸ åˆ¶é™è¶…é'}"
                )

                # è‡ªå‹•æœ€é©åŒ–ã®é©ç”¨
                optimized_df = self.system.auto_apply_memory_optimization(test_df)

                # æœ€é©åŒ–å¾Œã®åˆ¶é™ãƒã‚§ãƒƒã‚¯
                final_check = self.system.memory_optimizer.check_memory_limit()
                logger.info(
                    f"ğŸ“Š æœ€é©åŒ–å¾Œãƒ¡ãƒ¢ãƒªåˆ¶é™ãƒã‚§ãƒƒã‚¯: {'âœ… åˆ¶é™å†…' if final_check else 'âš ï¸ åˆ¶é™è¶…é'}"
                )

                # çµæœã®è¨˜éŒ²
                self.results["memory_limit_handling"] = {
                    "memory_limit_mb": self.system.memory_optimizer.memory_limit_mb,
                    "initial_within_limit": is_within_limit,
                    "final_within_limit": final_check,
                    "optimization_applied": not is_within_limit and final_check,
                }

            finally:
                # å…ƒã®åˆ¶é™ã«æˆ»ã™
                self.system.memory_optimizer.memory_limit_mb = original_limit

        return self.results.get("memory_limit_handling", {})

    def run_comprehensive_test(self):
        """åŒ…æ‹¬çš„ãªãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ"""
        logger.info("ğŸ¯ åŒ…æ‹¬çš„ãªãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ãƒ†ã‚¹ãƒˆé–‹å§‹")

        # 1. ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–åŠ¹æœæ¸¬å®š
        memory_optimization_result = self.test_memory_optimization_effectiveness()

        # 2. å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‡¦ç†ãƒ†ã‚¹ãƒˆ
        large_dataset_result = self.test_large_dataset_processing()

        # 3. ãƒ¡ãƒ¢ãƒªåˆ¶é™å‡¦ç†ãƒ†ã‚¹ãƒˆ
        memory_limit_result = self.test_memory_limit_handling()

        # ç·åˆçµæœã®è¡¨ç¤º
        logger.info("ğŸ‰ åŒ…æ‹¬çš„ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ãƒ†ã‚¹ãƒˆå®Œäº†")
        logger.info("=" * 60)
        logger.info("ğŸ“Š ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼:")

        if memory_optimization_result:
            logger.info(
                f"  ğŸ’¾ ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–åŠ¹æœ: {memory_optimization_result['total_memory_reduction_percent']:.1f}%å‰Šæ¸›"
            )

        if large_dataset_result:
            logger.info(
                f"  ğŸ“ˆ å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿å‡¦ç†: {large_dataset_result['memory_reduction_percent']:.1f}%å‰Šæ¸›"
            )

        if memory_limit_result:
            logger.info(
                f"  ğŸ›¡ï¸ ãƒ¡ãƒ¢ãƒªåˆ¶é™å‡¦ç†: {'âœ… æˆåŠŸ' if memory_limit_result.get('optimization_applied', False) else 'âš ï¸ è¦æ”¹å–„'}"
            )

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å–å¾—
        performance_metrics = self.system.get_performance_metrics()
        logger.info(
            f"  ğŸš€ ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹: {performance_metrics.get('memory_status', 'unknown')}"
        )

        return {
            "memory_optimization": memory_optimization_result,
            "large_dataset_processing": large_dataset_result,
            "memory_limit_handling": memory_limit_result,
            "performance_metrics": performance_metrics,
        }


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    logger.info("ğŸš€ ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–åŠ¹æœæ¸¬å®šãƒ†ã‚¹ãƒˆé–‹å§‹")

    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    tester = MemoryOptimizationTester()
    results = tester.run_comprehensive_test()

    # çµæœã®ä¿å­˜
    import json

    with open("memory_optimization_test_results.json", "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    logger.info("âœ… ãƒ†ã‚¹ãƒˆçµæœã‚’ memory_optimization_test_results.json ã«ä¿å­˜ã—ã¾ã—ãŸ")
    logger.info("ğŸ‰ ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–åŠ¹æœæ¸¬å®šãƒ†ã‚¹ãƒˆå®Œäº†")


if __name__ == "__main__":
    main()
