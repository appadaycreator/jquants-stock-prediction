"use client";

import { useState, useCallback, useEffect } from "react";
import { predictionCacheManager, PredictionCacheData, ModelComparisonCacheData } from "@/lib/prediction-cache-manager";

interface AnalysisParameters {
  symbol: string;
  days: number;
  modelType: string;
  features: string[];
  hyperparameters?: Record<string, any>;
}

interface CachedAnalysisResult {
  predictions: any[];
  modelComparison: any[];
  performance: {
    mae: number;
    rmse: number;
    r2: number;
  };
  fromCache: boolean;
  cacheKey: string;
  timestamp: string;
}

export function useCachedAnalysis() {
  const [isInitialized, setIsInitialized] = useState(false);
  const [cacheStats, setCacheStats] = useState({
    hits: 0,
    misses: 0,
    hitRate: 0,
    totalSize: 0,
    entryCount: 0,
  });

  // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
  useEffect(() => {
    const initializeCache = async () => {
      try {
        await predictionCacheManager.initialize();
        setIsInitialized(true);
        updateCacheStats();
      } catch (error) {
        console.error("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼:", error);
      }
    };

    initializeCache();
  }, []);

  const updateCacheStats = useCallback(() => {
    const stats = predictionCacheManager.getCacheStats();
    setCacheStats(stats);
  }, []);

  /**
   * ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸåˆ†æçµæœã®å–å¾—
   */
  const getCachedAnalysis = useCallback(async (
    parameters: AnalysisParameters,
  ): Promise<CachedAnalysisResult | null> => {
    if (!isInitialized) {
      console.warn("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“");
      return null;
    }

    try {
      const cacheKey = predictionCacheManager.generateCacheKey(
        "prediction",
        parameters,
        parameters.modelType,
      );

      // äºˆæ¸¬çµæœã®å–å¾—
      const predictionData = await predictionCacheManager.getCachedPrediction(cacheKey);
      if (!predictionData) {
        return null;
      }

      // ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒçµæœã®å–å¾—
      const comparisonKey = predictionCacheManager.generateCacheKey(
        "comparison",
        parameters,
      );
      const comparisonData = await predictionCacheManager.getCachedModelComparison(comparisonKey);

      updateCacheStats();

      return {
        predictions: predictionData.predictions,
        modelComparison: comparisonData?.models || [],
        performance: predictionData.performance,
        fromCache: true,
        cacheKey,
        timestamp: predictionData.timestamp,
      };

    } catch (error) {
      console.error("ã‚­ãƒ£ãƒƒã‚·ãƒ¥å–å¾—ã‚¨ãƒ©ãƒ¼:", error);
      return null;
    }
  }, [isInitialized, updateCacheStats]);

  /**
   * åˆ†æçµæœã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
   */
  const cacheAnalysisResult = useCallback(async (
    parameters: AnalysisParameters,
    result: {
      predictions: any[];
      modelComparison: any[];
      performance: { mae: number; rmse: number; r2: number };
    },
  ): Promise<void> => {
    if (!isInitialized) {
      console.warn("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“");
      return;
    }

    try {
      const predictionKey = predictionCacheManager.generateCacheKey(
        "prediction",
        parameters,
        parameters.modelType,
      );

      const comparisonKey = predictionCacheManager.generateCacheKey(
        "comparison",
        parameters,
      );

      // äºˆæ¸¬çµæœã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
      const predictionData: PredictionCacheData = {
        predictions: result.predictions,
        modelComparison: result.modelComparison,
        performance: result.performance,
        timestamp: new Date().toISOString(),
        modelName: parameters.modelType,
        parameters,
      };

      await predictionCacheManager.cachePrediction(
        predictionKey,
        predictionData,
        {
          ttl: 24 * 60 * 60 * 1000, // 24æ™‚é–“
          tags: ["analysis", parameters.symbol, parameters.modelType],
          priority: 1,
        },
      );

      // ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒçµæœã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
      const comparisonData: ModelComparisonCacheData = {
        models: result.modelComparison,
        bestModel: result.modelComparison[0]?.name || "",
        comparisonTimestamp: new Date().toISOString(),
        parameters,
      };

      await predictionCacheManager.cacheModelComparison(
        comparisonKey,
        comparisonData,
        {
          ttl: 24 * 60 * 60 * 1000, // 24æ™‚é–“
          tags: ["modelComparison", parameters.symbol],
          priority: 1,
        },
      );

      updateCacheStats();
      console.log("âœ… åˆ†æçµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ã—ã¾ã—ãŸ");

    } catch (error) {
      console.error("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ã‚¨ãƒ©ãƒ¼:", error);
    }
  }, [isInitialized, updateCacheStats]);

  /**
   * ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æ¤œç´¢
   */
  const searchCache = useCallback(async (
    tags: string[],
  ): Promise<Array<{ key: string; data: any; metadata: any }>> => {
    if (!isInitialized) {
      return [];
    }

    try {
      const results = await predictionCacheManager.searchCache("prediction", tags);
      return results;
    } catch (error) {
      console.error("ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¤œç´¢ã‚¨ãƒ©ãƒ¼:", error);
      return [];
    }
  }, [isInitialized]);

  /**
   * ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ã‚¯ãƒªã‚¢
   */
  const clearCache = useCallback(async (type?: "prediction" | "comparison"): Promise<void> => {
    if (!isInitialized) {
      return;
    }

    try {
      await predictionCacheManager.clearCache(type);
      updateCacheStats();
      console.log(`ğŸ§¹ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ: ${type || "all"}`);
    } catch (error) {
      console.error("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ã‚¨ãƒ©ãƒ¼:", error);
    }
  }, [isInitialized, updateCacheStats]);

  /**
   * ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æœ€é©åŒ–
   */
  const optimizeCache = useCallback(async (): Promise<void> => {
    if (!isInitialized) {
      return;
    }

    try {
      // å¤ã„ã‚¨ãƒ³ãƒˆãƒªã®å‰Šé™¤
      const oldEntries = await searchCache(["analysis"]);
      const oneWeekAgo = new Date();
      oneWeekAgo.setDate(oneWeekAgo.getDate() - 7);

      for (const entry of oldEntries) {
        const createdAt = new Date(entry.metadata.createdAt);
        if (createdAt < oneWeekAgo) {
          await predictionCacheManager.clearCache("prediction");
          break;
        }
      }

      updateCacheStats();
      console.log("ğŸ”§ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æœ€é©åŒ–ã—ã¾ã—ãŸ");

    } catch (error) {
      console.error("ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼:", error);
    }
  }, [isInitialized, searchCache, updateCacheStats]);

  /**
   * ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ã®è¨ˆç®—
   */
  const getCacheHitRate = useCallback((): number => {
    return cacheStats.hitRate;
  }, [cacheStats.hitRate]);

  /**
   * ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºã®å–å¾—
   */
  const getCacheSize = useCallback((): number => {
    return cacheStats.totalSize;
  }, [cacheStats.totalSize]);

  return {
    isInitialized,
    cacheStats,
    getCachedAnalysis,
    cacheAnalysisResult,
    searchCache,
    clearCache,
    optimizeCache,
    getCacheHitRate,
    getCacheSize,
    updateCacheStats,
  };
}
