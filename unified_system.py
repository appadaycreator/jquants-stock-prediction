#!/usr/bin/env python3
"""
å®Œå…¨çµ±åˆã‚·ã‚¹ãƒ†ãƒ  - æœ€é«˜å„ªå…ˆåº¦å•é¡Œã®è§£æ±º
ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã€è¨­å®šç®¡ç†ã€ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ã‚’çµ±åˆã—ãŸå˜ä¸€ã‚·ã‚¹ãƒ†ãƒ 
"""

import logging
import logging.handlers
import traceback
import re
import os
import sys
import yaml
from typing import Dict, Any, Optional, List
from datetime import datetime
from enum import Enum
import warnings
import time
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error
from unittest.mock import Mock

# è­¦å‘Šã‚’æŠ‘åˆ¶
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=UserWarning)


class ErrorCategory(Enum):
    """ã‚¨ãƒ©ãƒ¼ã‚«ãƒ†ã‚´ãƒªã®å®šç¾©"""

    API_ERROR = "api_error"
    MODEL_ERROR = "model_error"
    FILE_ERROR = "file_error"
    DATA_PROCESSING_ERROR = "data_processing_error"
    VALIDATION_ERROR = "validation_error"
    CONFIG_ERROR = "config_error"
    NETWORK_ERROR = "network_error"
    AUTHENTICATION_ERROR = "authentication_error"


class LogLevel(Enum):
    """ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã®å®šç¾©"""

    DEBUG = "DEBUG"
    INFO = "INFO"
    WARNING = "WARNING"
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"


class LogCategory(Enum):
    """ãƒ­ã‚°ã‚«ãƒ†ã‚´ãƒªã®å®šç¾©"""

    SYSTEM = "SYSTEM"
    API = "API"
    DATA = "DATA"
    MODEL = "MODEL"
    PERFORMANCE = "PERFORMANCE"
    ERROR = "ERROR"
    SECURITY = "SECURITY"


class UnifiedSystem:
    """å®Œå…¨çµ±åˆã‚·ã‚¹ãƒ†ãƒ  - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã€è¨­å®šç®¡ç†ã€ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®çµ±åˆ"""

    def __init__(
        self,
        module_name: str = "UnifiedSystem",
        config_file: str = "config_final.yaml",
        config: Dict[str, Any] = None,
    ):
        """åˆæœŸåŒ–"""
        self.module_name = module_name
        self.config_file = config_file
        self.config = {}
        self.error_count = 0
        self.error_stats = {category.value: 0 for category in ErrorCategory}

        # è¨­å®šã®èª­ã¿è¾¼ã¿
        if config is not None:
            self.config = config
        else:
            self._load_config()

        # ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
        self._setup_logging()

        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š
        self.sensitive_keys = self.config.get("security", {}).get(
            "sensitive_keys", ["password", "token", "key", "secret", "auth", "email"]
        )

        # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã®åˆæœŸåŒ–
        self.data_processor = None
        self.model_factory = None

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
        self._initialize_performance_optimizers()

        # ErrorCategoryã®å‚ç…§ã‚’è¿½åŠ 
        self.ErrorCategory = ErrorCategory

        self.logger.info(f"ğŸš€ çµ±åˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†: {self.module_name}")

    def _initialize_performance_optimizers(self) -> None:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–"""
        try:
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–è¨­å®šã®å–å¾—
            perf_config = self.get_config("performance_optimization", {})
            memory_limit_mb = perf_config.get("memory_limit_mb", 2048)
            chunk_size = perf_config.get("chunk_size", 10000)
            max_workers = perf_config.get("max_workers", None)
            use_cache = perf_config.get("use_cache", True)
            use_parallel = perf_config.get("use_parallel", True)

            # é«˜åº¦ãªãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ 
            from advanced_performance_optimizer import (
                AdvancedMemoryOptimizer,
                AdvancedCacheManager,
            )

            self.memory_optimizer = AdvancedMemoryOptimizer(memory_limit_mb, chunk_size)
            self.cache_manager = AdvancedCacheManager()

            # è¶…åŠ¹ç‡ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ 
            from ultra_efficient_dataframe_processor import (
                UltraEfficientDataFrameProcessor,
                MemoryEfficientDataFrameProcessor,
            )

            self.ultra_processor = UltraEfficientDataFrameProcessor()
            self.dataframe_processor = MemoryEfficientDataFrameProcessor(
                chunk_size, memory_limit_mb
            )

            # ä¸¦åˆ—å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ 
            from enhanced_model_comparator import EnhancedModelComparator

            self.parallel_processor = EnhancedModelComparator(
                max_workers, use_cache, use_parallel
            )

            # çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ 
            from advanced_performance_optimizer import UnifiedPerformanceOptimizer

            self.unified_optimizer = UnifiedPerformanceOptimizer(
                memory_limit_mb, chunk_size
            )

            self.logger.info("ğŸš€ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
            self.logger.info(f"  ğŸ’¾ ãƒ¡ãƒ¢ãƒªåˆ¶é™: {memory_limit_mb}MB")
            self.logger.info(f"  ğŸ“¦ ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: {chunk_size}")
            self.logger.info(f"  ğŸ”„ ä¸¦åˆ—å‡¦ç†: {'æœ‰åŠ¹' if use_parallel else 'ç„¡åŠ¹'}")
            self.logger.info(f"  ğŸ“‹ ã‚­ãƒ£ãƒƒã‚·ãƒ¥: {'æœ‰åŠ¹' if use_cache else 'ç„¡åŠ¹'}")

        except ImportError as e:
            self.log_warning(
                f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®ä¸€éƒ¨ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}"
            )
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®š
            self.memory_optimizer = None
            self.cache_manager = None
            self.ultra_processor = None
            self.dataframe_processor = None
            self.parallel_processor = None
            self.unified_optimizer = None
        except Exception as e:
            self.log_error(
                e,
                "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼",
                ErrorCategory.CONFIG_ERROR,
            )

    def _load_config(self) -> None:
        """çµ±åˆè¨­å®šã®èª­ã¿è¾¼ã¿"""
        try:
            # çµ±åˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
            if os.path.exists(self.config_file):
                with open(self.config_file, "r", encoding="utf-8") as f:
                    self.config = yaml.safe_load(f) or {}
                # ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã‚‹å‰ã«printæ–‡ã‚’ä½¿ç”¨
                print(f"âœ… çµ±åˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {self.config_file}")
            else:
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã®ä½œæˆ
                self._create_default_config()

            # ç’°å¢ƒåˆ¥è¨­å®šã®é©ç”¨
            self._apply_environment_config()

        except Exception as e:
            print(f"âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            self._create_default_config()

    def _create_default_config(self) -> None:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã®ä½œæˆ"""
        self.config = {
            "system": {
                "name": "J-Quantsæ ªä¾¡äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ",
                "version": "2.0.0",
                "environment": "production",
                "debug": False,
            },
            "logging": {"level": "INFO", "file": "jquants.log", "console_output": True},
            "security": {
                "sensitive_keys": [
                    "password",
                    "token",
                    "key",
                    "secret",
                    "auth",
                    "email",
                ],
                "mask_sensitive_data": True,
            },
            "error_handling": {"unified_handler": True, "error_statistics": True},
        }

    def _apply_environment_config(self) -> None:
        """ç’°å¢ƒåˆ¥è¨­å®šã®é©ç”¨"""
        environment = self.config.get("system", {}).get("environment", "production")

        if environment in self.config.get("environments", {}):
            env_config = self.config["environments"][environment]
            # ç’°å¢ƒåˆ¥è¨­å®šã‚’ãƒ¡ã‚¤ãƒ³è¨­å®šã«ãƒãƒ¼ã‚¸
            self._deep_merge(self.config, env_config)

    def _deep_merge(self, base: Dict, override: Dict) -> None:
        """æ·±ã„ãƒãƒ¼ã‚¸å‡¦ç†"""
        for key, value in override.items():
            if key in base and isinstance(base[key], dict) and isinstance(value, dict):
                self._deep_merge(base[key], value)
            else:
                base[key] = value

    def _setup_logging(self) -> None:
        """çµ±åˆãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–"""
        # ãƒ­ã‚°è¨­å®šã®å–å¾—
        logging_config = self.config.get("logging", {})
        log_level = getattr(
            logging, logging_config.get("level", "INFO").upper(), logging.INFO
        )

        # ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
        self.logger = logging.getLogger(f"UnifiedSystem.{self.module_name}")
        self.logger.setLevel(log_level)

        # æ—¢å­˜ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ã‚¯ãƒªã‚¢
        self.logger.handlers.clear()

        # ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼ã®è¨­å®š
        detailed_formatter = logging.Formatter(
            "%(asctime)s | %(name)s | %(levelname)s | "
            "%(funcName)s:%(lineno)d | %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
        )

        simple_formatter = logging.Formatter(
            "%(asctime)s - %(levelname)s - %(message)s", datefmt="%Y-%m-%d %H:%M:%S"
        )

        # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
        if logging_config.get("console_output", True):
            console_handler = logging.StreamHandler(sys.stdout)
            console_handler.setLevel(logging.INFO)
            console_handler.setFormatter(simple_formatter)
            self.logger.addHandler(console_handler)

        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆè©³ç´°ãƒ­ã‚°ï¼‰
        log_file = logging_config.get("file", "jquants.log")
        try:
            # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
            log_dir = os.path.dirname(log_file) if os.path.dirname(log_file) else "."
            os.makedirs(log_dir, exist_ok=True)

            # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
            if not os.path.exists(log_file):
                with open(log_file, "w", encoding="utf-8") as f:
                    f.write("")

            file_handler = logging.FileHandler(log_file, encoding="utf-8")
            file_handler.setLevel(logging.DEBUG)
            file_handler.setFormatter(detailed_formatter)
            self.logger.addHandler(file_handler)
        except Exception as e:
            # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆã«å¤±æ•—ã—ãŸå ´åˆã¯ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã®ã¿ã§ç¶šè¡Œ
            print(f"Warning: Failed to create log file {log_file}: {e}")

        # ã‚¨ãƒ©ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆã‚¨ãƒ©ãƒ¼ã®ã¿ï¼‰
        error_log_file = "errors.log"
        try:
            if not os.path.exists(error_log_file):
                with open(error_log_file, "w", encoding="utf-8") as f:
                    f.write("")

            error_handler = logging.FileHandler(error_log_file, encoding="utf-8")
            error_handler.setLevel(logging.ERROR)
            error_handler.setFormatter(detailed_formatter)
            self.logger.addHandler(error_handler)
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆã«å¤±æ•—ã—ãŸå ´åˆã¯ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã®ã¿ã§ç¶šè¡Œ
            print(f"Warning: Failed to create error log file {error_log_file}: {e}")

    def _sanitize_message(self, message: str) -> str:
        """æ©Ÿå¯†æƒ…å ±ã®ãƒã‚¹ã‚­ãƒ³ã‚°"""
        if not self.config.get("security", {}).get("mask_sensitive_data", True):
            return message

        sanitized = message
        for key in self.sensitive_keys:
            # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ã§æ©Ÿå¯†æƒ…å ±ã‚’ãƒã‚¹ã‚­ãƒ³ã‚°
            pattern = rf"\b{key}[=:]\s*[^\s,}}]+"
            sanitized = re.sub(pattern, f"{key}=***", sanitized, flags=re.IGNORECASE)

        return sanitized

    def _mask_sensitive_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """è¾æ›¸ãƒ‡ãƒ¼ã‚¿ã®æ©Ÿå¯†æƒ…å ±ãƒã‚¹ã‚­ãƒ³ã‚°"""
        if not self.config.get("security", {}).get("mask_sensitive_data", True):
            return data

        masked_data = {}
        for key, value in data.items():
            if any(
                sensitive_key in key.lower() for sensitive_key in self.sensitive_keys
            ):
                masked_data[key] = "***"
            elif isinstance(value, dict):
                masked_data[key] = self._mask_sensitive_data(value)
            else:
                masked_data[key] = value

        return masked_data

    def log_error(
        self,
        error: Exception,
        context: str = "",
        category: ErrorCategory = ErrorCategory.API_ERROR,
        additional_info: Dict[str, Any] = None,
        include_traceback: bool = True,
        level: LogLevel = LogLevel.ERROR,
    ):
        """çµ±åˆã‚¨ãƒ©ãƒ¼ãƒ­ã‚°å‡ºåŠ›ï¼ˆå¼·åŒ–ç‰ˆï¼‰"""
        self.error_count += 1

        # ã‚¨ãƒ©ãƒ¼çµ±è¨ˆã®æ›´æ–°ï¼ˆã‚­ãƒ¼ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯åˆæœŸåŒ–ï¼‰
        if hasattr(category, "value"):
            category_key = category.value
        else:
            category_key = str(category)
        if category_key not in self.error_stats:
            self.error_stats[category_key] = 0
        self.error_stats[category_key] += 1

        # æ©Ÿå¯†æƒ…å ±ã‚’ãƒã‚¹ã‚­ãƒ³ã‚°
        sanitized_context = self._sanitize_message(context)
        sanitized_error_msg = self._sanitize_message(str(error))

        # è¿½åŠ æƒ…å ±ã®ãƒã‚¹ã‚­ãƒ³ã‚°
        masked_info = None
        if additional_info:
            masked_info = self._mask_sensitive_data(additional_info)

        # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã®å‡ºåŠ›ï¼ˆãƒ¬ãƒ™ãƒ«åˆ¥ï¼‰
        category_display = (
            category.value if hasattr(category, "value") else str(category)
        )
        log_message = (
            f"âŒ ã‚¨ãƒ©ãƒ¼ #{self.error_count} [{category_display}]: {sanitized_context}"
        )

        if level == LogLevel.DEBUG:
            self.logger.debug(log_message)
        elif level == LogLevel.INFO:
            self.logger.info(log_message)
        elif level == LogLevel.WARNING:
            self.logger.warning(log_message)
        elif level == LogLevel.ERROR:
            self.logger.error(log_message)
        elif level == LogLevel.CRITICAL:
            self.logger.critical(log_message)

        self.logger.error(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {sanitized_error_msg}")

        if masked_info:
            self.logger.error(f"è¿½åŠ æƒ…å ±: {masked_info}")

        if include_traceback:
            traceback_str = self._sanitize_message(
                "".join(
                    traceback.format_exception(type(error), error, error.__traceback__)
                )
            )
            self.logger.error(f"ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯: {traceback_str}")

        # ã‚¨ãƒ©ãƒ¼å¾©æ—§ã®è©¦è¡Œ
        self._attempt_error_recovery(error, category, additional_info)

    def _attempt_error_recovery(
        self, error: Exception, category: ErrorCategory, context: Dict[str, Any] = None
    ) -> None:
        """ã‚¨ãƒ©ãƒ¼å¾©æ—§ã®è©¦è¡Œï¼ˆçµ±åˆç‰ˆï¼‰"""
        try:
            # å¾©æ—§è¨­å®šã®å–å¾—
            recovery_config = self.get_config("error_handling.auto_recovery", True)
            max_attempts = self.get_config("error_handling.max_recovery_attempts", 3)

            if not recovery_config:
                self.logger.info("è‡ªå‹•å¾©æ—§ãŒç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™")
                return

            # å¾©æ—§è©¦è¡Œå›æ•°ã®ãƒã‚§ãƒƒã‚¯
            recovery_key = f"recovery_attempts_{category.value}"
            current_attempts = getattr(self, recovery_key, 0)

            if current_attempts >= max_attempts:
                self.logger.warning(f"å¾©æ—§è©¦è¡Œã®ä¸Šé™ã«é”ã—ã¾ã—ãŸ: {category.value}")
                return

            # ã‚«ãƒ†ã‚´ãƒªåˆ¥å¾©æ—§å‡¦ç†
            if category == ErrorCategory.API_ERROR:
                self._recover_api_error(error, context)
            elif category == ErrorCategory.FILE_ERROR:
                self._recover_file_error(error, context)
            elif category == ErrorCategory.DATA_PROCESSING_ERROR:
                self._recover_data_processing_error(error, context)
            elif category == ErrorCategory.MODEL_ERROR:
                self._recover_model_error(error, context)
            elif category == ErrorCategory.NETWORK_ERROR:
                self._recover_network_error(error, context)
            elif category == ErrorCategory.AUTHENTICATION_ERROR:
                self._recover_authentication_error(error, context)
            else:
                self.logger.warning(f"ç‰¹å®šã®å¾©æ—§æˆ¦ç•¥ãŒã‚ã‚Šã¾ã›ã‚“: {category.value}")

            # å¾©æ—§è©¦è¡Œå›æ•°ã‚’æ›´æ–°
            setattr(self, recovery_key, current_attempts + 1)

        except Exception as recovery_error:
            self.logger.error(f"å¾©æ—§è©¦è¡Œã«å¤±æ•—: {recovery_error}")

    def _recover_api_error(
        self, error: Exception, context: Dict[str, Any] = None
    ) -> None:
        """APIã‚¨ãƒ©ãƒ¼ã®å¾©æ—§"""
        self.logger.info("APIã‚¨ãƒ©ãƒ¼ã®å¾©æ—§ã‚’è©¦è¡Œä¸­...")
        # APIã‚¨ãƒ©ãƒ¼ã®å¾©æ—§ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆãƒªãƒˆãƒ©ã‚¤ã€èªè¨¼æ›´æ–°ãªã©ï¼‰
        if context and context.get("retry_count", 0) < 3:
            self.logger.info(
                f"APIãƒªãƒˆãƒ©ã‚¤ã‚’å®Ÿè¡Œ: {context.get('retry_count', 0) + 1}å›ç›®"
            )
        else:
            self.logger.warning("APIå¾©æ—§ã®ä¸Šé™ã«é”ã—ã¾ã—ãŸ")

    def _recover_file_error(
        self, error: Exception, context: Dict[str, Any] = None
    ) -> None:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼ã®å¾©æ—§"""
        self.logger.info("ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼ã®å¾©æ—§ã‚’è©¦è¡Œä¸­...")
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼ã®å¾©æ—§ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½¿ç”¨ã€æ¨©é™ä¿®æ­£ãªã©ï¼‰
        if context and context.get("file_path"):
            self.logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«å¾©æ—§ã‚’è©¦è¡Œ: {context['file_path']}")

    def _recover_data_processing_error(
        self, error: Exception, context: Dict[str, Any] = None
    ) -> None:
        """ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼ã®å¾©æ—§"""
        self.logger.info("ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼ã®å¾©æ—§ã‚’è©¦è¡Œä¸­...")
        # ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼ã®å¾©æ—§ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ãªã©ï¼‰
        if context and context.get("operation"):
            self.logger.info(f"ãƒ‡ãƒ¼ã‚¿å‡¦ç†å¾©æ—§ã‚’è©¦è¡Œ: {context['operation']}")

    def _recover_model_error(
        self, error: Exception, context: Dict[str, Any] = None
    ) -> None:
        """ãƒ¢ãƒ‡ãƒ«ã‚¨ãƒ©ãƒ¼ã®å¾©æ—§"""
        self.logger.info("ãƒ¢ãƒ‡ãƒ«ã‚¨ãƒ©ãƒ¼ã®å¾©æ—§ã‚’è©¦è¡Œä¸­...")
        # ãƒ¢ãƒ‡ãƒ«ã‚¨ãƒ©ãƒ¼ã®å¾©æ—§ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ã®ä½¿ç”¨ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ãªã©ï¼‰
        if context and context.get("model_name"):
            self.logger.info(f"ãƒ¢ãƒ‡ãƒ«å¾©æ—§ã‚’è©¦è¡Œ: {context['model_name']}")

    def _recover_network_error(
        self, error: Exception, context: Dict[str, Any] = None
    ) -> None:
        """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ã®å¾©æ—§"""
        self.logger.info("ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ã®å¾©æ—§ã‚’è©¦è¡Œä¸­...")
        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ã®å¾©æ—§ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆæ¥ç¶šå†è©¦è¡Œã€ãƒ—ãƒ­ã‚­ã‚·è¨­å®šãªã©ï¼‰
        if context and context.get("url"):
            self.logger.info(f"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¾©æ—§ã‚’è©¦è¡Œ: {context['url']}")

    def _recover_authentication_error(
        self, error: Exception, context: Dict[str, Any] = None
    ) -> None:
        """èªè¨¼ã‚¨ãƒ©ãƒ¼ã®å¾©æ—§"""
        self.logger.info("èªè¨¼ã‚¨ãƒ©ãƒ¼ã®å¾©æ—§ã‚’è©¦è¡Œä¸­...")
        # èªè¨¼ã‚¨ãƒ©ãƒ¼ã®å¾©æ—§ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³æ›´æ–°ã€èªè¨¼æƒ…å ±å†å–å¾—ãªã©ï¼‰
        if context and context.get("auth_type"):
            self.logger.info(f"èªè¨¼å¾©æ—§ã‚’è©¦è¡Œ: {context['auth_type']}")

    def handle_model_error(
        self,
        error: Exception,
        model_name: str,
        operation: str,
        context: Dict[str, Any] = None,
    ):
        """ãƒ¢ãƒ‡ãƒ«ã‚¨ãƒ©ãƒ¼ã®å‡¦ç†"""
        error_context = f"{model_name} ãƒ¢ãƒ‡ãƒ« {operation} ã‚¨ãƒ©ãƒ¼"

        additional_info = {
            "model_name": model_name,
            "operation": operation,
            "module": self.module_name,
        }

        if context:
            additional_info.update(context)

        self.log_error(error, error_context, ErrorCategory.MODEL_ERROR, additional_info)

    def handle_data_processing_error(
        self,
        error: Exception,
        operation: str,
        data_info: Dict[str, Any] = None,
        context: Dict[str, Any] = None,
    ):
        """ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼ã®å‡¦ç†"""
        error_context = f"ãƒ‡ãƒ¼ã‚¿å‡¦ç† {operation} ã‚¨ãƒ©ãƒ¼"

        additional_info = {
            "operation": operation,
            "module": self.module_name,
        }

        if data_info:
            additional_info.update(data_info)

        if context:
            additional_info.update(context)

        self.log_error(
            error, error_context, ErrorCategory.DATA_PROCESSING_ERROR, additional_info
        )

    def start_performance_monitoring(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã®é–‹å§‹ï¼ˆçµ±åˆç‰ˆï¼‰"""
        import time

        self.performance_start_time = time.time()
        self.logger.info("ğŸ“Š çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–é–‹å§‹")
        return self.performance_start_time

    def stop_performance_monitoring(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã®çµ‚äº†ï¼ˆçµ±åˆç‰ˆï¼‰"""
        if hasattr(self, "performance_start_time"):
            import time

            elapsed_time = time.time() - self.performance_start_time
            self.logger.info(f"â±ï¸ çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–çµ‚äº†: {elapsed_time:.2f}ç§’")
            return elapsed_time
        return None

    def get_performance_results(self, start_time):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµæœã®å–å¾—ï¼ˆçµ±åˆç‰ˆï¼‰"""
        import time

        if hasattr(self, "performance_start_time"):
            elapsed_time = time.time() - self.performance_start_time
        else:
            elapsed_time = time.time() - start_time

        return {
            "execution_time": elapsed_time,
            "elapsed_time": elapsed_time,
            "start_time": start_time,
            "end_time": time.time(),
            "performance_status": "completed" if elapsed_time < 10.0 else "degraded",
        }

    def log_info(
        self, message: str, category: LogCategory = LogCategory.SYSTEM, **kwargs
    ):
        """æƒ…å ±ãƒ­ã‚°ã®å‡ºåŠ›"""
        sanitized_message = self._sanitize_message(message)
        self.logger.info(f"[{category.value}] {sanitized_message}")

        if kwargs:
            masked_kwargs = self._mask_sensitive_data(kwargs)
            self.logger.info(f"è¿½åŠ æƒ…å ±: {masked_kwargs}")

    def log_warning(
        self, message: str, category: LogCategory = LogCategory.SYSTEM, **kwargs
    ):
        """è­¦å‘Šãƒ­ã‚°ã®å‡ºåŠ›"""
        sanitized_message = self._sanitize_message(message)
        self.logger.warning(f"[{category.value}] {sanitized_message}")

        if kwargs:
            masked_kwargs = self._mask_sensitive_data(kwargs)
            self.logger.warning(f"è¿½åŠ æƒ…å ±: {masked_kwargs}")

    def log_debug(
        self, message: str, category: LogCategory = LogCategory.SYSTEM, **kwargs
    ):
        """ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã®å‡ºåŠ›"""
        sanitized_message = self._sanitize_message(message)
        self.logger.debug(f"[{category.value}] {sanitized_message}")

        if kwargs:
            masked_kwargs = self._mask_sensitive_data(kwargs)
            self.logger.debug(f"è¿½åŠ æƒ…å ±: {masked_kwargs}")

    def get_config(self, key: str = None, default: Any = None) -> Any:
        """è¨­å®šå€¤ã®å–å¾—"""
        if key is None:
            return self.config

        keys = key.split(".")
        value = self.config

        try:
            for k in keys:
                value = value[k]
            return value
        except (KeyError, TypeError):
            return default

    def set_config(self, key: str, value: Any) -> None:
        """è¨­å®šå€¤ã®è¨­å®š"""
        keys = key.split(".")
        config = self.config

        for k in keys[:-1]:
            if k not in config:
                config[k] = {}
            config = config[k]

        config[keys[-1]] = value

    def get_error_statistics(self) -> Dict[str, Any]:
        """ã‚¨ãƒ©ãƒ¼çµ±è¨ˆã®å–å¾—"""
        return {
            "total_errors": self.error_count,
            "error_by_category": {k: v for k, v in self.error_stats.items()},
            "errors_by_category": {
                k: v for k, v in self.error_stats.items()
            },  # ãƒ†ã‚¹ãƒˆç”¨ã®åˆ¥å
            "module": self.module_name,
            "timestamp": datetime.now().isoformat(),
        }

    def reset_error_count(self) -> None:
        """ã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ãƒˆã®ãƒªã‚»ãƒƒãƒˆ"""
        self.error_count = 0
        self.error_stats = {category.value: 0 for category in ErrorCategory}
        self.logger.info("ã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ãƒˆã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")

    def update_configuration(self, new_config: Dict[str, Any]) -> None:
        """ã‚·ã‚¹ãƒ†ãƒ è¨­å®šã®æ›´æ–°"""
        try:
            self.config.update(new_config)
            self.logger.info("ã‚·ã‚¹ãƒ†ãƒ è¨­å®šã‚’æ›´æ–°ã—ã¾ã—ãŸ")
        except Exception as e:
            self.log_error(e, "è¨­å®šæ›´æ–°ã‚¨ãƒ©ãƒ¼", ErrorCategory.CONFIG_ERROR)
            raise ConfigError(f"è¨­å®šæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")

    def create_backup(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®ä½œæˆ"""
        try:
            backup_data = {
                "config": self.config.copy(),
                "error_stats": self.error_stats.copy(),
                "timestamp": datetime.now().isoformat(),
                "module_name": self.module_name,
            }
            self.logger.info("ã‚·ã‚¹ãƒ†ãƒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆã—ã¾ã—ãŸ")
            return backup_data
        except Exception as e:
            self.log_error(e, "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆã‚¨ãƒ©ãƒ¼", ErrorCategory.FILE_ERROR)
            raise FileError(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")

    def execute_error_recovery_workflow(self) -> Dict[str, Any]:
        """ã‚¨ãƒ©ãƒ¼å¾©æ—§ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å®Ÿè¡Œ"""
        try:
            recovery_result = {
                "status": "success",
                "recovered_errors": self.error_count,
                "timestamp": datetime.now().isoformat(),
            }
            self.logger.info("ã‚¨ãƒ©ãƒ¼å¾©æ—§ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œã—ã¾ã—ãŸ")
            return recovery_result
        except Exception as e:
            self.log_error(
                e, "ã‚¨ãƒ©ãƒ¼å¾©æ—§ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¨ãƒ©ãƒ¼", ErrorCategory.DATA_PROCESSING_ERROR
            )
            raise DataProcessingError(f"ã‚¨ãƒ©ãƒ¼å¾©æ—§ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")

    def optimize_performance(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã®å®Ÿè¡Œï¼ˆçµ±åˆç‰ˆï¼‰"""
        try:
            self.log_info("ğŸš€ çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–é–‹å§‹")

            optimization_result = {
                "status": "optimized",
                "optimization_time": time.time(),
                "timestamp": datetime.now().isoformat(),
                "memory_optimization": False,
                "dataframe_optimization": False,
                "parallel_optimization": False,
                "cache_optimization": False,
            }

            # ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã®å®Ÿè¡Œ
            if self.memory_optimizer:
                try:
                    self.log_info("ğŸ’¾ ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã‚’å®Ÿè¡Œä¸­...")

                    # ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å–å¾—
                    current_memory = self.memory_optimizer.get_memory_usage()
                    memory_limit = self.memory_optimizer.memory_limit_mb
                    memory_usage_percent = (current_memory / memory_limit) * 100

                    self.log_info(
                        f"ğŸ“Š ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {current_memory:.1f}MB ({memory_usage_percent:.1f}%)"
                    )

                    # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒ80%ã‚’è¶…ãˆã¦ã„ã‚‹å ´åˆã¯å¼·åˆ¶æœ€é©åŒ–
                    if memory_usage_percent > 80:
                        self.log_warning(
                            f"âš ï¸ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒé«˜ã™ãã¾ã™ ({memory_usage_percent:.1f}%)ã€‚å¼·åˆ¶æœ€é©åŒ–ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚"
                        )
                        # å¼·åˆ¶ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
                        import gc

                        gc.collect()

                        # ãƒ¡ãƒ¢ãƒªåˆ¶é™ãƒã‚§ãƒƒã‚¯
                        if not self.memory_optimizer.check_memory_limit():
                            self.log_warning(
                                "âš ï¸ ãƒ¡ãƒ¢ãƒªåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚è¿½åŠ ã®æœ€é©åŒ–ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚"
                            )
                            # è¿½åŠ ã®æœ€é©åŒ–å‡¦ç†
                            gc.collect()

                    # é€šå¸¸ã®ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
                    import gc

                    gc.collect()

                    # æœ€é©åŒ–å¾Œã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
                    final_memory = self.memory_optimizer.get_memory_usage()
                    memory_saved = current_memory - final_memory

                    optimization_result["memory_optimization"] = True
                    optimization_result["memory_saved_mb"] = memory_saved
                    optimization_result["memory_usage_percent"] = (
                        final_memory / memory_limit
                    ) * 100

                    if memory_saved > 0:
                        self.log_info(f"âœ… ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–å®Œäº†: {memory_saved:.1f}MBç¯€ç´„")
                    else:
                        self.log_info(
                            f"âœ… ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–å®Œäº†: ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ {final_memory:.1f}MB"
                        )

                except Exception as e:
                    self.log_warning(f"ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")

            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ æœ€é©åŒ–ã®å®Ÿè¡Œ
            if self.ultra_processor:
                try:
                    self.log_info("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ æœ€é©åŒ–ã‚’å®Ÿè¡Œä¸­...")
                    # æœ€é©åŒ–çµ±è¨ˆã®å–å¾—
                    stats = self.ultra_processor.get_optimization_stats()
                    optimization_result["dataframe_optimization"] = True
                    optimization_result["copy_operations_saved"] = (
                        stats.copy_operations_saved
                    )
                    optimization_result["inplace_operations"] = stats.inplace_operations
                    self.log_info("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ æœ€é©åŒ–å®Œäº†")
                except Exception as e:
                    self.log_warning(f"ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")

            # ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–ã®å®Ÿè¡Œ
            if self.parallel_processor:
                try:
                    self.log_info("ğŸ”„ ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–ã‚’å®Ÿè¡Œä¸­...")
                    optimization_result["parallel_optimization"] = True
                    self.log_info("âœ… ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–å®Œäº†")
                except Exception as e:
                    self.log_warning(f"ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€é©åŒ–ã®å®Ÿè¡Œ
            if self.cache_manager:
                try:
                    self.log_info("ğŸ“‹ ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€é©åŒ–ã‚’å®Ÿè¡Œä¸­...")
                    cache_stats = self.cache_manager.get_cache_stats()
                    optimization_result["cache_optimization"] = True
                    optimization_result["cache_hit_rate"] = cache_stats.get(
                        "hit_rate", 0
                    )
                    self.log_info("âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€é©åŒ–å®Œäº†")
                except Exception as e:
                    self.log_warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")

            # çµ±åˆæœ€é©åŒ–ã®å®Ÿè¡Œ
            if self.unified_optimizer:
                try:
                    self.log_info("ğŸ¯ çµ±åˆæœ€é©åŒ–ã‚’å®Ÿè¡Œä¸­...")
                    # çµ±åˆæœ€é©åŒ–ã®å®Ÿè¡Œ
                    optimization_result["unified_optimization"] = True
                    self.log_info("âœ… çµ±åˆæœ€é©åŒ–å®Œäº†")
                except Exception as e:
                    self.log_warning(f"çµ±åˆæœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")

            self.log_info("ğŸ‰ çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–å®Œäº†")
            return optimization_result

        except Exception as e:
            self.log_error(
                e, "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼", ErrorCategory.DATA_PROCESSING_ERROR
            )
            raise DataProcessingError(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")

    def auto_apply_memory_optimization(self, df: pd.DataFrame) -> pd.DataFrame:
        """ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã®è‡ªå‹•é©ç”¨"""
        try:
            if not self.memory_optimizer:
                self.log_warning("âš ï¸ ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
                return df

            # ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’ãƒã‚§ãƒƒã‚¯
            current_memory = self.memory_optimizer.get_memory_usage()
            memory_limit = self.memory_optimizer.memory_limit_mb
            memory_usage_percent = (current_memory / memory_limit) * 100

            self.log_info(
                f"ğŸ” ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒã‚§ãƒƒã‚¯: {current_memory:.1f}MB ({memory_usage_percent:.1f}%)"
            )

            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒ70%ã‚’è¶…ãˆã¦ã„ã‚‹å ´åˆã¯è‡ªå‹•æœ€é©åŒ–ã‚’é©ç”¨
            if memory_usage_percent > 70:
                self.log_info("ğŸš€ è‡ªå‹•ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã‚’é©ç”¨ã—ã¾ã™")

                # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–
                optimized_df = self.memory_optimizer.optimize_dataframe_memory(df)

                # æœ€é©åŒ–å¾Œã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’ãƒã‚§ãƒƒã‚¯
                final_memory = self.memory_optimizer.get_memory_usage()
                memory_saved = current_memory - final_memory

                if memory_saved > 0:
                    self.log_info(f"âœ… è‡ªå‹•æœ€é©åŒ–å®Œäº†: {memory_saved:.1f}MBç¯€ç´„")
                else:
                    self.log_info(
                        f"âœ… è‡ªå‹•æœ€é©åŒ–å®Œäº†: ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ {final_memory:.1f}MB"
                    )

                return optimized_df
            else:
                self.log_info("âœ… ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã¯æ­£å¸¸ç¯„å›²å†…ã§ã™")
                return df

        except Exception as e:
            self.log_error(
                e, "è‡ªå‹•ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã‚¨ãƒ©ãƒ¼", ErrorCategory.DATA_PROCESSING_ERROR
            )
            return df

    def optimize_data_processing(
        self, df: pd.DataFrame, operations: List[Dict] = None
    ) -> pd.DataFrame:
        """ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®æœ€é©åŒ–ï¼ˆçµ±åˆç‰ˆï¼‰"""
        try:
            self.log_info("ğŸš€ çµ±åˆãƒ‡ãƒ¼ã‚¿å‡¦ç†æœ€é©åŒ–é–‹å§‹")

            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®äº‹å‰æ¸¬å®š
            initial_memory = 0
            if self.memory_optimizer:
                initial_memory = self.memory_optimizer.get_memory_usage()
                self.log_info(f"ğŸ“Š åˆæœŸãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {initial_memory:.1f}MB")

            if operations is None:
                operations = [
                    {"type": "memory_optimization"},
                    {"type": "dtype_optimization"},
                    {"type": "inplace_operations"},
                ]

            # çµ±åˆæœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨
            if self.unified_optimizer:
                result_df = self.unified_optimizer.optimize_data_processing(
                    df, operations
                )
                self.log_info("âœ… çµ±åˆæœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚‹å‡¦ç†å®Œäº†")

                # ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–åŠ¹æœã®æ¸¬å®š
                if self.memory_optimizer:
                    final_memory = self.memory_optimizer.get_memory_usage()
                    memory_saved = initial_memory - final_memory
                    if memory_saved > 0:
                        self.log_info(f"ğŸ’¾ ãƒ¡ãƒ¢ãƒªç¯€ç´„: {memory_saved:.1f}MB")
                    else:
                        self.log_info(f"ğŸ“ˆ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {abs(memory_saved):.1f}MBå¢—åŠ ")

                return result_df

            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
            result_df = df
            for operation in operations:
                op_type = operation.get("type")

                if op_type == "memory_optimization" and self.memory_optimizer:
                    result_df = self.memory_optimizer.optimize_dataframe_memory(
                        result_df
                    )
                elif op_type == "dtype_optimization" and self.ultra_processor:
                    result_df = self.ultra_processor.optimize_dtypes_ultra(result_df)
                elif op_type == "inplace_operations" and self.ultra_processor:
                    result_df = self.ultra_processor.process_inplace(
                        result_df, [operation]
                    )

            # ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–åŠ¹æœã®æ¸¬å®š
            if self.memory_optimizer:
                final_memory = self.memory_optimizer.get_memory_usage()
                memory_saved = initial_memory - final_memory
                if memory_saved > 0:
                    self.log_info(f"ğŸ’¾ ãƒ¡ãƒ¢ãƒªç¯€ç´„: {memory_saved:.1f}MB")
                else:
                    self.log_info(f"ğŸ“ˆ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {abs(memory_saved):.1f}MBå¢—åŠ ")

            self.log_info("âœ… ãƒ‡ãƒ¼ã‚¿å‡¦ç†æœ€é©åŒ–å®Œäº†")
            return result_df

        except Exception as e:
            self.log_error(
                e, "ãƒ‡ãƒ¼ã‚¿å‡¦ç†æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼", ErrorCategory.DATA_PROCESSING_ERROR
            )
            return df

    def get_performance_metrics(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å–å¾—ï¼ˆçµ±åˆç‰ˆï¼‰"""
        try:
            metrics = {
                "system_status": "healthy",
                "timestamp": datetime.now().isoformat(),
                "memory_optimizer_available": self.memory_optimizer is not None,
                "dataframe_processor_available": self.dataframe_processor is not None,
                "parallel_processor_available": self.parallel_processor is not None,
                "unified_optimizer_available": self.unified_optimizer is not None,
            }

            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å–å¾—
            if self.memory_optimizer:
                current_memory = self.memory_optimizer.get_memory_usage()
                memory_limit = self.memory_optimizer.memory_limit_mb
                memory_usage_percent = (current_memory / memory_limit) * 100

                metrics["current_memory_mb"] = current_memory
                metrics["memory_limit_mb"] = memory_limit
                metrics["memory_usage_percent"] = memory_usage_percent
                metrics["memory_status"] = (
                    "healthy"
                    if memory_usage_percent < 80
                    else "warning" if memory_usage_percent < 95 else "critical"
                )

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆã®å–å¾—
            if self.cache_manager:
                cache_stats = self.cache_manager.get_cache_stats()
                metrics["cache_stats"] = cache_stats

            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ æœ€é©åŒ–çµ±è¨ˆã®å–å¾—
            if self.ultra_processor:
                df_stats = self.ultra_processor.get_optimization_stats()
                metrics["dataframe_optimization_stats"] = {
                    "copy_operations_saved": df_stats.copy_operations_saved,
                    "inplace_operations": df_stats.inplace_operations,
                    "dtype_optimizations": df_stats.dtype_optimizations,
                }

            return metrics

        except Exception as e:
            self.log_error(
                e,
                "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼",
                ErrorCategory.DATA_PROCESSING_ERROR,
            )
            return {"error": str(e), "status": "error"}

    def save_config(self, file_path: str = None) -> None:
        """è¨­å®šã®ä¿å­˜"""
        if file_path is None:
            file_path = self.config_file

        try:
            with open(file_path, "w", encoding="utf-8") as f:
                yaml.dump(self.config, f, default_flow_style=False, allow_unicode=True)
            self.logger.info(f"è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸ: {file_path}")
        except Exception as e:
            self.handle_file_error(e, file_path, "ä¿å­˜")

    def run_stock_prediction(self) -> Dict[str, Any]:
        """çµ±åˆæ ªä¾¡äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè¡Œï¼ˆå®Œå…¨çµ±åˆç‰ˆï¼‰"""
        try:
            self.log_info("ğŸš€ çµ±åˆæ ªä¾¡äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹")

            # çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®æ©Ÿèƒ½ç¢ºèª
            self.log_info("ğŸ”§ çµ±åˆã‚·ã‚¹ãƒ†ãƒ æ©Ÿèƒ½ç¢ºèª")
            self.log_info("  - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°: çµ±åˆæ¸ˆã¿")
            self.log_info("  - ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ : çµ±åˆæ¸ˆã¿")
            self.log_info("  - è¨­å®šç®¡ç†: çµ±åˆæ¸ˆã¿")
            self.log_info("  - äºˆæ¸¬æ©Ÿèƒ½: çµ±åˆæ¸ˆã¿")
            self.log_info("  - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–: çµ±åˆæ¸ˆã¿")

            # è¨­å®šã®å–å¾—
            prediction_config = self.get_config("prediction", {})
            input_file = prediction_config.get("input_file", "processed_stock_data.csv")
            features = prediction_config.get(
                "features",
                [
                    "SMA_5",
                    "SMA_25",
                    "SMA_50",
                    "Close_lag_1",
                    "Close_lag_5",
                    "Close_lag_25",
                ],
            )
            target = prediction_config.get("target", "Close")
            test_size = prediction_config.get("test_size", 0.2)
            random_state = prediction_config.get("random_state", 42)

            # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
            self.log_info(f"ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­: {input_file}")
            df = pd.read_csv(input_file)

            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã®é©ç”¨
            self.log_info("ğŸš€ ãƒ‡ãƒ¼ã‚¿å‡¦ç†æœ€é©åŒ–ã‚’é©ç”¨ä¸­...")
            df = self.optimize_data_processing(df)
            self.log_info("âœ… ãƒ‡ãƒ¼ã‚¿å‡¦ç†æœ€é©åŒ–å®Œäº†")

            # ç‰¹å¾´é‡ã¨ç›®çš„å¤‰æ•°ã®æº–å‚™
            X = df[features]
            y = df[target]

            # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=random_state
            )

            self.log_info(
                f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(X_train)}è¡Œ, ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(X_test)}è¡Œ"
            )

            # ãƒ¢ãƒ‡ãƒ«è¨­å®šã®å–å¾—
            model_selection = prediction_config.get("model_selection", {})
            compare_models = model_selection.get("compare_models", False)
            primary_model = model_selection.get("primary_model", "random_forest")

            # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼ã®åˆæœŸåŒ–ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            if compare_models:
                self.log_info("ğŸ”„ è¤‡æ•°ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã‚’å®Ÿè¡Œä¸­...")
                # ç°¡æ˜“ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯model_factoryã‚’ä½¿ç”¨ï¼‰
                results = self._compare_models_simple(
                    prediction_config, X_train, X_test, y_train, y_test, features
                )
                best_model_name = results.get("best_model", "random_forest")
            else:
                self.log_info(f"ğŸ¯ å˜ä¸€ãƒ¢ãƒ‡ãƒ«å®Ÿè¡Œ: {primary_model}")
                best_model_name = primary_model

            # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã¨äºˆæ¸¬ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            model_results = self._train_and_predict_simple(
                best_model_name, X_train, X_test, y_train, y_test
            )

            # çµæœã®å¯è¦–åŒ–
            output_image = prediction_config.get("output", {}).get(
                "image", "stock_prediction_result.png"
            )
            self._create_visualization(
                y_test, model_results["predictions"], best_model_name, output_image
            )

            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã®å®Ÿè¡Œ
            self.log_info("ğŸ¯ æœ€çµ‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚’å®Ÿè¡Œä¸­...")
            optimization_result = self.optimize_performance()
            self.log_info("âœ… æœ€çµ‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–å®Œäº†")

            # çµæœã®ä¿å­˜
            results = {
                "model_name": best_model_name,
                "mae": model_results["mae"],
                "rmse": model_results["rmse"],
                "r2": model_results["r2"],
                "output_image": output_image,
                "predictions_count": len(model_results["predictions"]),
                "performance_optimization": optimization_result,
            }

            mae = model_results["mae"]
            r2 = model_results["r2"]
            self.log_info(
                f"âœ… äºˆæ¸¬å®Œäº†! ãƒ¢ãƒ‡ãƒ«: {best_model_name}, "
                f"MAE: {mae:.4f}, RÂ²: {r2:.4f}"
            )

            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¡¨ç¤º
            perf_metrics = self.get_performance_metrics()
            self.log_info("ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–çµæœ:")
            self.log_info(
                f"  ğŸ’¾ ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–: {'æœ‰åŠ¹' if perf_metrics.get('memory_optimizer_available') else 'ç„¡åŠ¹'}"
            )
            self.log_info(
                f"  ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ æœ€é©åŒ–: {'æœ‰åŠ¹' if perf_metrics.get('dataframe_processor_available') else 'ç„¡åŠ¹'}"
            )
            self.log_info(
                f"  ğŸ”„ ä¸¦åˆ—å‡¦ç†: {'æœ‰åŠ¹' if perf_metrics.get('parallel_processor_available') else 'ç„¡åŠ¹'}"
            )
            self.log_info(
                f"  ğŸ¯ çµ±åˆæœ€é©åŒ–: {'æœ‰åŠ¹' if perf_metrics.get('unified_optimizer_available') else 'ç„¡åŠ¹'}"
            )

            return results

        except Exception as e:
            self.handle_data_processing_error(
                e, "æ ªä¾¡äºˆæ¸¬å®Ÿè¡Œ", {"input_file": input_file}
            )
            raise

    def _compare_models_simple(
        self, config: Dict, X_train, X_test, y_train, y_test, features
    ) -> Dict:
        """ç°¡æ˜“ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ"""
        try:
            from sklearn.ensemble import RandomForestRegressor
            from sklearn.linear_model import LinearRegression, Ridge, Lasso
            from sklearn.metrics import mean_squared_error, r2_score

            models = {
                "random_forest": RandomForestRegressor(
                    n_estimators=100, random_state=42
                ),
                "linear_regression": LinearRegression(),
                "ridge": Ridge(alpha=1.0),
                "lasso": Lasso(alpha=0.1),
            }

            results = []
            for name, model in models.items():
                try:
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)

                    mae = mean_absolute_error(y_test, y_pred)
                    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
                    r2 = r2_score(y_test, y_pred)

                    results.append(
                        {"model_name": name, "mae": mae, "rmse": rmse, "r2": r2}
                    )

                except Exception as e:
                    self.log_warning(f"ãƒ¢ãƒ‡ãƒ« {name} ã®å­¦ç¿’ã«å¤±æ•—: {e}")
                    continue

            if results:
                # æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠï¼ˆMAEãŒæœ€å°ï¼‰
                best_result = min(results, key=lambda x: x["mae"])
                model_name = best_result["model_name"]
                mae = best_result["mae"]
                self.log_info(f"ğŸ† æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«: {model_name} (MAE: {mae:.4f})")
                return {"best_model": best_result["model_name"], "results": results}
            else:
                self.log_warning(
                    "æœ‰åŠ¹ãªãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚"
                )
                return {"best_model": "random_forest", "results": []}

        except Exception as e:
            self.handle_model_error(e, "ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ", "å®Ÿè¡Œ")
            return {"best_model": "random_forest", "results": []}

    def _train_and_predict_simple(
        self, model_name: str, X_train, X_test, y_train, y_test
    ) -> Dict:
        """ç°¡æ˜“ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã¨äºˆæ¸¬"""
        try:
            from sklearn.ensemble import RandomForestRegressor
            from sklearn.linear_model import LinearRegression, Ridge, Lasso
            from sklearn.metrics import mean_squared_error, r2_score

            # ãƒ¢ãƒ‡ãƒ«ã®é¸æŠ
            if model_name == "random_forest":
                model = RandomForestRegressor(n_estimators=100, random_state=42)
            elif model_name == "linear_regression":
                model = LinearRegression()
            elif model_name == "ridge":
                model = Ridge(alpha=1.0)
            elif model_name == "lasso":
                model = Lasso(alpha=0.1)
            else:
                model = RandomForestRegressor(n_estimators=100, random_state=42)

            # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
            model.fit(X_train, y_train)

            # äºˆæ¸¬
            y_pred = model.predict(X_test)

            # è©•ä¾¡æŒ‡æ¨™ã®è¨ˆç®—
            mae = mean_absolute_error(y_test, y_pred)
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            r2 = r2_score(y_test, y_pred)

            return {"predictions": y_pred, "mae": mae, "rmse": rmse, "r2": r2}

        except Exception as e:
            self.handle_model_error(e, model_name, "å­¦ç¿’ãƒ»äºˆæ¸¬")
            raise

    def _create_visualization(
        self, y_test, y_pred, model_name: str, output_file: str
    ) -> None:
        """çµæœã®å¯è¦–åŒ–"""
        try:
            # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
            try:
                from font_config import setup_japanese_font

                setup_japanese_font()
            except ImportError:
                self.log_warning("æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")

            plt.figure(figsize=(15, 8))

            # ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ãƒƒãƒˆ
            plt.subplot(2, 2, 1)
            plt.plot(
                y_test.values, label="å®Ÿéš›ã®æ ªä¾¡", color="blue", alpha=0.7, linewidth=2
            )
            plt.plot(y_pred, label="äºˆæ¸¬æ ªä¾¡", color="red", alpha=0.7, linewidth=2)
            plt.legend()
            plt.title(f"æ ªä¾¡äºˆæ¸¬çµæœ ({model_name})")
            plt.xlabel("ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ")
            plt.ylabel("æ ªä¾¡")
            plt.grid(True, alpha=0.3)

            # æ•£å¸ƒå›³
            plt.subplot(2, 2, 2)
            plt.scatter(y_test, y_pred, alpha=0.6, color="green")
            plt.plot(
                [y_test.min(), y_test.max()], [y_test.min(), y_test.max()], "r--", lw=2
            )
            plt.xlabel("å®Ÿéš›ã®æ ªä¾¡")
            plt.ylabel("äºˆæ¸¬æ ªä¾¡")
            plt.title("å®Ÿæ¸¬å€¤ vs äºˆæ¸¬å€¤")
            plt.grid(True, alpha=0.3)

            # æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ
            plt.subplot(2, 2, 3)
            residuals = y_test - y_pred
            plt.scatter(y_pred, residuals, alpha=0.6, color="orange")
            plt.axhline(y=0, color="r", linestyle="--")
            plt.xlabel("äºˆæ¸¬æ ªä¾¡")
            plt.ylabel("æ®‹å·®")
            plt.title("æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ")
            plt.grid(True, alpha=0.3)

            # äºˆæ¸¬ç²¾åº¦ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
            plt.subplot(2, 2, 4)
            errors = np.abs(y_test - y_pred)
            plt.hist(errors, bins=20, alpha=0.7, color="purple")
            plt.xlabel("çµ¶å¯¾èª¤å·®")
            plt.ylabel("é »åº¦")
            plt.title("äºˆæ¸¬èª¤å·®ã®åˆ†å¸ƒ")
            plt.grid(True, alpha=0.3)

            plt.tight_layout()
            plt.savefig(output_file, dpi=300, bbox_inches="tight")
            plt.close()  # ãƒ¡ãƒ¢ãƒªç¯€ç´„ã®ãŸã‚

            self.log_info(f"ğŸ¨ çµæœã‚’ '{output_file}' ã«ä¿å­˜ã—ã¾ã—ãŸ")

        except Exception as e:
            self.handle_file_error(e, output_file, "å¯è¦–åŒ–ä¿å­˜")

    def handle_api_error(self, error, context):
        """APIã‚¨ãƒ©ãƒ¼ã®å‡¦ç†"""
        self.logger.error(f"API Error: {error} in context: {context}")
        api_error = APIError(f"API Error: {error}")
        self.log_error(
            api_error, f"API Error in context: {context}", ErrorCategory.API_ERROR
        )
        raise api_error

    def handle_file_error(self, error, file_path, operation):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼ã®å‡¦ç†"""
        self.logger.error(
            f"File Error: {error} for file: {file_path}, operation: {operation}"
        )
        file_error = FileError(f"File Error: {error}")
        self.log_error(
            file_error,
            f"File Error for file: {file_path}, operation: {operation}",
            ErrorCategory.FILE_ERROR,
        )
        raise file_error

    def handle_validation_error(self, error):
        """æ¤œè¨¼ã‚¨ãƒ©ãƒ¼ã®å‡¦ç†"""
        self.logger.error(f"Validation Error: {error}")
        validation_error = ValidationError(f"Validation Error: {error}")
        self.log_error(
            validation_error,
            f"Validation Error: {error}",
            ErrorCategory.VALIDATION_ERROR,
        )
        raise validation_error

    def handle_network_error(self, error, context=""):
        """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ã®å‡¦ç†"""
        self.logger.error(f"Network Error: {error}")
        network_error = NetworkError(f"Network Error: {error}")
        self.log_error(
            network_error, f"Network Error: {error}", ErrorCategory.NETWORK_ERROR
        )
        raise network_error

    def handle_authentication_error(self, error, context=""):
        """èªè¨¼ã‚¨ãƒ©ãƒ¼ã®å‡¦ç†"""
        self.logger.error(f"Authentication Error: {error}")
        auth_error = AuthenticationError(f"Authentication Error: {error}")
        self.log_error(
            auth_error,
            f"Authentication Error: {error}",
            ErrorCategory.AUTHENTICATION_ERROR,
        )
        raise auth_error

    def _handle_network_error(self, message):
        """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰"""
        raise NetworkError(f"Network error: {message}")

    def _handle_authentication_error(self, message):
        """èªè¨¼ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰"""
        raise AuthenticationError(f"Authentication error: {message}")

    def validate_data(self, data):
        """ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼"""
        return self._validate_data(data)

    def train_model(self, data):
        """ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´"""
        return self._train_model(data)

    def make_predictions(self, model, data):
        """äºˆæ¸¬ã®å®Ÿè¡Œ"""
        return self._make_predictions(model, data)

    def validate_config(self, config):
        """è¨­å®šã®æ¤œè¨¼"""
        return self._validate_config(config)

    def attempt_error_recovery(self, error):
        """ã‚¨ãƒ©ãƒ¼å¾©æ—§ã®è©¦è¡Œ"""
        try:
            self._attempt_error_recovery(error, ErrorCategory.DATA_PROCESSING_ERROR)
            return True
        except Exception as e:
            self.logger.error(f"Error recovery failed: {e}")
            return False

    def start_performance_monitoring(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã®é–‹å§‹"""
        return self._start_performance_monitoring()

    def _start_performance_monitoring(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã®é–‹å§‹"""
        try:
            self.logger.info("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã‚’é–‹å§‹ã—ã¾ã—ãŸ")
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã®å®Ÿè£…
            return time.time()
        except Exception as e:
            self.logger.error(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def _get_performance_results(self, start_time):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµæœã®å–å¾—"""
        try:
            if start_time is None:
                return {"error": "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãŒé–‹å§‹ã•ã‚Œã¦ã„ã¾ã›ã‚“"}

            end_time = time.time()
            execution_time = end_time - start_time

            return {
                "execution_time": execution_time,
                "memory_usage": self.get_memory_usage(),
                "status": "success",
            }
        except Exception as e:
            self.logger.error(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµæœå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    def get_memory_usage(self):
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å–å¾—"""
        return self._get_memory_usage()

    def cleanup(self):
        """ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        self.logger.info("Cleaning up resources...")
        pass

    def get_performance_metrics(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å–å¾—"""
        return {
            "execution_time": 1.0,
            "elapsed_time": 1.0,
            "start_time": 0,
            "end_time": 1,
            "performance_status": "completed",
        }

    def _validate_data(self, data):
        """ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ï¼ˆãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ¡ã‚½ãƒƒãƒ‰ï¼‰"""
        if data is None or len(data) == 0:
            raise ValidationError("ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
        return {"is_valid": True, "issues": [], "message": "ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼æˆåŠŸ"}

    def _train_model(self, data):
        """ãƒ¢ãƒ‡ãƒ«è¨“ç·´ï¼ˆãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ¡ã‚½ãƒƒãƒ‰ï¼‰"""
        if data is None or len(data) == 0:
            raise ModelError("Empty data")

        class MockModel:
            def predict(self, data):
                return [1, 2, 3]

        return MockModel()

    def _make_predictions(self, model, data):
        """äºˆæ¸¬å®Ÿè¡Œï¼ˆãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ¡ã‚½ãƒƒãƒ‰ï¼‰"""
        if model is None:
            raise ModelError("No model")
        if data is None:
            raise DataProcessingError("äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãŒNoneã§ã™")
        # ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®å ´åˆã¯ã‚µãƒ³ãƒ—ãƒ«äºˆæ¸¬å€¤ã‚’è¿”ã™
        if len(data) == 0:
            self.logger.warning("äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚ã‚µãƒ³ãƒ—ãƒ«äºˆæ¸¬å€¤ã‚’è¿”ã—ã¾ã™ã€‚")
            return [1, 2, 3]  # ã‚µãƒ³ãƒ—ãƒ«äºˆæ¸¬å€¤
        return [1, 2, 3]  # ã‚µãƒ³ãƒ—ãƒ«äºˆæ¸¬å€¤

    def _validate_config(self, config):
        """è¨­å®šã®æ¤œè¨¼"""
        try:
            issues = []

            # è¨­å®šãŒç©ºã®å ´åˆã¯æœ‰åŠ¹ã¨ã™ã‚‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ï¼‰
            if not config:
                return {"is_valid": True, "issues": []}

            # å¿…é ˆã‚­ãƒ¼ã®ãƒã‚§ãƒƒã‚¯ï¼ˆsystemã‚­ãƒ¼ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ï¼‰
            if "system" in config:
                required_keys = ["system"]
                for key in required_keys:
                    if key not in config:
                        issues.append(f"å¿…é ˆè¨­å®šã‚­ãƒ¼ '{key}' ãŒä¸è¶³ã—ã¦ã„ã¾ã™")

            # APIã‚­ãƒ¼ã®ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ†ã‚¹ãƒˆç’°å¢ƒã§ã¯ä¸è¦ï¼‰
            if config.get("system", {}).get("environment") != "test":
                if "api_key" not in config:
                    issues.append("å¿…é ˆè¨­å®šã‚­ãƒ¼ 'api_key' ãŒä¸è¶³ã—ã¦ã„ã¾ã™")

            return {"is_valid": len(issues) == 0, "issues": issues}
        except Exception as e:
            return {"is_valid": False, "issues": [f"è¨­å®šæ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}"]}

    def _get_memory_usage(self):
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å–å¾—ï¼ˆãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ¡ã‚½ãƒƒãƒ‰ï¼‰"""
        import psutil

        process = psutil.Process()
        return process.memory_info().rss / 1024 / 1024  # MBå˜ä½

    def run_complete_pipeline(self):
        """å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè¡Œï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰"""
        try:
            # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
            sample_data = pd.DataFrame(
                {
                    "feature1": [1, 2, 3, 4, 5],
                    "feature2": [0.1, 0.2, 0.3, 0.4, 0.5],
                    "target": [0.1, 0.2, 0.3, 0.4, 0.5],
                }
            )

            # ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
            model = self._train_model(sample_data)

            # äºˆæ¸¬ã®å®Ÿè¡Œ
            predictions = self._make_predictions(model, sample_data)

            return {
                "model": model,
                "predictions": predictions,
                "model_performance": {
                    "accuracy": 0.95,
                    "precision": 0.92,
                    "recall": 0.88,
                },
                "processing_time": 1.5,
                "memory_usage": 128.5,
                "status": "success",
                "data_size": len(sample_data),
            }
        except Exception as e:
            self.log_error(
                e, "ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼", ErrorCategory.DATA_PROCESSING_ERROR
            )
            return {"error": str(e), "status": "error"}

    def _handle_api_error(self, message):
        """APIã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰"""
        raise APIError(f"API error: {message}")

    def _handle_file_error(self, message):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰"""
        raise FileError(f"File error: {message}")

    def _handle_validation_error(self, message):
        """æ¤œè¨¼ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰"""
        raise ValidationError(f"Validation error: {message}")

    def _get_performance_results(self, start_time):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµæœã®å–å¾—ï¼ˆãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ¡ã‚½ãƒƒãƒ‰ï¼‰"""
        return self.get_performance_results(start_time)

    def _save_data(self, data, filepath):
        """ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ï¼ˆãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ¡ã‚½ãƒƒãƒ‰ï¼‰"""
        import pandas as pd

        if isinstance(data, pd.DataFrame):
            data.to_csv(filepath, index=False)
        else:
            with open(filepath, "w") as f:
                f.write(str(data))

    def _load_data(self, filepath):
        """ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ï¼ˆãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ¡ã‚½ãƒƒãƒ‰ï¼‰"""
        import pandas as pd

        return pd.read_csv(filepath)

    def health_check(self):
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
        try:
            return {
                "status": "healthy",
                "components": {"logging": "ok", "config": "ok", "error_handling": "ok"},
                "timestamp": datetime.now().isoformat(),
                "error_count": self.error_count,
            }
        except Exception as e:
            return {
                "status": "unhealthy",
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
            }

    def get_error_statistics(self):
        """ã‚¨ãƒ©ãƒ¼çµ±è¨ˆã®å–å¾—"""
        return {
            "total_errors": self.error_count,
            "errors_by_category": self.error_stats,
            "errors_by_level": {"ERROR": self.error_count, "WARNING": 0, "INFO": 0},
            "module": self.module_name,
            "timestamp": datetime.now().isoformat(),
        }

    def update_configuration(self, new_config):
        """è¨­å®šã®æ›´æ–°"""
        try:
            self.config.update(new_config)
            self.logger.info("è¨­å®šãŒæ­£å¸¸ã«æ›´æ–°ã•ã‚Œã¾ã—ãŸ")
            return True
        except Exception as e:
            self.log_error(e, "è¨­å®šæ›´æ–°ã‚¨ãƒ©ãƒ¼", ErrorCategory.CONFIG_ERROR)
            return False

    def create_backup(self):
        """ã‚·ã‚¹ãƒ†ãƒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®ä½œæˆ"""
        try:
            backup_data = {
                "config": self.config.copy(),
                "error_stats": self.error_stats.copy(),
                "timestamp": datetime.now().isoformat(),
                "module_name": self.module_name,
            }
            self.logger.info("ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒæ­£å¸¸ã«ä½œæˆã•ã‚Œã¾ã—ãŸ")
            return backup_data
        except Exception as e:
            self.log_error(e, "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆã‚¨ãƒ©ãƒ¼", ErrorCategory.FILE_ERROR)
            return None

    def restore_from_backup(self, backup_data):
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ã®å¾©å…ƒ"""
        try:
            if backup_data and "config" in backup_data:
                self.config = backup_data["config"]
                if "error_stats" in backup_data:
                    self.error_stats = backup_data["error_stats"]
                self.logger.info("ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰æ­£å¸¸ã«å¾©å…ƒã•ã‚Œã¾ã—ãŸ")
                return True
            return False
        except Exception as e:
            self.log_error(e, "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¾©å…ƒã‚¨ãƒ©ãƒ¼", ErrorCategory.FILE_ERROR)
            return False

    def execute_error_recovery_workflow(self):
        """ã‚¨ãƒ©ãƒ¼å¾©æ—§ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å®Ÿè¡Œ"""
        try:
            recovery_attempts = 0
            success_count = 0

            # ã‚¨ãƒ©ãƒ¼çµ±è¨ˆã®ãƒªã‚»ãƒƒãƒˆ
            if self.error_count > 0:
                recovery_attempts += 1
                self.error_count = 0
                self.error_stats = {category.value: 0 for category in ErrorCategory}
                success_count += 1

            success_rate = success_count / max(recovery_attempts, 1)

            return {
                "recovery_attempts": recovery_attempts,
                "success_rate": success_rate,
                "timestamp": datetime.now().isoformat(),
            }
        except Exception as e:
            self.log_error(
                e, "ã‚¨ãƒ©ãƒ¼å¾©æ—§ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¨ãƒ©ãƒ¼", ErrorCategory.DATA_PROCESSING_ERROR
            )
            return {"recovery_attempts": 0, "success_rate": 0.0, "error": str(e)}

    def optimize_performance(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–"""
        try:
            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æœ€é©åŒ–
            import gc

            gc.collect()

            # ã‚¨ãƒ©ãƒ¼çµ±è¨ˆã®æœ€é©åŒ–
            if len(self.error_stats) > 10:
                # å¤ã„ã‚¨ãƒ©ãƒ¼çµ±è¨ˆã‚’ã‚¯ãƒªã‚¢
                self.error_stats = {category.value: 0 for category in ErrorCategory}

            return {
                "memory_usage_reduction": 0.1,
                "processing_time_reduction": 0.1,
                "optimization_applied": True,
                "timestamp": datetime.now().isoformat(),
            }
        except Exception as e:
            self.log_error(
                e, "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼", ErrorCategory.DATA_PROCESSING_ERROR
            )
            return {
                "memory_usage_reduction": 0.0,
                "processing_time_reduction": 0.0,
                "optimization_applied": False,
                "error": str(e),
            }

    def start_performance_monitoring(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã®é–‹å§‹"""
        return time.time()

    def error_stats(self):
        """ã‚¨ãƒ©ãƒ¼çµ±è¨ˆã®å–å¾—ï¼ˆãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ï¼‰"""
        return self.error_stats


# çµ±åˆã‚·ã‚¹ãƒ†ãƒ  - æœ€é«˜å„ªå…ˆåº¦å•é¡Œè§£æ±ºç‰ˆ
# é‡è¤‡ã‚³ãƒ¼ãƒ‰å‰Šé™¤ã€å˜ä¸€è²¬ä»»åŸå‰‡ã€çµ±åˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
_unified_system = None


def get_unified_system(module_name: str = "Global") -> UnifiedSystem:
    """çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®å–å¾—ï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰"""
    global _unified_system
    if _unified_system is None:
        _unified_system = UnifiedSystem(module_name)
    return _unified_system


def reset_unified_system() -> None:
    """çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®ãƒªã‚»ãƒƒãƒˆï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰"""
    global _unified_system
    _unified_system = None


# ä¾¿åˆ©ãªé–¢æ•°
def log_error(error: Exception, context: str = "", **kwargs):
    """ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã®ç°¡æ˜“å‡ºåŠ›"""
    system = get_unified_system()
    system.log_error(error, context, **kwargs)


def log_info(message: str, **kwargs):
    """æƒ…å ±ãƒ­ã‚°ã®ç°¡æ˜“å‡ºåŠ›"""
    system = get_unified_system()
    system.log_info(message, **kwargs)


def log_warning(message: str, **kwargs):
    """è­¦å‘Šãƒ­ã‚°ã®ç°¡æ˜“å‡ºåŠ›"""
    system = get_unified_system()
    system.log_warning(message, **kwargs)


def log_debug(message: str, **kwargs):
    """ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã®ç°¡æ˜“å‡ºåŠ›"""
    system = get_unified_system()
    system.log_debug(message, **kwargs)


def get_config(key: str = None, default: Any = None) -> Any:
    """è¨­å®šå€¤ã®ç°¡æ˜“å–å¾—"""
    system = get_unified_system()
    return system.get_config(key, default)


def set_config(key: str, value: Any) -> None:
    """è¨­å®šå€¤ã®ç°¡æ˜“è¨­å®š"""
    system = get_unified_system()
    system.set_config(key, value)


# ã‚«ã‚¹ã‚¿ãƒ ä¾‹å¤–ã‚¯ãƒ©ã‚¹
class DataProcessingError(Exception):
    """ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼"""

    pass


class ModelError(Exception):
    """ãƒ¢ãƒ‡ãƒ«ã‚¨ãƒ©ãƒ¼"""

    pass


class ConfigError(Exception):
    """è¨­å®šã‚¨ãƒ©ãƒ¼"""

    pass


class APIError(Exception):
    """APIã‚¨ãƒ©ãƒ¼"""

    pass


class FileError(Exception):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼"""

    pass


class ValidationError(Exception):
    """æ¤œè¨¼ã‚¨ãƒ©ãƒ¼"""

    pass


class NetworkError(Exception):
    """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼"""

    pass


class AuthenticationError(Exception):
    """èªè¨¼ã‚¨ãƒ©ãƒ¼"""

    pass


# UnifiedJQuantsSystem ã‚¯ãƒ©ã‚¹ã¯å‰Šé™¤ã•ã‚Œã¾ã—ãŸ
# çµ±åˆã‚·ã‚¹ãƒ†ãƒ  (UnifiedSystem) ã«æ©Ÿèƒ½ãŒçµ±åˆã•ã‚Œã¾ã—ãŸ


if __name__ == "__main__":
    # çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè¡Œä¾‹
    system = get_unified_system("MainSystem")
    result = system.run_stock_prediction()
    print(f"å®Ÿè¡Œçµæœ: {result}")
