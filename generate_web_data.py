#!/usr/bin/env python3
"""
Webè¡¨ç¤ºç”¨ã®ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆç°¡æ˜“ç‰ˆï¼‰
UnifiedSystemã®å¾ªç’°å‚ç…§ã‚’å›é¿ã—ãŸç‹¬ç«‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import json
import pandas as pd
import numpy as np
import os
import sys
import logging
import subprocess
import yaml
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def validate_and_select_features(df, config_features, target):
    """åˆ©ç”¨å¯èƒ½ãªç‰¹å¾´é‡ã‚’æ¤œè¨¼ãƒ»é¸æŠ"""
    available_features = df.columns.tolist()
    logger.info(f"ğŸ“ åˆ©ç”¨å¯èƒ½ãªã‚«ãƒ©ãƒ : {available_features}")
    logger.info(f"ğŸ”§ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ç‰¹å¾´é‡: {config_features}")

    # åˆ©ç”¨å¯èƒ½ãªç‰¹å¾´é‡ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    valid_features = [f for f in config_features if f in available_features]

    if len(valid_features) == 0:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ•°å€¤å‹ã‚«ãƒ©ãƒ ã‚’è‡ªå‹•é¸æŠ
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        valid_features = [
            col
            for col in numeric_cols
            if col != target and col not in ["Date", "Code", "CompanyName"]
        ]
        logger.warning(
            f"ğŸ”„ è¨­å®šã®ç‰¹å¾´é‡ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€è‡ªå‹•é¸æŠã—ã¾ã—ãŸ: {valid_features}"
        )

    logger.info(f"âœ… ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡: {valid_features}")
    return valid_features


def generate_web_data():
    """Webè¡¨ç¤ºç”¨ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    # ç›´æ¥è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆUnifiedSystemã®ç„¡é™ãƒ«ãƒ¼ãƒ—ã‚’å›é¿ï¼‰
    try:
        with open("config_final.yaml", "r", encoding="utf-8") as f:
            config = yaml.safe_load(f) or {}
        prediction_config = config.get("prediction", {})
        preprocessing_config = config.get("preprocessing", {})
        logger.info("âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
    except Exception as e:
        logger.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨
        prediction_config = {
            "features": ["Close", "Volume", "Open", "High", "Low"],
            "target": "Close",
            "test_size": 0.2,
            "random_state": 42,
        }
        preprocessing_config = {"output_file": "processed_stock_data.csv"}

    output_dir = Path("web-app/public/data")
    output_dir.mkdir(parents=True, exist_ok=True)

    logger.info("ğŸŒ Webè¡¨ç¤ºç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆä¸­...")

    # 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    input_file = preprocessing_config.get("output_file", "processed_stock_data.csv")

    # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã€ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
    if not os.path.exists(input_file):
        logger.warning(f"ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_file}")
        logger.info("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã™...")
        subprocess.run([sys.executable, "create_sample_data.py"], check=True)

    df = pd.read_csv(input_file)

    # 2. ç‰¹å¾´é‡ã®æ¤œè¨¼ã¨é¸æŠ
    config_features = prediction_config.get("features", [])
    target = prediction_config.get("target", "Close")
    features = validate_and_select_features(df, config_features, target)

    if len(features) == 0:
        logger.error("âŒ ä½¿ç”¨å¯èƒ½ãªç‰¹å¾´é‡ãŒã‚ã‚Šã¾ã›ã‚“")
        return

    # 3. ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
    X = df[features].dropna()
    y = df[target].iloc[: len(X)]

    test_size = prediction_config.get("test_size", 0.2)
    random_state = prediction_config.get("random_state", 42)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state
    )

    # 4. ãƒ¢ãƒ‡ãƒ«å®Ÿè¡Œï¼ˆRandom Forestã‚’ä½¿ç”¨ï¼‰
    model = RandomForestRegressor(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # 5. è©•ä¾¡æŒ‡æ¨™è¨ˆç®—
    mae = mean_absolute_error(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)

    metrics = {"mae": mae, "rmse": rmse, "r2": r2}

    # 6. Webç”¨ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ

    # æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ (æ™‚ç³»åˆ—)
    try:
        if "Date" in df.columns:
            df["Date"] = pd.to_datetime(df["Date"])
            stock_data = []
            for i, idx in enumerate(X_test.index):
                if idx < len(df) and i < len(y_test) and i < len(y_pred):
                    stock_data.append(
                        {
                            "Date": df.iloc[idx]["Date"].strftime("%Y-%m-%d"),
                            "Actual": float(y_test.iloc[i]),
                            "Predicted": float(y_pred[i]),
                        }
                    )
        else:
            stock_data = []
            for i, (actual, predicted) in enumerate(zip(y_test, y_pred)):
                stock_data.append(
                    {
                        "Date": f"2024-09-{i+1:02d}",
                        "Actual": float(actual),
                        "Predicted": float(predicted),
                    }
                )

        with open(output_dir / "stock_data.json", "w", encoding="utf-8") as f:
            json.dump(stock_data, f, indent=2, ensure_ascii=False)
        logger.info("âœ… æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
    except Exception as e:
        logger.error(f"âŒ æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")

    # ç‰¹å¾´é‡é‡è¦åº¦
    try:
        feature_importance = pd.DataFrame(
            {"feature": features, "importance": model.feature_importances_}
        ).sort_values("importance", ascending=False)

        if not feature_importance.empty:
            total_importance = feature_importance["importance"].sum()
            feature_analysis = []
            for _, row in feature_importance.iterrows():
                feature_analysis.append(
                    {
                        "feature": row["feature"],
                        "importance": float(row["importance"]),
                        "percentage": (
                            float(row["importance"] / total_importance * 100)
                            if total_importance > 0
                            else 0
                        ),
                    }
                )

            with open(output_dir / "feature_analysis.json", "w", encoding="utf-8") as f:
                json.dump(feature_analysis, f, indent=2, ensure_ascii=False)
            logger.info("âœ… ç‰¹å¾´é‡åˆ†æãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
    except Exception as e:
        logger.error(f"âŒ ç‰¹å¾´é‡åˆ†æãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")

    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™
    try:
        performance_metrics = {
            "model_name": "Random Forest",
            "mae": float(metrics.get("mae", 0)),
            "rmse": float(metrics.get("rmse", 0)),
            "r2": float(metrics.get("r2", 0)),
            "data_points": len(y_test),
            "train_size": len(X_train),
            "test_size": len(X_test),
        }

        with open(output_dir / "performance_metrics.json", "w", encoding="utf-8") as f:
            json.dump(performance_metrics, f, indent=2, ensure_ascii=False)
        logger.info("âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
    except Exception as e:
        logger.error(f"âŒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")

    # äºˆæ¸¬çµæœ (æ•£å¸ƒå›³ç”¨)
    try:
        prediction_results = []
        for actual, predicted in zip(y_test, y_pred):
            prediction_results.append(
                {
                    "Actual": float(actual),
                    "Predicted": float(predicted),
                    "Residuals": float(actual - predicted),
                }
            )

        with open(output_dir / "prediction_results.json", "w", encoding="utf-8") as f:
            json.dump(prediction_results, f, indent=2, ensure_ascii=False)
        logger.info("âœ… äºˆæ¸¬çµæœãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
    except Exception as e:
        logger.error(f"âŒ äºˆæ¸¬çµæœãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")

    # ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ (ç°¡æ˜“ç‰ˆ)
    try:
        model_comparison = [
            {
                "model_name": "primary_model",
                "model_type": "Random Forest",
                "mae": float(metrics.get("mae", 0)),
                "rmse": float(metrics.get("rmse", 0)),
                "r2": float(metrics.get("r2", 0)),
            }
        ]

        with open(output_dir / "model_comparison.json", "w", encoding="utf-8") as f:
            json.dump(model_comparison, f, indent=2, ensure_ascii=False)
        logger.info("âœ… ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
    except Exception as e:
        logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")

    # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚µãƒãƒªãƒ¼
    try:
        dashboard_summary = {
            "total_data_points": len(df),
            "prediction_period": (
                f"{df.index[0]} - {df.index[-1]}" if len(df) > 0 else "N/A"
            ),
            "best_model": "Random Forest",
            "mae": f"{metrics.get('mae', 0):.2f}",
            "r2": f"{metrics.get('r2', 0):.2f}",
            "last_updated": pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S"),
        }

        with open(output_dir / "dashboard_summary.json", "w", encoding="utf-8") as f:
            json.dump(dashboard_summary, f, indent=2, ensure_ascii=False)
        logger.info("âœ… ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
    except Exception as e:
        logger.error(f"âŒ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚µãƒãƒªãƒ¼ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")

    logger.info(f"âœ… å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ãŒ {output_dir} ã«ç”Ÿæˆã•ã‚Œã¾ã—ãŸ")


if __name__ == "__main__":
    generate_web_data()
