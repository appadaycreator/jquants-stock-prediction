#!/usr/bin/env python3
"""
çµ±åˆä¸¦åˆ—å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ 
æ—¢å­˜ã®ã‚·ã‚¹ãƒ†ãƒ ã«ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–ã‚’çµ±åˆ
"""

import os
import sys
import time
import logging
from typing import Dict, Any, List, Callable, Optional
from unified_parallel_processing_system import (
    execute_parallel,
    get_parallel_config,
    set_parallel_config,
)
from unified_system import get_unified_system
from concurrent.futures import as_completed
import multiprocessing as mp
import threading
import yaml

# æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from unified_parallel_processing_system import (
        ParallelProcessingOptimizer,
        get_optimizer,
        start_performance_monitoring,
        parallel_execute_unified,
        parallel_map_unified,
    )
except ImportError:
    print(
        "ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚parallel_processing_optimizer.pyã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
    )
    sys.exit(1)

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class EnhancedParallelSystem:
    """çµ±åˆä¸¦åˆ—å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, config_path: str = "config_final.yaml"):
        """
        åˆæœŸåŒ–

        Args:
            config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        self.config_path = config_path
        self.config = self._load_config()
        self.optimizer = get_optimizer()
        self.monitoring_active = False

        logger.info("ğŸš€ çµ±åˆä¸¦åˆ—å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")

    def _load_config(self) -> Dict[str, Any]:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        try:
            with open(self.config_path, "r", encoding="utf-8") as f:
                return yaml.safe_load(f)
        except Exception as e:
            logger.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    def start_monitoring(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã‚’é–‹å§‹"""
        if not self.monitoring_active:
            start_performance_monitoring()
            self.monitoring_active = True
            logger.info("ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–é–‹å§‹")

    def optimize_data_processing(
        self,
        data_chunks: List[Any],
        processing_func: Callable,
        task_type: str = "mixed",
    ) -> List[Any]:
        """
        ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®ä¸¦åˆ—æœ€é©åŒ–

        Args:
            data_chunks: å‡¦ç†ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒãƒ£ãƒ³ã‚¯ã®ãƒªã‚¹ãƒˆ
            processing_func: å‡¦ç†é–¢æ•°
            task_type: ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—

        Returns:
            å‡¦ç†çµæœã®ãƒªã‚¹ãƒˆ
        """
        logger.info(f"ğŸ”„ ãƒ‡ãƒ¼ã‚¿å‡¦ç†ä¸¦åˆ—æœ€é©åŒ–é–‹å§‹")
        logger.info(f"   - ãƒãƒ£ãƒ³ã‚¯æ•°: {len(data_chunks)}")
        logger.info(f"   - ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—: {task_type}")

        # ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆ
        tasks = [lambda chunk=chunk: processing_func(chunk) for chunk in data_chunks]

        # ä¸¦åˆ—å®Ÿè¡Œ
        results = parallel_execute_unified(tasks, task_type)

        logger.info(f"âœ… ãƒ‡ãƒ¼ã‚¿å‡¦ç†ä¸¦åˆ—æœ€é©åŒ–å®Œäº†")
        return results

    def optimize_model_training(
        self,
        models_config: List[Dict[str, Any]],
        training_func: Callable,
        task_type: str = "cpu_intensive",
    ) -> List[Any]:
        """
        ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã®ä¸¦åˆ—æœ€é©åŒ–

        Args:
            models_config: ãƒ¢ãƒ‡ãƒ«è¨­å®šã®ãƒªã‚¹ãƒˆ
            training_func: è¨“ç·´é–¢æ•°
            task_type: ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—

        Returns:
            è¨“ç·´çµæœã®ãƒªã‚¹ãƒˆ
        """
        logger.info(f"ğŸ¤– ãƒ¢ãƒ‡ãƒ«è¨“ç·´ä¸¦åˆ—æœ€é©åŒ–é–‹å§‹")
        logger.info(f"   - ãƒ¢ãƒ‡ãƒ«æ•°: {len(models_config)}")
        logger.info(f"   - ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—: {task_type}")

        # ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆ
        tasks = [
            lambda config=config: training_func(config) for config in models_config
        ]

        # ä¸¦åˆ—å®Ÿè¡Œ
        results = parallel_execute_unified(tasks, task_type)

        logger.info(f"âœ… ãƒ¢ãƒ‡ãƒ«è¨“ç·´ä¸¦åˆ—æœ€é©åŒ–å®Œäº†")
        return results

    def optimize_backtesting(
        self,
        strategies: List[Dict[str, Any]],
        backtest_func: Callable,
        task_type: str = "mixed",
    ) -> List[Any]:
        """
        ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã®ä¸¦åˆ—æœ€é©åŒ–

        Args:
            strategies: æˆ¦ç•¥è¨­å®šã®ãƒªã‚¹ãƒˆ
            backtest_func: ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆé–¢æ•°
            task_type: ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—

        Returns:
            ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã®ãƒªã‚¹ãƒˆ
        """
        logger.info(f"ğŸ“Š ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆä¸¦åˆ—æœ€é©åŒ–é–‹å§‹")
        logger.info(f"   - æˆ¦ç•¥æ•°: {len(strategies)}")
        logger.info(f"   - ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—: {task_type}")

        # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚¿ã‚¹ã‚¯ã‚’ä½œæˆ
        tasks = [
            lambda strategy=strategy: backtest_func(strategy) for strategy in strategies
        ]

        # ä¸¦åˆ—å®Ÿè¡Œ
        results = parallel_execute_unified(tasks, task_type)

        logger.info(f"âœ… ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆä¸¦åˆ—æœ€é©åŒ–å®Œäº†")
        return results

    def optimize_sentiment_analysis(
        self,
        text_data: List[str],
        analysis_func: Callable,
        task_type: str = "io_intensive",
    ) -> List[Any]:
        """
        æ„Ÿæƒ…åˆ†æã®ä¸¦åˆ—æœ€é©åŒ–

        Args:
            text_data: åˆ†æã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
            analysis_func: åˆ†æé–¢æ•°
            task_type: ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—

        Returns:
            åˆ†æçµæœã®ãƒªã‚¹ãƒˆ
        """
        logger.info(f"ğŸ’­ æ„Ÿæƒ…åˆ†æä¸¦åˆ—æœ€é©åŒ–é–‹å§‹")
        logger.info(f"   - ãƒ†ã‚­ã‚¹ãƒˆæ•°: {len(text_data)}")
        logger.info(f"   - ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—: {task_type}")

        # ä¸¦åˆ—ãƒãƒƒãƒ—å®Ÿè¡Œ
        results = parallel_map_unified(analysis_func, text_data, task_type)

        logger.info(f"âœ… æ„Ÿæƒ…åˆ†æä¸¦åˆ—æœ€é©åŒ–å®Œäº†")
        return results

    def optimize_technical_indicators(
        self,
        stock_data: List[Dict[str, Any]],
        indicator_func: Callable,
        task_type: str = "cpu_intensive",
    ) -> List[Any]:
        """
        æŠ€è¡“æŒ‡æ¨™è¨ˆç®—ã®ä¸¦åˆ—æœ€é©åŒ–

        Args:
            stock_data: æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
            indicator_func: æŒ‡æ¨™è¨ˆç®—é–¢æ•°
            task_type: ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—

        Returns:
            æŒ‡æ¨™è¨ˆç®—çµæœã®ãƒªã‚¹ãƒˆ
        """
        logger.info(f"ğŸ“ˆ æŠ€è¡“æŒ‡æ¨™è¨ˆç®—ä¸¦åˆ—æœ€é©åŒ–é–‹å§‹")
        logger.info(f"   - ãƒ‡ãƒ¼ã‚¿æ•°: {len(stock_data)}")
        logger.info(f"   - ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—: {task_type}")

        # ä¸¦åˆ—ãƒãƒƒãƒ—å®Ÿè¡Œ
        results = parallel_map_unified(indicator_func, stock_data, task_type)

        logger.info(f"âœ… æŠ€è¡“æŒ‡æ¨™è¨ˆç®—ä¸¦åˆ—æœ€é©åŒ–å®Œäº†")
        return results

    def get_performance_stats(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã‚’å–å¾—"""
        if not self.monitoring_active:
            return {"error": "ç›£è¦–ãŒé–‹å§‹ã•ã‚Œã¦ã„ã¾ã›ã‚“"}

        optimizer = self.optimizer
        with optimizer.lock:
            if not optimizer.performance_history:
                return {"error": "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“"}

            recent_metrics = optimizer.performance_history[-5:]
            avg_cpu = sum(m.cpu_usage for m in recent_metrics) / len(recent_metrics)
            avg_memory = sum(m.memory_usage for m in recent_metrics) / len(
                recent_metrics
            )

            return {
                "current_workers": optimizer.current_workers,
                "max_workers": optimizer.max_workers,
                "avg_cpu_usage": avg_cpu,
                "avg_memory_usage": avg_memory,
                "auto_adjust": optimizer.auto_adjust,
                "performance_history_count": len(optimizer.performance_history),
            }

    def set_workers(self, workers: int):
        """ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã‚’æ‰‹å‹•è¨­å®š"""
        with self.optimizer.lock:
            old_workers = self.optimizer.current_workers
            self.optimizer.current_workers = max(
                1, min(workers, self.optimizer.max_workers_limit)
            )
            logger.info(
                f"ğŸ”§ ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°æ‰‹å‹•è¨­å®š: {old_workers} â†’ {self.optimizer.current_workers}"
            )

    def enable_auto_adjust(self, enabled: bool = True):
        """è‡ªå‹•èª¿æ•´ã®æœ‰åŠ¹/ç„¡åŠ¹ã‚’è¨­å®š"""
        self.optimizer.auto_adjust = enabled
        logger.info(f"ğŸ”§ è‡ªå‹•èª¿æ•´: {'æœ‰åŠ¹' if enabled else 'ç„¡åŠ¹'}")


# æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆé–¢æ•°
def integrate_parallel_processing():
    """æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã«ä¸¦åˆ—å‡¦ç†ã‚’çµ±åˆ"""
    logger.info("ğŸ”— æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆé–‹å§‹")

    # çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
    enhanced_system = get_unified_system()

    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–é–‹å§‹
    enhanced_system.start_monitoring()

    logger.info("âœ… æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆå®Œäº†")
    return enhanced_system


def optimize_existing_systems():
    """æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã®æœ€é©åŒ–"""
    logger.info("ğŸš€ æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ æœ€é©åŒ–é–‹å§‹")

    # çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã‚’å–å¾—
    enhanced_system = integrate_parallel_processing()

    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æœ€é©åŒ–å¯¾è±¡ã‚’å–å¾—
    config = enhanced_system.config

    # ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®æœ€é©åŒ–
    if "preprocessing" in config:
        logger.info("ğŸ“Š ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®æœ€é©åŒ–")
        # æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã«ä¸¦åˆ—å‡¦ç†ã‚’é©ç”¨

    # ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã®æœ€é©åŒ–
    if "prediction" in config:
        logger.info("ğŸ¤– äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã®æœ€é©åŒ–")
        # æ—¢å­˜ã®äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã«ä¸¦åˆ—å‡¦ç†ã‚’é©ç”¨

    # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã®æœ€é©åŒ–
    if "trading" in config:
        logger.info("ğŸ“ˆ ãƒˆãƒ¬ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®æœ€é©åŒ–")
        # æ—¢å­˜ã®ãƒˆãƒ¬ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã«ä¸¦åˆ—å‡¦ç†ã‚’é©ç”¨

    logger.info("âœ… æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ æœ€é©åŒ–å®Œäº†")
    return enhanced_system


if __name__ == "__main__":
    # çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ
    enhanced_system = optimize_existing_systems()

    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã®è¡¨ç¤º
    stats = enhanced_system.get_performance_stats()
    print(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ: {stats}")

    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    def test_processing(data):
        time.sleep(0.1)
        return f"processed_{data}"

    test_data = [f"data_{i}" for i in range(10)]
    results = enhanced_system.optimize_data_processing(
        test_data, test_processing, "mixed"
    )
    print(f"å‡¦ç†çµæœ: {results}")
