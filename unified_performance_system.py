#!/usr/bin/env python3
"""
çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ 
å…¨ã¦ã®æœ€é©åŒ–æ©Ÿèƒ½ã‚’çµ±åˆã—ã€ä¸€å…ƒç®¡ç†ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ 
"""

import logging
import time
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional, Union
from dataclasses import dataclass
import json
import os
from pathlib import Path

# æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from enhanced_memory_optimizer import (
    EnhancedMemoryOptimizer,
    create_enhanced_memory_optimizer,
)
from enhanced_parallel_processor import EnhancedParallelProcessor, parallel_context
from enhanced_chart_optimizer import EnhancedChartOptimizer, create_chart_optimizer
from performance_integration_test import PerformanceIntegrationTester

logger = logging.getLogger(__name__)


@dataclass
class PerformanceConfig:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨­å®š"""

    memory_limit_mb: int = 1024
    max_data_points: int = 3000
    target_render_time: float = 3.0
    enable_aggressive_optimization: bool = True
    enable_parallel_processing: bool = True
    enable_chart_optimization: bool = True
    enable_memory_optimization: bool = True
    max_workers: int = 8
    quality_level: str = "high"


@dataclass
class OptimizationResult:
    """æœ€é©åŒ–çµæœ"""

    success: bool
    execution_time: float
    memory_usage_mb: float
    memory_reduction_percent: float
    processing_speed_improvement: float
    chart_render_time: float
    data_points: int
    optimizations_applied: List[str]
    metrics: Dict[str, Any]
    error_message: Optional[str] = None


class UnifiedPerformanceSystem:
    """çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, config: Optional[PerformanceConfig] = None):
        self.config = config or PerformanceConfig()

        # æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
        self.memory_optimizer = None
        self.parallel_processor = None
        self.chart_optimizer = None

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å±¥æ­´
        self.optimization_history = []
        self.performance_metrics = {}

        logger.info("ğŸš€ çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
        self._initialize_systems()

    def _initialize_systems(self):
        """æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–"""
        try:
            # ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ 
            if self.config.enable_memory_optimization:
                self.memory_optimizer = create_enhanced_memory_optimizer(
                    memory_limit_mb=self.config.memory_limit_mb,
                    aggressive_mode=self.config.enable_aggressive_optimization,
                )
                logger.info("âœ… ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")

            # ä¸¦åˆ—å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ 
            if self.config.enable_parallel_processing:
                self.parallel_processor = EnhancedParallelProcessor(
                    max_workers=self.config.max_workers, adaptive_mode=True
                )
                logger.info("âœ… ä¸¦åˆ—å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")

            # ãƒãƒ£ãƒ¼ãƒˆæœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ 
            if self.config.enable_chart_optimization:
                self.chart_optimizer = create_chart_optimizer(
                    max_data_points=self.config.max_data_points,
                    target_render_time=self.config.target_render_time,
                    quality_level=self.config.quality_level,
                )
                logger.info("âœ… ãƒãƒ£ãƒ¼ãƒˆæœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")

        except Exception as e:
            logger.error(f"ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def optimize_data_processing(
        self,
        data: pd.DataFrame,
        operations: List[str] = None,
        chart_type: str = "candlestick",
    ) -> OptimizationResult:
        """ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®çµ±åˆæœ€é©åŒ–"""
        start_time = time.time()
        start_memory = self._get_memory_usage()

        logger.info(f"ğŸš€ çµ±åˆãƒ‡ãƒ¼ã‚¿å‡¦ç†æœ€é©åŒ–é–‹å§‹")
        logger.info(f"   - ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(data)}è¡Œ")
        logger.info(f"   - æ“ä½œ: {operations or ['all']}")

        optimizations_applied = []
        optimized_data = data.copy()

        try:
            # 1. ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–
            if self.config.enable_memory_optimization and self.memory_optimizer:
                with self.memory_optimizer.memory_monitoring("memory_optimization"):
                    optimized_data = (
                        self.memory_optimizer.optimize_dataframe_aggressive(
                            optimized_data
                        )
                    )
                    optimizations_applied.append("memory_optimization")
                    logger.info("âœ… ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–å®Œäº†")

            # 2. ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–
            if self.config.enable_parallel_processing and self.parallel_processor:
                with parallel_context(max_workers=self.config.max_workers) as processor:
                    # ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¦ä¸¦åˆ—å‡¦ç†
                    chunk_size = max(
                        1000, len(optimized_data) // self.config.max_workers
                    )
                    chunks = [
                        optimized_data.iloc[i : i + chunk_size]
                        for i in range(0, len(optimized_data), chunk_size)
                    ]

                    processed_chunks = processor.parallel_map_optimized(
                        self._process_data_chunk, chunks, task_type="mixed"
                    )

                    optimized_data = pd.concat(processed_chunks, ignore_index=True)
                    optimizations_applied.append("parallel_processing")
                    logger.info("âœ… ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–å®Œäº†")

            # 3. ãƒãƒ£ãƒ¼ãƒˆæœ€é©åŒ–
            chart_render_time = 0
            if self.config.enable_chart_optimization and self.chart_optimizer:
                chart_result = self.chart_optimizer.optimize_chart_rendering(
                    optimized_data, chart_type=chart_type, title="æœ€é©åŒ–ã•ã‚ŒãŸãƒãƒ£ãƒ¼ãƒˆ"
                )
                chart_render_time = chart_result["render_time"]
                optimizations_applied.append("chart_optimization")
                logger.info("âœ… ãƒãƒ£ãƒ¼ãƒˆæœ€é©åŒ–å®Œäº†")

            # çµæœã®è¨ˆç®—
            end_time = time.time()
            end_memory = self._get_memory_usage()

            execution_time = end_time - start_time
            memory_usage = end_memory - start_memory
            memory_reduction = self._calculate_memory_reduction(
                start_memory, end_memory
            )
            speed_improvement = self._calculate_speed_improvement(
                execution_time, len(data)
            )

            result = OptimizationResult(
                success=True,
                execution_time=execution_time,
                memory_usage_mb=memory_usage,
                memory_reduction_percent=memory_reduction,
                processing_speed_improvement=speed_improvement,
                chart_render_time=chart_render_time,
                data_points=len(optimized_data),
                optimizations_applied=optimizations_applied,
                metrics={
                    "original_data_size": len(data),
                    "optimized_data_size": len(optimized_data),
                    "compression_ratio": len(optimized_data) / len(data),
                    "target_achieved": chart_render_time
                    <= self.config.target_render_time,
                },
            )

            # å±¥æ­´ã«è¨˜éŒ²
            self.optimization_history.append(
                {"timestamp": time.time(), "result": result, "config": self.config}
            )

            logger.info("âœ… çµ±åˆãƒ‡ãƒ¼ã‚¿å‡¦ç†æœ€é©åŒ–å®Œäº†")
            logger.info(f"   - å®Ÿè¡Œæ™‚é–“: {execution_time:.2f}ç§’")
            logger.info(f"   - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {memory_usage:.1f}MB")
            logger.info(f"   - ãƒ¡ãƒ¢ãƒªå‰Šæ¸›: {memory_reduction:.1f}%")
            logger.info(f"   - å‡¦ç†é€Ÿåº¦å‘ä¸Š: {speed_improvement:.1f}å€")
            logger.info(f"   - ãƒãƒ£ãƒ¼ãƒˆæç”»: {chart_render_time:.2f}ç§’")

            return result

        except Exception as e:
            logger.error(f"çµ±åˆæœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return OptimizationResult(
                success=False,
                execution_time=time.time() - start_time,
                memory_usage_mb=0,
                memory_reduction_percent=0,
                processing_speed_improvement=1,
                chart_render_time=0,
                data_points=0,
                optimizations_applied=[],
                metrics={},
                error_message=str(e),
            )

    def _process_data_chunk(self, chunk: pd.DataFrame) -> pd.DataFrame:
        """ãƒ‡ãƒ¼ã‚¿ãƒãƒ£ãƒ³ã‚¯ã®å‡¦ç†"""
        # åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿å‡¦ç†
        processed_chunk = chunk.copy()

        # æ¬ æå€¤ã®å‡¦ç†
        processed_chunk = processed_chunk.dropna()

        # ãƒ‡ãƒ¼ã‚¿å‹ã®æœ€é©åŒ–
        for col in processed_chunk.columns:
            if processed_chunk[col].dtype == "float64":
                processed_chunk[col] = processed_chunk[col].astype("float32")
            elif processed_chunk[col].dtype == "int64":
                processed_chunk[col] = processed_chunk[col].astype("int32")

        return processed_chunk

    def _get_memory_usage(self) -> float:
        """ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å–å¾—ï¼ˆMBï¼‰"""
        import psutil

        return psutil.Process().memory_info().rss / 1024 / 1024

    def _calculate_memory_reduction(
        self, start_memory: float, end_memory: float
    ) -> float:
        """ãƒ¡ãƒ¢ãƒªå‰Šæ¸›ç‡ã‚’è¨ˆç®—"""
        if start_memory > 0:
            return max(0, (start_memory - end_memory) / start_memory * 100)
        return 0

    def _calculate_speed_improvement(
        self, execution_time: float, data_size: int
    ) -> float:
        """å‡¦ç†é€Ÿåº¦å‘ä¸Šç‡ã‚’è¨ˆç®—"""
        if execution_time > 0:
            return data_size / execution_time
        return 1

    def run_performance_test(self, test_data_size: int = 50000) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ"""
        logger.info(f"ğŸ§ª ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆé–‹å§‹: {test_data_size}è¡Œ")

        try:
            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
            test_data = self._generate_test_data(test_data_size)

            # çµ±åˆæœ€é©åŒ–ã®å®Ÿè¡Œ
            result = self.optimize_data_processing(test_data)

            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨˜éŒ²
            self.performance_metrics = {
                "test_data_size": test_data_size,
                "execution_time": result.execution_time,
                "memory_usage": result.memory_usage_mb,
                "memory_reduction": result.memory_reduction_percent,
                "speed_improvement": result.processing_speed_improvement,
                "chart_render_time": result.chart_render_time,
                "success": result.success,
                "optimizations_applied": result.optimizations_applied,
            }

            logger.info("âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Œäº†")
            return self.performance_metrics

        except Exception as e:
            logger.error(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    def _generate_test_data(self, size: int) -> pd.DataFrame:
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ"""
        np.random.seed(42)
        dates = pd.date_range("2020-01-01", periods=size, freq="D")

        base_price = 1000 + np.cumsum(np.random.randn(size) * 0.02) * 1000

        data = pd.DataFrame(
            {
                "Date": dates,
                "Open": base_price,
                "High": base_price * (1 + np.random.uniform(0, 0.05, size)),
                "Low": base_price * (1 - np.random.uniform(0, 0.05, size)),
                "Close": base_price + np.random.uniform(-20, 20, size),
                "Volume": np.random.randint(1000000, 10000000, size),
                "SMA_5": base_price.rolling(window=5).mean(),
                "SMA_20": base_price.rolling(window=20).mean(),
                "SMA_50": base_price.rolling(window=50).mean(),
                "RSI": np.random.uniform(0, 100, size),
                "MACD": np.random.uniform(-10, 10, size),
                "BB_Upper": base_price * 1.02,
                "BB_Lower": base_price * 0.98,
                "ATR": np.random.uniform(1, 10, size),
            }
        )

        return data

    def get_performance_report(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        if not self.optimization_history:
            return {"message": "æœ€é©åŒ–å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“"}

        # æœ€æ–°ã®çµæœã‚’å–å¾—
        latest_result = self.optimization_history[-1]["result"]

        # çµ±è¨ˆæƒ…å ±ã®è¨ˆç®—
        total_optimizations = len(self.optimization_history)
        successful_optimizations = sum(
            1 for h in self.optimization_history if h["result"].success
        )
        success_rate = (
            (successful_optimizations / total_optimizations * 100)
            if total_optimizations > 0
            else 0
        )

        avg_execution_time = np.mean(
            [h["result"].execution_time for h in self.optimization_history]
        )
        avg_memory_reduction = np.mean(
            [h["result"].memory_reduction_percent for h in self.optimization_history]
        )
        avg_speed_improvement = np.mean(
            [
                h["result"].processing_speed_improvement
                for h in self.optimization_history
            ]
        )

        return {
            "system_status": {
                "memory_optimizer": self.memory_optimizer is not None,
                "parallel_processor": self.parallel_processor is not None,
                "chart_optimizer": self.chart_optimizer is not None,
            },
            "performance_metrics": self.performance_metrics,
            "optimization_history": {
                "total_optimizations": total_optimizations,
                "successful_optimizations": successful_optimizations,
                "success_rate": success_rate,
                "avg_execution_time": avg_execution_time,
                "avg_memory_reduction": avg_memory_reduction,
                "avg_speed_improvement": avg_speed_improvement,
            },
            "latest_result": {
                "success": latest_result.success,
                "execution_time": latest_result.execution_time,
                "memory_usage_mb": latest_result.memory_usage_mb,
                "memory_reduction_percent": latest_result.memory_reduction_percent,
                "processing_speed_improvement": latest_result.processing_speed_improvement,
                "chart_render_time": latest_result.chart_render_time,
                "data_points": latest_result.data_points,
                "optimizations_applied": latest_result.optimizations_applied,
            },
            "dod_validation": self._validate_dod(latest_result),
            "recommendations": self._generate_recommendations(),
        }

    def _validate_dod(self, result: OptimizationResult) -> Dict[str, bool]:
        """DoDï¼ˆå—ã‘å…¥ã‚ŒåŸºæº–ï¼‰ã®æ¤œè¨¼"""
        return {
            "memory_reduction_30_percent": result.memory_reduction_percent >= 30,
            "processing_speed_2x": result.processing_speed_improvement >= 2.0,
            "chart_render_3_seconds": result.chart_render_time <= 3.0,
            "overall_success": (
                result.memory_reduction_percent >= 30
                and result.processing_speed_improvement >= 2.0
                and result.chart_render_time <= 3.0
            ),
        }

    def _generate_recommendations(self) -> List[str]:
        """æ¨å¥¨äº‹é …ã®ç”Ÿæˆ"""
        recommendations = []

        if not self.optimization_history:
            return recommendations

        latest_result = self.optimization_history[-1]["result"]

        if latest_result.memory_reduction_percent < 30:
            recommendations.append(
                "ãƒ¡ãƒ¢ãƒªå‰Šæ¸›ãŒ30%æœªæº€ã§ã™ã€‚ã‚ˆã‚Šç©æ¥µçš„ãªãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã‚’æ¨å¥¨ã—ã¾ã™ã€‚"
            )

        if latest_result.processing_speed_improvement < 2.0:
            recommendations.append(
                "å‡¦ç†é€Ÿåº¦å‘ä¸ŠãŒ2å€æœªæº€ã§ã™ã€‚ä¸¦åˆ—å‡¦ç†ã®æœ€é©åŒ–ã‚’æ¨å¥¨ã—ã¾ã™ã€‚"
            )

        if latest_result.chart_render_time > 3.0:
            recommendations.append(
                "ãƒãƒ£ãƒ¼ãƒˆæç”»ãŒ3ç§’ã‚’è¶…ãˆã¦ã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’æ¨å¥¨ã—ã¾ã™ã€‚"
            )

        if not latest_result.success:
            recommendations.append(
                "æœ€é©åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            )

        return recommendations

    def cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if self.memory_optimizer:
            self.memory_optimizer.cleanup()

        if self.parallel_processor:
            self.parallel_processor.cleanup()

        if self.chart_optimizer:
            self.chart_optimizer.cleanup()

        self.optimization_history.clear()
        self.performance_metrics.clear()

        logger.info("ğŸ§¹ çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚·ã‚¹ãƒ†ãƒ ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã¾ã—ãŸ")


def create_unified_performance_system(
    memory_limit_mb: int = 1024,
    max_data_points: int = 3000,
    target_render_time: float = 3.0,
    enable_aggressive_optimization: bool = True,
) -> UnifiedPerformanceSystem:
    """çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œæˆ"""
    config = PerformanceConfig(
        memory_limit_mb=memory_limit_mb,
        max_data_points=max_data_points,
        target_render_time=target_render_time,
        enable_aggressive_optimization=enable_aggressive_optimization,
    )
    return UnifiedPerformanceSystem(config)


if __name__ == "__main__":
    # ãƒ­ã‚°è¨­å®š
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    )

    # çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ
    system = create_unified_performance_system()

    try:
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
        test_results = system.run_performance_test(test_data_size=30000)

        # ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
        report = system.get_performance_report()

        # çµæœã®è¡¨ç¤º
        print("\n" + "=" * 80)
        print("ğŸš€ çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ çµæœ")
        print("=" * 80)

        print(f"ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹:")
        print(f"   - å®Ÿè¡Œæ™‚é–“: {test_results.get('execution_time', 0):.2f}ç§’")
        print(f"   - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {test_results.get('memory_usage', 0):.1f}MB")
        print(f"   - ãƒ¡ãƒ¢ãƒªå‰Šæ¸›: {test_results.get('memory_reduction', 0):.1f}%")
        print(f"   - å‡¦ç†é€Ÿåº¦å‘ä¸Š: {test_results.get('speed_improvement', 1):.1f}å€")
        print(f"   - ãƒãƒ£ãƒ¼ãƒˆæç”»: {test_results.get('chart_render_time', 0):.2f}ç§’")

        dod_validation = report.get("dod_validation", {})
        print(f"\nğŸ¯ DoDæ¤œè¨¼çµæœ:")
        print(
            f"   - ãƒ¡ãƒ¢ãƒªå‰Šæ¸›30%ä»¥ä¸Š: {'âœ…' if dod_validation.get('memory_reduction_30_percent', False) else 'âŒ'}"
        )
        print(
            f"   - å‡¦ç†é€Ÿåº¦2å€ä»¥ä¸Š: {'âœ…' if dod_validation.get('processing_speed_2x', False) else 'âŒ'}"
        )
        print(
            f"   - ãƒãƒ£ãƒ¼ãƒˆæç”»3ç§’ä»¥å†…: {'âœ…' if dod_validation.get('chart_render_3_seconds', False) else 'âŒ'}"
        )
        print(
            f"   - ç·åˆåˆ¤å®š: {'âœ… æˆåŠŸ' if dod_validation.get('overall_success', False) else 'âŒ å¤±æ•—'}"
        )

        recommendations = report.get("recommendations", [])
        if recommendations:
            print(f"\nğŸ’¡ æ¨å¥¨äº‹é …:")
            for i, rec in enumerate(recommendations, 1):
                print(f"   {i}. {rec}")

        print("\n" + "=" * 80)
        print("âœ… çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ å®Œäº†")
        print("=" * 80)

    except Exception as e:
        logger.error(f"ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")

    finally:
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        system.cleanup()
