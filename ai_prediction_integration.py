#!/usr/bin/env python3
"""
AIäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«çµ±åˆã‚·ã‚¹ãƒ†ãƒ 
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è‡ªå‹•å£²è²·ã‚·ã‚¹ãƒ†ãƒ ã®è¿½åŠ æ¨å¥¨æ©Ÿèƒ½

æœŸå¾…åŠ¹æœ: æœˆé–“15-25%ã®åˆ©ç›Šå‘ä¸Š
å®Ÿè£…é›£æ˜“åº¦: ğŸŸ¡ Medium
æ¨å®šå·¥æ•°: 2-3æ—¥

ä¸»è¦æ©Ÿèƒ½:
1. æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬
2. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ã«ã‚ˆã‚‹ç²¾åº¦å‘ä¸Š
3. äºˆæ¸¬ä¿¡é ¼åº¦ã®å‹•çš„èª¿æ•´
4. ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®ç¶™ç¶šç›£è¦–
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Union
import json
import logging
from dataclasses import dataclass, asdict
from enum import Enum
import warnings
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.svm import SVR
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
import joblib
import threading
import time
from concurrent.futures import ThreadPoolExecutor
import asyncio

warnings.filterwarnings("ignore")

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[logging.FileHandler("ai_prediction.log"), logging.StreamHandler()],
)
logger = logging.getLogger(__name__)


class ModelType(Enum):
    """äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—"""

    RANDOM_FOREST = "random_forest"
    GRADIENT_BOOSTING = "gradient_boosting"
    LINEAR_REGRESSION = "linear_regression"
    RIDGE_REGRESSION = "ridge_regression"
    SVM = "svm"
    NEURAL_NETWORK = "neural_network"
    ENSEMBLE = "ensemble"


class PredictionConfidence(Enum):
    """äºˆæ¸¬ä¿¡é ¼åº¦"""

    VERY_LOW = "very_low"  # 0-0.2
    LOW = "low"  # 0.2-0.4
    MEDIUM = "medium"  # 0.4-0.6
    HIGH = "high"  # 0.6-0.8
    VERY_HIGH = "very_high"  # 0.8-1.0


@dataclass
class PredictionResult:
    """äºˆæ¸¬çµæœã‚¯ãƒ©ã‚¹"""

    symbol: str
    predicted_price: float
    confidence: float
    confidence_level: PredictionConfidence
    model_type: ModelType
    prediction_horizon: int  # äºˆæ¸¬æœŸé–“ï¼ˆåˆ†ï¼‰
    features_used: List[str]
    prediction_time: datetime
    actual_price: Optional[float] = None
    prediction_error: Optional[float] = None


@dataclass
class ModelPerformance:
    """ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã‚¯ãƒ©ã‚¹"""

    model_type: ModelType
    accuracy: float
    mse: float
    r2_score: float
    last_updated: datetime
    prediction_count: int
    success_rate: float


@dataclass
class EnsemblePrediction:
    """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ã‚¯ãƒ©ã‚¹"""

    symbol: str
    predictions: List[PredictionResult]
    weighted_prediction: float
    ensemble_confidence: float
    best_model: ModelType
    prediction_time: datetime


class AIModelFactory:
    """AIãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.performance_tracker = {}

    def create_model(self, model_type: ModelType, **kwargs):
        """ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ"""
        if model_type == ModelType.RANDOM_FOREST:
            return RandomForestRegressor(
                n_estimators=kwargs.get("n_estimators", 100),
                max_depth=kwargs.get("max_depth", 10),
                random_state=42,
            )
        elif model_type == ModelType.GRADIENT_BOOSTING:
            return GradientBoostingRegressor(
                n_estimators=kwargs.get("n_estimators", 100),
                learning_rate=kwargs.get("learning_rate", 0.1),
                max_depth=kwargs.get("max_depth", 6),
                random_state=42,
            )
        elif model_type == ModelType.LINEAR_REGRESSION:
            return LinearRegression()
        elif model_type == ModelType.RIDGE_REGRESSION:
            return Ridge(alpha=kwargs.get("alpha", 1.0))
        elif model_type == ModelType.SVM:
            return SVR(
                kernel=kwargs.get("kernel", "rbf"),
                C=kwargs.get("C", 1.0),
                gamma=kwargs.get("gamma", "scale"),
            )
        elif model_type == ModelType.NEURAL_NETWORK:
            return MLPRegressor(
                hidden_layer_sizes=kwargs.get("hidden_layer_sizes", (100, 50)),
                max_iter=kwargs.get("max_iter", 1000),
                random_state=42,
            )
        else:
            raise ValueError(f"æœªå¯¾å¿œã®ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—: {model_type}")

    def get_scaler(self, model_type: ModelType):
        """ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚’å–å¾—"""
        if model_type not in self.scalers:
            self.scalers[model_type] = StandardScaler()
        return self.scalers[model_type]


class PredictionEngine:
    """äºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³ã‚¯ãƒ©ã‚¹"""

    def __init__(self, symbols: List[str]):
        self.symbols = symbols
        self.model_factory = AIModelFactory()
        self.models = {}
        self.performance_tracker = {}
        self.prediction_history = []

        # å„éŠ˜æŸ„ã®ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–
        for symbol in symbols:
            self._initialize_models_for_symbol(symbol)

    def _initialize_models_for_symbol(self, symbol: str):
        """éŠ˜æŸ„ã®ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–"""
        self.models[symbol] = {}
        self.performance_tracker[symbol] = {}

        # å„ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
        for model_type in ModelType:
            if model_type != ModelType.ENSEMBLE:
                self.models[symbol][model_type] = self.model_factory.create_model(
                    model_type
                )
                self.performance_tracker[symbol][model_type] = ModelPerformance(
                    model_type=model_type,
                    accuracy=0.0,
                    mse=0.0,
                    r2_score=0.0,
                    last_updated=datetime.now(),
                    prediction_count=0,
                    success_rate=0.0,
                )

    def prepare_features(
        self, data: pd.DataFrame, symbol: str
    ) -> Tuple[np.ndarray, List[str]]:
        """ç‰¹å¾´é‡ã‚’æº–å‚™"""
        features = []
        feature_names = []

        # ä¾¡æ ¼ç‰¹å¾´é‡
        if "close" in data.columns:
            features.append(data["close"].values)
            feature_names.append("close")

        # æŠ€è¡“æŒ‡æ¨™
        if "rsi" in data.columns:
            features.append(data["rsi"].values)
            feature_names.append("rsi")

        if "macd" in data.columns:
            features.append(data["macd"].values)
            feature_names.append("macd")

        if "bb_upper" in data.columns and "bb_lower" in data.columns:
            bb_position = (data["close"] - data["bb_lower"]) / (
                data["bb_upper"] - data["bb_lower"]
            )
            features.append(bb_position.values)
            feature_names.append("bb_position")

        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
        if "volume" in data.columns:
            features.append(data["volume"].values)
            feature_names.append("volume")

        # ä¾¡æ ¼å¤‰åŒ–ç‡
        if "close" in data.columns:
            price_change = data["close"].pct_change().fillna(0)
            features.append(price_change.values)
            feature_names.append("price_change")

        # ç§»å‹•å¹³å‡
        if "close" in data.columns:
            ma_5 = data["close"].rolling(5).mean()
            ma_20 = data["close"].rolling(20).mean()
            ma_ratio = (data["close"] / ma_20).fillna(1)
            features.append(ma_ratio.values)
            feature_names.append("ma_ratio")

        # ç‰¹å¾´é‡ã‚’çµåˆ
        if features:
            X = np.column_stack(features)
            return X, feature_names
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç‰¹å¾´é‡ï¼ˆä¾¡æ ¼ã®ã¿ï¼‰
            if "close" in data.columns:
                return data["close"].values.reshape(-1, 1), ["close"]
            else:
                raise ValueError("æœ‰åŠ¹ãªç‰¹å¾´é‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    def train_model(
        self, symbol: str, model_type: ModelType, X: np.ndarray, y: np.ndarray
    ):
        """ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´"""
        try:
            model = self.models[symbol][model_type]
            scaler = self.model_factory.get_scaler(model_type)

            # ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
            X_scaled = scaler.fit_transform(X)

            # ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
            model.fit(X_scaled, y)

            # æ€§èƒ½ã‚’è©•ä¾¡
            y_pred = model.predict(X_scaled)
            mse = mean_squared_error(y, y_pred)
            r2 = r2_score(y, y_pred)

            # æ€§èƒ½ã‚’æ›´æ–°
            self.performance_tracker[symbol][model_type].accuracy = 1 - mse / np.var(y)
            self.performance_tracker[symbol][model_type].mse = mse
            self.performance_tracker[symbol][model_type].r2_score = r2
            self.performance_tracker[symbol][model_type].last_updated = datetime.now()

            logger.info(f"ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº†: {symbol} - {model_type.value} - R2: {r2:.4f}")

        except Exception as e:
            logger.error(f"ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã‚¨ãƒ©ãƒ¼: {symbol} - {model_type.value} - {e}")

    def predict(
        self, symbol: str, model_type: ModelType, X: np.ndarray
    ) -> PredictionResult:
        """äºˆæ¸¬ã‚’å®Ÿè¡Œ"""
        try:
            model = self.models[symbol][model_type]
            scaler = self.model_factory.get_scaler(model_type)

            # ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
            X_scaled = scaler.transform(X)

            # äºˆæ¸¬ã‚’å®Ÿè¡Œ
            prediction = model.predict(X_scaled.reshape(1, -1))[0]

            # ä¿¡é ¼åº¦ã‚’è¨ˆç®—ï¼ˆãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã«åŸºã¥ãï¼‰
            performance = self.performance_tracker[symbol][model_type]
            confidence = min(0.95, max(0.05, performance.r2_score))

            # ä¿¡é ¼åº¦ãƒ¬ãƒ™ãƒ«ã‚’æ±ºå®š
            if confidence >= 0.8:
                confidence_level = PredictionConfidence.VERY_HIGH
            elif confidence >= 0.6:
                confidence_level = PredictionConfidence.HIGH
            elif confidence >= 0.4:
                confidence_level = PredictionConfidence.MEDIUM
            elif confidence >= 0.2:
                confidence_level = PredictionConfidence.LOW
            else:
                confidence_level = PredictionConfidence.VERY_LOW

            # äºˆæ¸¬çµæœã‚’ä½œæˆ
            result = PredictionResult(
                symbol=symbol,
                predicted_price=prediction,
                confidence=confidence,
                confidence_level=confidence_level,
                model_type=model_type,
                prediction_horizon=5,  # 5åˆ†å…ˆã‚’äºˆæ¸¬
                features_used=[f"feature_{i}" for i in range(X.shape[1])],
                prediction_time=datetime.now(),
            )

            # äºˆæ¸¬å±¥æ­´ã«è¿½åŠ 
            self.prediction_history.append(result)

            # æ€§èƒ½ã‚’æ›´æ–°
            self.performance_tracker[symbol][model_type].prediction_count += 1

            return result

        except Exception as e:
            logger.error(f"äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {symbol} - {model_type.value} - {e}")
            return None

    def ensemble_predict(self, symbol: str, X: np.ndarray) -> EnsemblePrediction:
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ã‚’å®Ÿè¡Œ"""
        predictions = []
        weights = []

        # å„ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬
        for model_type in ModelType:
            if model_type != ModelType.ENSEMBLE:
                prediction = self.predict(symbol, model_type, X)
                if prediction:
                    predictions.append(prediction)
                    # é‡ã¿ã¯ä¿¡é ¼åº¦ã«åŸºã¥ã
                    weights.append(prediction.confidence)

        if not predictions:
            return None

        # é‡ã¿ã‚’æ­£è¦åŒ–
        total_weight = sum(weights)
        if total_weight > 0:
            weights = [w / total_weight for w in weights]
        else:
            weights = [1.0 / len(predictions)] * len(predictions)

        # é‡ã¿ä»˜ãå¹³å‡ã‚’è¨ˆç®—
        weighted_prediction = sum(
            p * w for p, w in zip([p.predicted_price for p in predictions], weights)
        )

        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ä¿¡é ¼åº¦ã‚’è¨ˆç®—
        ensemble_confidence = sum(
            c * w for c, w in zip([p.confidence for p in predictions], weights)
        )

        # æœ€è‰¯ã®ãƒ¢ãƒ‡ãƒ«ã‚’ç‰¹å®š
        best_model = max(predictions, key=lambda p: p.confidence).model_type

        return EnsemblePrediction(
            symbol=symbol,
            predictions=predictions,
            weighted_prediction=weighted_prediction,
            ensemble_confidence=ensemble_confidence,
            best_model=best_model,
            prediction_time=datetime.now(),
        )


class ModelPerformanceMonitor:
    """ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ç›£è¦–ã‚¯ãƒ©ã‚¹"""

    def __init__(self, prediction_engine: PredictionEngine):
        self.prediction_engine = prediction_engine
        self.monitoring_active = False
        self.monitor_thread = None

    def start_monitoring(self):
        """ç›£è¦–ã‚’é–‹å§‹"""
        if not self.monitoring_active:
            self.monitoring_active = True
            self.monitor_thread = threading.Thread(target=self._monitor_loop)
            self.monitor_thread.daemon = True
            self.monitor_thread.start()
            logger.info("ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ç›£è¦–ã‚’é–‹å§‹ã—ã¾ã—ãŸ")

    def stop_monitoring(self):
        """ç›£è¦–ã‚’åœæ­¢"""
        self.monitoring_active = False
        if self.monitor_thread:
            self.monitor_thread.join()
        logger.info("ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ç›£è¦–ã‚’åœæ­¢ã—ã¾ã—ãŸ")

    def _monitor_loop(self):
        """ç›£è¦–ãƒ«ãƒ¼ãƒ—"""
        while self.monitoring_active:
            try:
                self._update_performance_metrics()
                time.sleep(60)  # 1åˆ†ã”ã¨ã«æ›´æ–°
            except Exception as e:
                logger.error(f"ç›£è¦–ãƒ«ãƒ¼ãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
                time.sleep(10)

    def _update_performance_metrics(self):
        """æ€§èƒ½æŒ‡æ¨™ã‚’æ›´æ–°"""
        for symbol in self.prediction_engine.symbols:
            for model_type in ModelType:
                if model_type != ModelType.ENSEMBLE:
                    # æœ€è¿‘ã®äºˆæ¸¬çµæœã‚’å–å¾—
                    recent_predictions = [
                        p
                        for p in self.prediction_engine.prediction_history
                        if p.symbol == symbol
                        and p.model_type == model_type
                        and (datetime.now() - p.prediction_time).seconds < 3600  # 1æ™‚é–“ä»¥å†…
                    ]

                    if recent_predictions:
                        # å®Ÿéš›ã®ä¾¡æ ¼ã¨æ¯”è¼ƒã—ã¦æ€§èƒ½ã‚’è¨ˆç®—
                        # ã“ã“ã§ã¯ç°¡ç•¥åŒ–ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯å®Ÿéš›ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ï¼‰
                        success_count = sum(
                            1 for p in recent_predictions if p.actual_price is not None
                        )
                        if success_count > 0:
                            self.prediction_engine.performance_tracker[symbol][
                                model_type
                            ].success_rate = success_count / len(recent_predictions)

    def get_performance_report(self) -> Dict:
        """æ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆã‚’å–å¾—"""
        report = {}

        for symbol in self.prediction_engine.symbols:
            report[symbol] = {}
            for model_type in ModelType:
                if model_type != ModelType.ENSEMBLE:
                    performance = self.prediction_engine.performance_tracker[symbol][
                        model_type
                    ]
                    report[symbol][model_type.value] = {
                        "accuracy": performance.accuracy,
                        "mse": performance.mse,
                        "r2_score": performance.r2_score,
                        "prediction_count": performance.prediction_count,
                        "success_rate": performance.success_rate,
                        "last_updated": performance.last_updated.isoformat(),
                    }

        return report


class AIPredictionIntegrationSystem:
    """AIäºˆæ¸¬çµ±åˆã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, symbols: List[str]):
        self.symbols = symbols
        self.prediction_engine = PredictionEngine(symbols)
        self.performance_monitor = ModelPerformanceMonitor(self.prediction_engine)
        self.is_running = False

        logger.info(f"AIäºˆæ¸¬çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ: {symbols}")

    def train_all_models(self, historical_data: Dict[str, pd.DataFrame]):
        """å…¨ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´"""
        logger.info("å…¨ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã‚’é–‹å§‹...")

        for symbol in self.symbols:
            if symbol in historical_data:
                try:
                    data = historical_data[symbol]
                    X, feature_names = self.prediction_engine.prepare_features(
                        data, symbol
                    )

                    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ï¼ˆæ¬¡ã®ä¾¡æ ¼ï¼‰
                    if len(data) > 1:
                        y = data["close"].shift(-1).dropna().values
                        X = X[:-1]  # æœ€å¾Œã®è¡Œã‚’é™¤å¤–

                        # å„ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
                        for model_type in ModelType:
                            if model_type != ModelType.ENSEMBLE:
                                self.prediction_engine.train_model(
                                    symbol, model_type, X, y
                                )

                    logger.info(f"ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº†: {symbol}")

                except Exception as e:
                    logger.error(f"ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã‚¨ãƒ©ãƒ¼: {symbol} - {e}")

        logger.info("å…¨ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ãŒå®Œäº†ã—ã¾ã—ãŸ")

    def get_predictions(
        self, current_data: Dict[str, pd.DataFrame]
    ) -> Dict[str, EnsemblePrediction]:
        """äºˆæ¸¬ã‚’å–å¾—"""
        predictions = {}

        for symbol in self.symbols:
            if symbol in current_data:
                try:
                    data = current_data[symbol]
                    X, _ = self.prediction_engine.prepare_features(data, symbol)

                    # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ã‚’å®Ÿè¡Œ
                    ensemble_prediction = self.prediction_engine.ensemble_predict(
                        symbol, X[-1:]
                    )
                    if ensemble_prediction:
                        predictions[symbol] = ensemble_prediction

                except Exception as e:
                    logger.error(f"äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {symbol} - {e}")

        return predictions

    def start_system(self):
        """ã‚·ã‚¹ãƒ†ãƒ ã‚’é–‹å§‹"""
        if not self.is_running:
            self.is_running = True
            self.performance_monitor.start_monitoring()
            logger.info("AIäºˆæ¸¬çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã‚’é–‹å§‹ã—ã¾ã—ãŸ")

    def stop_system(self):
        """ã‚·ã‚¹ãƒ†ãƒ ã‚’åœæ­¢"""
        if self.is_running:
            self.is_running = False
            self.performance_monitor.stop_monitoring()
            logger.info("AIäºˆæ¸¬çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã‚’åœæ­¢ã—ã¾ã—ãŸ")

    def get_system_status(self) -> Dict:
        """ã‚·ã‚¹ãƒ†ãƒ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—"""
        performance_report = self.performance_monitor.get_performance_report()

        return {
            "system_running": self.is_running,
            "symbols": self.symbols,
            "performance_report": performance_report,
            "total_predictions": len(self.prediction_engine.prediction_history),
            "last_update": datetime.now().isoformat(),
        }


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰"""
    # ãƒ†ã‚¹ãƒˆç”¨ã®éŠ˜æŸ„ãƒªã‚¹ãƒˆ
    symbols = ["7203", "6758", "9984"]  # ãƒˆãƒ¨ã‚¿ã€ã‚½ãƒ‹ãƒ¼ã€ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯G

    # AIäºˆæ¸¬çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–
    ai_system = AIPredictionIntegrationSystem(symbols)

    # ã‚·ã‚¹ãƒ†ãƒ ã‚’é–‹å§‹
    ai_system.start_system()

    try:
        # ãƒ†ã‚¹ãƒˆç”¨ã®å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        historical_data = {}
        for symbol in symbols:
            # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
            dates = pd.date_range(start="2024-01-01", end="2024-12-31", freq="D")
            data = pd.DataFrame(
                {
                    "close": np.random.randn(len(dates)).cumsum() + 1000,
                    "volume": np.random.randint(1000, 10000, len(dates)),
                    "rsi": np.random.uniform(20, 80, len(dates)),
                    "macd": np.random.randn(len(dates)),
                    "bb_upper": np.random.randn(len(dates)) + 1020,
                    "bb_lower": np.random.randn(len(dates)) + 980,
                },
                index=dates,
            )
            historical_data[symbol] = data

        # ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
        ai_system.train_all_models(historical_data)

        # äºˆæ¸¬ã‚’å®Ÿè¡Œ
        current_data = {symbol: historical_data[symbol].tail(100) for symbol in symbols}
        predictions = ai_system.get_predictions(current_data)

        # çµæœã‚’è¡¨ç¤º
        print("\n=== AIäºˆæ¸¬çµæœ ===")
        for symbol, prediction in predictions.items():
            print(f"\n{symbol}:")
            print(f"  äºˆæ¸¬ä¾¡æ ¼: {prediction.weighted_prediction:.2f}")
            print(f"  ä¿¡é ¼åº¦: {prediction.ensemble_confidence:.3f}")
            print(f"  æœ€è‰¯ãƒ¢ãƒ‡ãƒ«: {prediction.best_model.value}")

        # ã‚·ã‚¹ãƒ†ãƒ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’è¡¨ç¤º
        status = ai_system.get_system_status()
        print(f"\n=== ã‚·ã‚¹ãƒ†ãƒ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ ===")
        print(f"ç¨¼åƒä¸­: {status['system_running']}")
        print(f"ç·äºˆæ¸¬æ•°: {status['total_predictions']}")

    finally:
        # ã‚·ã‚¹ãƒ†ãƒ ã‚’åœæ­¢
        ai_system.stop_system()


if __name__ == "__main__":
    main()
