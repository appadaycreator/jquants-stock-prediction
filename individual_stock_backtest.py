#!/usr/bin/env python3
"""
å€‹åˆ¥éŠ˜æŸ„ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã®è©³ç´°åŒ–ã‚·ã‚¹ãƒ†ãƒ 
æœŸå¾…åŠ¹æœ: æŠ•è³‡æˆ¦ç•¥ã®ç²¾åº¦å‘ä¸Š
å®Ÿè£…é›£æ˜“åº¦: ğŸŸ¡ ä¸­
æ¨å®šå·¥æ•°: 3-4æ—¥

æ©Ÿèƒ½:
1. å€‹åˆ¥éŠ˜æŸ„ã®éå»ãƒ‡ãƒ¼ã‚¿ã§ã®æˆ¦ç•¥æ¤œè¨¼
2. å€‹åˆ¥éŠ˜æŸ„ã®å­£ç¯€æ€§ãƒ»å‘¨æœŸæ€§åˆ†æ
3. å€‹åˆ¥éŠ˜æŸ„ã®æ¥­ç¸¾ç™ºè¡¨å‰å¾Œã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
4. å€‹åˆ¥éŠ˜æŸ„ã®æŠ€è¡“æŒ‡æ¨™æœ€é©åŒ–
5. è¤‡æ•°éŠ˜æŸ„ã®æ¯”è¼ƒåˆ†æ
"""

import pandas as pd
import numpy as np
import yfinance as yf
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Any
import json
import logging
from dataclasses import dataclass, asdict
import warnings
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
from scipy import stats
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import ParameterGrid
import talib

# æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from advanced_backtest_system import (
    BacktestEngine,
    MomentumStrategy,
    MeanReversionStrategy,
    BreakoutStrategy,
    BacktestResult,
    BaseStrategy,
)
from advanced_performance_metrics import AdvancedPerformanceAnalyzer

warnings.filterwarnings("ignore")

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[logging.FileHandler("individual_backtest.log"), logging.StreamHandler()],
)
logger = logging.getLogger(__name__)


@dataclass
class SeasonalAnalysis:
    """å­£ç¯€æ€§åˆ†æçµæœ"""
    
    monthly_returns: Dict[int, float]
    quarterly_returns: Dict[int, float]
    seasonal_patterns: Dict[str, Any]
    statistical_significance: Dict[str, float]
    best_months: List[int]
    worst_months: List[int]


@dataclass
class EarningsAnalysis:
    """æ¥­ç¸¾ç™ºè¡¨åˆ†æçµæœ"""
    
    pre_earnings_returns: Dict[str, float]
    post_earnings_returns: Dict[str, float]
    earnings_volatility: Dict[str, float]
    surprise_impact: Dict[str, float]
    trading_volume_changes: Dict[str, float]


@dataclass
class TechnicalOptimization:
    """æŠ€è¡“æŒ‡æ¨™æœ€é©åŒ–çµæœ"""
    
    optimal_parameters: Dict[str, Any]
    performance_metrics: Dict[str, float]
    parameter_sensitivity: Dict[str, float]
    optimization_history: List[Dict[str, Any]]


@dataclass
class IndividualStockResult:
    """å€‹åˆ¥éŠ˜æŸ„åˆ†æçµæœ"""
    
    symbol: str
    analysis_period: Tuple[datetime, datetime]
    
    # åŸºæœ¬åˆ†æ
    basic_metrics: Dict[str, float]
    
    # å­£ç¯€æ€§åˆ†æ
    seasonal_analysis: SeasonalAnalysis
    
    # æ¥­ç¸¾ç™ºè¡¨åˆ†æ
    earnings_analysis: EarningsAnalysis
    
    # æŠ€è¡“æŒ‡æ¨™æœ€é©åŒ–
    technical_optimization: TechnicalOptimization
    
    # æˆ¦ç•¥ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœ
    strategy_results: Dict[str, BacktestResult]
    
    # æ¯”è¼ƒåˆ†æ
    comparison_metrics: Dict[str, Any]


class SeasonalAnalyzer:
    """å­£ç¯€æ€§åˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.analyzer = AdvancedPerformanceAnalyzer()
    
    def analyze_seasonality(self, data: pd.DataFrame, symbol: str) -> SeasonalAnalysis:
        """å­£ç¯€æ€§åˆ†æå®Ÿè¡Œ"""
        logger.info(f"å­£ç¯€æ€§åˆ†æé–‹å§‹: {symbol}")
        
        # æœˆæ¬¡ãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®—
        monthly_returns = self._calculate_monthly_returns(data)
        
        # å››åŠæœŸãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®—
        quarterly_returns = self._calculate_quarterly_returns(data)
        
        # å­£ç¯€ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        seasonal_patterns = self._analyze_seasonal_patterns(monthly_returns)
        
        # çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®š
        statistical_significance = self._test_statistical_significance(monthly_returns)
        
        # æœ€è‰¯ãƒ»æœ€æ‚ªæœˆã®ç‰¹å®š
        best_months, worst_months = self._identify_best_worst_months(monthly_returns)
        
        return SeasonalAnalysis(
            monthly_returns=monthly_returns,
            quarterly_returns=quarterly_returns,
            seasonal_patterns=seasonal_patterns,
            statistical_significance=statistical_significance,
            best_months=best_months,
            worst_months=worst_months
        )
    
    def _calculate_monthly_returns(self, data: pd.DataFrame) -> Dict[int, float]:
        """æœˆæ¬¡ãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®—"""
        monthly_data = data.resample('M').last()
        monthly_returns = {}
        
        for month in range(1, 13):
            month_data = monthly_data[monthly_data.index.month == month]
            if len(month_data) > 1:
                returns = month_data['Close'].pct_change().dropna()
                monthly_returns[month] = returns.mean()
            else:
                monthly_returns[month] = 0.0
        
        return monthly_returns
    
    def _calculate_quarterly_returns(self, data: pd.DataFrame) -> Dict[int, float]:
        """å››åŠæœŸãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®—"""
        quarterly_data = data.resample('Q').last()
        quarterly_returns = {}
        
        for quarter in range(1, 5):
            quarter_data = quarterly_data[quarterly_data.index.quarter == quarter]
            if len(quarter_data) > 1:
                returns = quarter_data['Close'].pct_change().dropna()
                quarterly_returns[quarter] = returns.mean()
            else:
                quarterly_returns[quarter] = 0.0
        
        return quarterly_returns
    
    def _analyze_seasonal_patterns(self, monthly_returns: Dict[int, float]) -> Dict[str, Any]:
        """å­£ç¯€ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        returns_array = np.array(list(monthly_returns.values()))
        
        # ãƒ•ãƒ¼ãƒªã‚¨å¤‰æ›ã«ã‚ˆã‚‹å‘¨æœŸæ€§æ¤œå‡º
        fft = np.fft.fft(returns_array)
        frequencies = np.fft.fftfreq(len(returns_array))
        
        # ä¸»è¦ãªå‘¨æœŸæ€§ã®ç‰¹å®š
        dominant_frequencies = np.argsort(np.abs(fft))[-3:]
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
        months = np.array(list(monthly_returns.keys()))
        returns = np.array(list(monthly_returns.values()))
        
        # ç·šå½¢å›å¸°ã«ã‚ˆã‚‹ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
        slope, intercept, r_value, p_value, std_err = stats.linregress(months, returns)
        
        return {
            'dominant_frequencies': dominant_frequencies.tolist(),
            'trend_slope': slope,
            'trend_r_squared': r_value ** 2,
            'trend_p_value': p_value,
            'volatility': np.std(returns),
            'mean_return': np.mean(returns)
        }
    
    def _test_statistical_significance(self, monthly_returns: Dict[int, float]) -> Dict[str, float]:
        """çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®š"""
        returns_array = np.array(list(monthly_returns.values()))
        
        # æ­£è¦æ€§æ¤œå®šï¼ˆShapiro-Wilkï¼‰
        shapiro_stat, shapiro_p = stats.shapiro(returns_array)
        
        # ç­‰åˆ†æ•£æ€§æ¤œå®šï¼ˆLeveneï¼‰
        # æœˆã‚’2ã¤ã®ã‚°ãƒ«ãƒ¼ãƒ—ã«åˆ†å‰²ã—ã¦æ¤œå®š
        group1 = returns_array[:6]  # 1-6æœˆ
        group2 = returns_array[6:]  # 7-12æœˆ
        levene_stat, levene_p = stats.levene(group1, group2)
        
        # ç›¸é–¢åˆ†æ
        months = np.array(list(monthly_returns.keys()))
        correlation, corr_p = stats.pearsonr(months, returns_array)
        
        return {
            'shapiro_statistic': shapiro_stat,
            'shapiro_p_value': shapiro_p,
            'levene_statistic': levene_stat,
            'levene_p_value': levene_p,
            'correlation_coefficient': correlation,
            'correlation_p_value': corr_p
        }
    
    def _identify_best_worst_months(self, monthly_returns: Dict[int, float]) -> Tuple[List[int], List[int]]:
        """æœ€è‰¯ãƒ»æœ€æ‚ªæœˆã®ç‰¹å®š"""
        sorted_returns = sorted(monthly_returns.items(), key=lambda x: x[1], reverse=True)
        
        # ä¸Šä½3ãƒ¶æœˆ
        best_months = [month for month, _ in sorted_returns[:3]]
        
        # ä¸‹ä½3ãƒ¶æœˆ
        worst_months = [month for month, _ in sorted_returns[-3:]]
        
        return best_months, worst_months


class EarningsAnalyzer:
    """æ¥­ç¸¾ç™ºè¡¨åˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.earnings_dates = {}
    
    def analyze_earnings_impact(self, data: pd.DataFrame, symbol: str) -> EarningsAnalysis:
        """æ¥­ç¸¾ç™ºè¡¨å½±éŸ¿åˆ†æ"""
        logger.info(f"æ¥­ç¸¾ç™ºè¡¨åˆ†æé–‹å§‹: {symbol}")
        
        # æ¥­ç¸¾ç™ºè¡¨æ—¥æ¨å®šï¼ˆå››åŠæœŸçµ‚äº†å¾Œ30-45æ—¥å¾Œï¼‰
        earnings_dates = self._estimate_earnings_dates(data)
        
        # æ¥­ç¸¾ç™ºè¡¨å‰å¾Œã®ãƒªã‚¿ãƒ¼ãƒ³åˆ†æ
        pre_earnings_returns = self._analyze_pre_earnings_returns(data, earnings_dates)
        post_earnings_returns = self._analyze_post_earnings_returns(data, earnings_dates)
        
        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æ
        earnings_volatility = self._analyze_earnings_volatility(data, earnings_dates)
        
        # ã‚µãƒ—ãƒ©ã‚¤ã‚ºå½±éŸ¿åˆ†æ
        surprise_impact = self._analyze_surprise_impact(data, earnings_dates)
        
        # å–å¼•é‡å¤‰åŒ–åˆ†æ
        volume_changes = self._analyze_volume_changes(data, earnings_dates)
        
        return EarningsAnalysis(
            pre_earnings_returns=pre_earnings_returns,
            post_earnings_returns=post_earnings_returns,
            earnings_volatility=earnings_volatility,
            surprise_impact=surprise_impact,
            trading_volume_changes=volume_changes
        )
    
    def _estimate_earnings_dates(self, data: pd.DataFrame) -> List[datetime]:
        """æ¥­ç¸¾ç™ºè¡¨æ—¥æ¨å®š"""
        earnings_dates = []
        
        # å››åŠæœŸçµ‚äº†æ—¥ã‚’ç‰¹å®š
        quarterly_ends = data.resample('Q').last().index
        
        for quarter_end in quarterly_ends:
            # å››åŠæœŸçµ‚äº†å¾Œ30-45æ—¥å¾Œã«æ¥­ç¸¾ç™ºè¡¨ã¨ä»®å®š
            estimated_earnings_date = quarter_end + timedelta(days=37)
            
            # ãƒ‡ãƒ¼ã‚¿ç¯„å›²å†…ã‹ãƒã‚§ãƒƒã‚¯
            if estimated_earnings_date in data.index:
                earnings_dates.append(estimated_earnings_date)
        
        return earnings_dates
    
    def _analyze_pre_earnings_returns(self, data: pd.DataFrame, earnings_dates: List[datetime]) -> Dict[str, float]:
        """æ¥­ç¸¾ç™ºè¡¨å‰ãƒªã‚¿ãƒ¼ãƒ³åˆ†æ"""
        pre_returns = {}
        
        for earnings_date in earnings_dates:
            # æ¥­ç¸¾ç™ºè¡¨å‰5æ—¥ã€10æ—¥ã€20æ—¥ã®ãƒªã‚¿ãƒ¼ãƒ³
            for days in [5, 10, 20]:
                start_date = earnings_date - timedelta(days=days)
                
                if start_date in data.index and earnings_date in data.index:
                    start_price = data.loc[start_date, 'Close']
                    end_price = data.loc[earnings_date, 'Close']
                    return_pct = (end_price - start_price) / start_price
                    pre_returns[f'pre_{days}d'] = return_pct
        
        return pre_returns
    
    def _analyze_post_earnings_returns(self, data: pd.DataFrame, earnings_dates: List[datetime]) -> Dict[str, float]:
        """æ¥­ç¸¾ç™ºè¡¨å¾Œãƒªã‚¿ãƒ¼ãƒ³åˆ†æ"""
        post_returns = {}
        
        for earnings_date in earnings_dates:
            # æ¥­ç¸¾ç™ºè¡¨å¾Œ5æ—¥ã€10æ—¥ã€20æ—¥ã®ãƒªã‚¿ãƒ¼ãƒ³
            for days in [5, 10, 20]:
                end_date = earnings_date + timedelta(days=days)
                
                if earnings_date in data.index and end_date in data.index:
                    start_price = data.loc[earnings_date, 'Close']
                    end_price = data.loc[end_date, 'Close']
                    return_pct = (end_price - start_price) / start_price
                    post_returns[f'post_{days}d'] = return_pct
        
        return post_returns
    
    def _analyze_earnings_volatility(self, data: pd.DataFrame, earnings_dates: List[datetime]) -> Dict[str, float]:
        """æ¥­ç¸¾ç™ºè¡¨æœŸé–“ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æ"""
        volatility_metrics = {}
        
        for earnings_date in earnings_dates:
            # æ¥­ç¸¾ç™ºè¡¨å‰å¾Œ10æ—¥é–“ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
            pre_start = earnings_date - timedelta(days=10)
            post_end = earnings_date + timedelta(days=10)
            
            if pre_start in data.index and post_end in data.index:
                pre_data = data.loc[pre_start:earnings_date, 'Close']
                post_data = data.loc[earnings_date:post_end, 'Close']
                
                pre_volatility = pre_data.pct_change().std()
                post_volatility = post_data.pct_change().std()
                
                volatility_metrics['pre_volatility'] = pre_volatility
                volatility_metrics['post_volatility'] = post_volatility
                volatility_metrics['volatility_change'] = post_volatility - pre_volatility
        
        return volatility_metrics
    
    def _analyze_surprise_impact(self, data: pd.DataFrame, earnings_dates: List[datetime]) -> Dict[str, float]:
        """ã‚µãƒ—ãƒ©ã‚¤ã‚ºå½±éŸ¿åˆ†æ"""
        surprise_metrics = {}
        
        for earnings_date in earnings_dates:
            # æ¥­ç¸¾ç™ºè¡¨å‰å¾Œã®ä¾¡æ ¼å¤‰åŒ–
            pre_price = data.loc[earnings_date - timedelta(days=1), 'Close']
            post_price = data.loc[earnings_date + timedelta(days=1), 'Close']
            
            price_change = (post_price - pre_price) / pre_price
            surprise_metrics['price_change'] = price_change
            
            # å–å¼•é‡å¤‰åŒ–
            pre_volume = data.loc[earnings_date - timedelta(days=1), 'Volume']
            post_volume = data.loc[earnings_date + timedelta(days=1), 'Volume']
            
            volume_change = (post_volume - pre_volume) / pre_volume
            surprise_metrics['volume_change'] = volume_change
        
        return surprise_metrics
    
    def _analyze_volume_changes(self, data: pd.DataFrame, earnings_dates: List[datetime]) -> Dict[str, float]:
        """å–å¼•é‡å¤‰åŒ–åˆ†æ"""
        volume_metrics = {}
        
        for earnings_date in earnings_dates:
            # æ¥­ç¸¾ç™ºè¡¨å‰å¾Œ5æ—¥é–“ã®å¹³å‡å–å¼•é‡
            pre_start = earnings_date - timedelta(days=5)
            post_end = earnings_date + timedelta(days=5)
            
            if pre_start in data.index and post_end in data.index:
                pre_volume = data.loc[pre_start:earnings_date, 'Volume'].mean()
                post_volume = data.loc[earnings_date:post_end, 'Volume'].mean()
                
                volume_metrics['pre_volume'] = pre_volume
                volume_metrics['post_volume'] = post_volume
                volume_metrics['volume_ratio'] = post_volume / pre_volume
        
        return volume_metrics


class TechnicalOptimizer:
    """æŠ€è¡“æŒ‡æ¨™æœ€é©åŒ–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.optimization_history = []
    
    def optimize_technical_indicators(self, data: pd.DataFrame, symbol: str) -> TechnicalOptimization:
        """æŠ€è¡“æŒ‡æ¨™æœ€é©åŒ–"""
        logger.info(f"æŠ€è¡“æŒ‡æ¨™æœ€é©åŒ–é–‹å§‹: {symbol}")
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚°ãƒªãƒƒãƒ‰å®šç¾©
        param_grid = self._define_parameter_grid()
        
        # æœ€é©åŒ–å®Ÿè¡Œ
        optimal_params, performance_metrics, sensitivity = self._run_optimization(data, param_grid)
        
        return TechnicalOptimization(
            optimal_parameters=optimal_params,
            performance_metrics=performance_metrics,
            parameter_sensitivity=sensitivity,
            optimization_history=self.optimization_history
        )
    
    def _define_parameter_grid(self) -> Dict[str, List]:
        """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚°ãƒªãƒƒãƒ‰å®šç¾©"""
        return {
            'sma_short': [5, 10, 15, 20],
            'sma_long': [20, 30, 50, 100],
            'rsi_period': [14, 21, 28],
            'macd_fast': [12, 15, 18],
            'macd_slow': [26, 30, 34],
            'bb_period': [20, 25, 30],
            'bb_std': [1.5, 2.0, 2.5]
        }
    
    def _run_optimization(self, data: pd.DataFrame, param_grid: Dict[str, List]) -> Tuple[Dict[str, Any], Dict[str, float], Dict[str, float]]:
        """æœ€é©åŒ–å®Ÿè¡Œ"""
        best_params = {}
        best_performance = 0
        all_results = []
        
        # ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒå®Ÿè¡Œ
        for params in ParameterGrid(param_grid):
            try:
                # æŠ€è¡“æŒ‡æ¨™è¨ˆç®—
                indicators = self._calculate_technical_indicators(data, params)
                
                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡
                performance = self._evaluate_performance(data, indicators, params)
                
                all_results.append({
                    'params': params,
                    'performance': performance
                })
                
                # æœ€è‰¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°
                if performance > best_performance:
                    best_performance = performance
                    best_params = params
                    
            except Exception as e:
                logger.warning(f"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™è¨ˆç®—
        performance_metrics = self._calculate_performance_metrics(all_results)
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ„Ÿåº¦åˆ†æ
        sensitivity = self._analyze_parameter_sensitivity(all_results)
        
        return best_params, performance_metrics, sensitivity
    
    def _calculate_technical_indicators(self, data: pd.DataFrame, params: Dict[str, Any]) -> Dict[str, pd.Series]:
        """æŠ€è¡“æŒ‡æ¨™è¨ˆç®—"""
        indicators = {}
        
        # SMA
        indicators['sma_short'] = talib.SMA(data['Close'], timeperiod=params['sma_short'])
        indicators['sma_long'] = talib.SMA(data['Close'], timeperiod=params['sma_long'])
        
        # RSI
        indicators['rsi'] = talib.RSI(data['Close'], timeperiod=params['rsi_period'])
        
        # MACD
        macd, macd_signal, macd_hist = talib.MACD(
            data['Close'],
            fastperiod=params['macd_fast'],
            slowperiod=params['macd_slow'],
            signalperiod=9
        )
        indicators['macd'] = macd
        indicators['macd_signal'] = macd_signal
        indicators['macd_histogram'] = macd_hist
        
        # ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰
        bb_upper, bb_middle, bb_lower = talib.BBANDS(
            data['Close'],
            timeperiod=params['bb_period'],
            nbdevup=params['bb_std'],
            nbdevdn=params['bb_std']
        )
        indicators['bb_upper'] = bb_upper
        indicators['bb_middle'] = bb_middle
        indicators['bb_lower'] = bb_lower
        
        return indicators
    
    def _evaluate_performance(self, data: pd.DataFrame, indicators: Dict[str, pd.Series], params: Dict[str, Any]) -> float:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡"""
        # ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆ
        signals = self._generate_signals(data, indicators)
        
        # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        returns = self._calculate_strategy_returns(data, signals)
        
        # ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªè¨ˆç®—
        if returns.std() > 0:
            sharpe_ratio = returns.mean() / returns.std() * np.sqrt(252)
        else:
            sharpe_ratio = 0
        
        return sharpe_ratio
    
    def _generate_signals(self, data: pd.DataFrame, indicators: Dict[str, pd.Series]) -> pd.Series:
        """ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆ"""
        signals = pd.Series(0, index=data.index)
        
        # SMAã‚¯ãƒ­ã‚¹ã‚ªãƒ¼ãƒãƒ¼
        sma_signal = np.where(
            indicators['sma_short'] > indicators['sma_long'], 1,
            np.where(indicators['sma_short'] < indicators['sma_long'], -1, 0)
        )
        
        # RSIã‚·ã‚°ãƒŠãƒ«
        rsi_signal = np.where(
            indicators['rsi'] > 70, -1,
            np.where(indicators['rsi'] < 30, 1, 0)
        )
        
        # MACDã‚·ã‚°ãƒŠãƒ«
        macd_signal = np.where(
            indicators['macd'] > indicators['macd_signal'], 1,
            np.where(indicators['macd'] < indicators['macd_signal'], -1, 0)
        )
        
        # ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰ã‚·ã‚°ãƒŠãƒ«
        bb_signal = np.where(
            data['Close'] > indicators['bb_upper'], -1,
            np.where(data['Close'] < indicators['bb_lower'], 1, 0)
        )
        
        # ã‚·ã‚°ãƒŠãƒ«çµ±åˆ
        combined_signal = (sma_signal + rsi_signal + macd_signal + bb_signal) / 4
        signals = pd.Series(combined_signal, index=data.index)
        
        return signals
    
    def _calculate_strategy_returns(self, data: pd.DataFrame, signals: pd.Series) -> pd.Series:
        """æˆ¦ç•¥ãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®—"""
        returns = data['Close'].pct_change()
        strategy_returns = signals.shift(1) * returns
        return strategy_returns.dropna()
    
    def _calculate_performance_metrics(self, all_results: List[Dict[str, Any]]) -> Dict[str, float]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™è¨ˆç®—"""
        performances = [result['performance'] for result in all_results]
        
        return {
            'best_performance': max(performances),
            'worst_performance': min(performances),
            'mean_performance': np.mean(performances),
            'std_performance': np.std(performances),
            'median_performance': np.median(performances)
        }
    
    def _analyze_parameter_sensitivity(self, all_results: List[Dict[str, Any]]) -> Dict[str, float]:
        """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ„Ÿåº¦åˆ†æ"""
        sensitivity = {}
        
        # å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ„Ÿåº¦è¨ˆç®—
        param_names = list(all_results[0]['params'].keys())
        
        for param_name in param_names:
            param_values = []
            performances = []
            
            for result in all_results:
                param_values.append(result['params'][param_name])
                performances.append(result['performance'])
            
            # ç›¸é–¢ä¿‚æ•°è¨ˆç®—
            correlation = np.corrcoef(param_values, performances)[0, 1]
            sensitivity[param_name] = correlation
        
        return sensitivity


class IndividualStockBacktestSystem:
    """å€‹åˆ¥éŠ˜æŸ„ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, initial_capital: float = 1000000):
        self.initial_capital = initial_capital
        self.seasonal_analyzer = SeasonalAnalyzer()
        self.earnings_analyzer = EarningsAnalyzer()
        self.technical_optimizer = TechnicalOptimizer()
        self.backtest_engine = BacktestEngine(initial_capital)
    
    def analyze_individual_stock(self, symbol: str, start_date: datetime, end_date: datetime) -> IndividualStockResult:
        """å€‹åˆ¥éŠ˜æŸ„åˆ†æå®Ÿè¡Œ"""
        logger.info(f"å€‹åˆ¥éŠ˜æŸ„åˆ†æé–‹å§‹: {symbol}")
        
        # ãƒ‡ãƒ¼ã‚¿å–å¾—
        data = self._fetch_stock_data(symbol, start_date, end_date)
        
        if data.empty:
            raise ValueError(f"ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ: {symbol}")
        
        # åŸºæœ¬æŒ‡æ¨™è¨ˆç®—
        basic_metrics = self._calculate_basic_metrics(data)
        
        # å­£ç¯€æ€§åˆ†æ
        seasonal_analysis = self.seasonal_analyzer.analyze_seasonality(data, symbol)
        
        # æ¥­ç¸¾ç™ºè¡¨åˆ†æ
        earnings_analysis = self.earnings_analyzer.analyze_earnings_impact(data, symbol)
        
        # æŠ€è¡“æŒ‡æ¨™æœ€é©åŒ–
        technical_optimization = self.technical_optimizer.optimize_technical_indicators(data, symbol)
        
        # æˆ¦ç•¥ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
        strategy_results = self._run_strategy_backtests(data, symbol, start_date, end_date)
        
        # æ¯”è¼ƒåˆ†æ
        comparison_metrics = self._calculate_comparison_metrics(data, symbol)
        
        return IndividualStockResult(
            symbol=symbol,
            analysis_period=(start_date, end_date),
            basic_metrics=basic_metrics,
            seasonal_analysis=seasonal_analysis,
            earnings_analysis=earnings_analysis,
            technical_optimization=technical_optimization,
            strategy_results=strategy_results,
            comparison_metrics=comparison_metrics
        )
    
    def _fetch_stock_data(self, symbol: str, start_date: datetime, end_date: datetime) -> pd.DataFrame:
        """æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        try:
            ticker = yf.Ticker(symbol)
            data = ticker.history(start=start_date, end=end_date)
            return data
        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼ {symbol}: {e}")
            return pd.DataFrame()
    
    def _calculate_basic_metrics(self, data: pd.DataFrame) -> Dict[str, float]:
        """åŸºæœ¬æŒ‡æ¨™è¨ˆç®—"""
        returns = data['Close'].pct_change().dropna()
        
        return {
            'total_return': (data['Close'].iloc[-1] / data['Close'].iloc[0]) - 1,
            'annualized_return': ((data['Close'].iloc[-1] / data['Close'].iloc[0]) ** (252 / len(data))) - 1,
            'volatility': returns.std() * np.sqrt(252),
            'sharpe_ratio': returns.mean() / returns.std() * np.sqrt(252) if returns.std() > 0 else 0,
            'max_drawdown': self._calculate_max_drawdown(data['Close']),
            'skewness': returns.skew(),
            'kurtosis': returns.kurtosis(),
            'var_95': np.percentile(returns, 5),
            'var_99': np.percentile(returns, 1)
        }
    
    def _calculate_max_drawdown(self, prices: pd.Series) -> float:
        """æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³è¨ˆç®—"""
        peak = prices.expanding().max()
        drawdown = (prices - peak) / peak
        return drawdown.min()
    
    def _run_strategy_backtests(self, data: pd.DataFrame, symbol: str, start_date: datetime, end_date: datetime) -> Dict[str, BacktestResult]:
        """æˆ¦ç•¥ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        strategies = [
            MomentumStrategy({"lookback": 20, "threshold": 0.05}),
            MeanReversionStrategy({"lookback": 20, "std_threshold": 2.0}),
            BreakoutStrategy({"lookback": 20, "volume_threshold": 1.5})
        ]
        
        results = {}
        
        for strategy in strategies:
            try:
                result = self.backtest_engine.run_backtest(data, strategy, start_date, end_date)
                results[strategy.name] = result
            except Exception as e:
                logger.error(f"æˆ¦ç•¥ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ {symbol}-{strategy.name}: {e}")
                results[strategy.name] = None
        
        return results
    
    def _calculate_comparison_metrics(self, data: pd.DataFrame, symbol: str) -> Dict[str, Any]:
        """æ¯”è¼ƒåˆ†ææŒ‡æ¨™è¨ˆç®—"""
        returns = data['Close'].pct_change().dropna()
        
        # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ¯”è¼ƒï¼ˆæ—¥çµŒå¹³å‡ã‚’æƒ³å®šï¼‰
        benchmark_return = 0.05  # ä»®ã®å¹´ç‡5%
        excess_return = returns.mean() * 252 - benchmark_return
        
        # ç›¸é–¢åˆ†æï¼ˆè‡ªå·±ç›¸é–¢ï¼‰
        autocorrelation = returns.autocorr(lag=1)
        
        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
        volatility_clustering = returns.rolling(20).std().autocorr(lag=1)
        
        return {
            'excess_return': excess_return,
            'autocorrelation': autocorrelation,
            'volatility_clustering': volatility_clustering,
            'trend_strength': self._calculate_trend_strength(data['Close']),
            'momentum_score': self._calculate_momentum_score(returns)
        }
    
    def _calculate_trend_strength(self, prices: pd.Series) -> float:
        """ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦è¨ˆç®—"""
        # ç·šå½¢å›å¸°ã«ã‚ˆã‚‹ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
        x = np.arange(len(prices))
        y = prices.values
        
        slope, _, r_value, _, _ = stats.linregress(x, y)
        return r_value ** 2  # RÂ²å€¤
    
    def _calculate_momentum_score(self, returns: pd.Series) -> float:
        """ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        # éå»20æ—¥ã€60æ—¥ã€120æ—¥ã®ãƒªã‚¿ãƒ¼ãƒ³
        momentum_20 = returns.rolling(20).sum().iloc[-1] if len(returns) >= 20 else 0
        momentum_60 = returns.rolling(60).sum().iloc[-1] if len(returns) >= 60 else 0
        momentum_120 = returns.rolling(120).sum().iloc[-1] if len(returns) >= 120 else 0
        
        # é‡ã¿ä»˜ããƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ã‚¹ã‚³ã‚¢
        momentum_score = (momentum_20 * 0.5 + momentum_60 * 0.3 + momentum_120 * 0.2)
        
        return momentum_score
    
    def compare_multiple_stocks(self, symbols: List[str], start_date: datetime, end_date: datetime) -> Dict[str, IndividualStockResult]:
        """è¤‡æ•°éŠ˜æŸ„æ¯”è¼ƒåˆ†æ"""
        logger.info(f"è¤‡æ•°éŠ˜æŸ„æ¯”è¼ƒåˆ†æé–‹å§‹: {len(symbols)}éŠ˜æŸ„")
        
        results = {}
        
        with ThreadPoolExecutor(max_workers=5) as executor:
            future_to_symbol = {
                executor.submit(self.analyze_individual_stock, symbol, start_date, end_date): symbol
                for symbol in symbols
            }
            
            for future in as_completed(future_to_symbol):
                symbol = future_to_symbol[future]
                try:
                    result = future.result()
                    results[symbol] = result
                    logger.info(f"åˆ†æå®Œäº†: {symbol}")
                except Exception as e:
                    logger.error(f"åˆ†æã‚¨ãƒ©ãƒ¼ {symbol}: {e}")
                    results[symbol] = None
        
        return results
    
    def generate_comprehensive_report(self, result: IndividualStockResult) -> str:
        """åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        report = []
        report.append("=" * 100)
        report.append(f"ğŸ“Š å€‹åˆ¥éŠ˜æŸ„è©³ç´°åˆ†æãƒ¬ãƒãƒ¼ãƒˆ - {result.symbol}")
        report.append("=" * 100)
        
        # åŸºæœ¬æƒ…å ±
        report.append(f"\nğŸ“… åˆ†ææœŸé–“: {result.analysis_period[0].strftime('%Y-%m-%d')} - {result.analysis_period[1].strftime('%Y-%m-%d')}")
        
        # åŸºæœ¬æŒ‡æ¨™
        report.append(f"\nğŸ“ˆ åŸºæœ¬æŒ‡æ¨™:")
        for key, value in result.basic_metrics.items():
            if isinstance(value, float):
                report.append(f"  {key}: {value:.4f}")
            else:
                report.append(f"  {key}: {value}")
        
        # å­£ç¯€æ€§åˆ†æ
        report.append(f"\nğŸ—“ï¸ å­£ç¯€æ€§åˆ†æ:")
        report.append(f"  æœ€è‰¯æœˆ: {result.seasonal_analysis.best_months}")
        report.append(f"  æœ€æ‚ªæœˆ: {result.seasonal_analysis.worst_months}")
        report.append(f"  ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦: {result.seasonal_analysis.seasonal_patterns['trend_r_squared']:.4f}")
        
        # æ¥­ç¸¾ç™ºè¡¨åˆ†æ
        report.append(f"\nğŸ“Š æ¥­ç¸¾ç™ºè¡¨åˆ†æ:")
        for key, value in result.earnings_analysis.pre_earnings_returns.items():
            report.append(f"  {key}: {value:.4f}")
        
        # æŠ€è¡“æŒ‡æ¨™æœ€é©åŒ–
        report.append(f"\nâš™ï¸ æŠ€è¡“æŒ‡æ¨™æœ€é©åŒ–:")
        report.append(f"  æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {result.technical_optimization.optimal_parameters}")
        report.append(f"  æœ€é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹: {result.technical_optimization.performance_metrics['best_performance']:.4f}")
        
        # æˆ¦ç•¥ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœ
        report.append(f"\nğŸ¯ æˆ¦ç•¥ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœ:")
        for strategy_name, strategy_result in result.strategy_results.items():
            if strategy_result:
                report.append(f"  {strategy_name}:")
                report.append(f"    ç·ãƒªã‚¿ãƒ¼ãƒ³: {strategy_result.total_return:.2%}")
                report.append(f"    ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª: {strategy_result.sharpe_ratio:.2f}")
                report.append(f"    æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³: {strategy_result.max_drawdown:.2%}")
            else:
                report.append(f"  {strategy_name}: ãƒ‡ãƒ¼ã‚¿ãªã—")
        
        # æ¯”è¼ƒåˆ†æ
        report.append(f"\nğŸ“Š æ¯”è¼ƒåˆ†æ:")
        for key, value in result.comparison_metrics.items():
            report.append(f"  {key}: {value:.4f}")
        
        return "\n".join(report)
    
    def save_results(self, result: IndividualStockResult, filename: str = None):
        """çµæœä¿å­˜"""
        if filename is None:
            filename = f"individual_analysis_{result.symbol}"
        
        # JSONå½¢å¼ã§ä¿å­˜
        result_dict = asdict(result)
        
        # æ—¥æ™‚ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
        for key, value in result_dict.items():
            if isinstance(value, datetime):
                result_dict[key] = value.isoformat()
            elif isinstance(value, tuple) and len(value) == 2 and isinstance(value[0], datetime):
                result_dict[key] = [value[0].isoformat(), value[1].isoformat()]
        
        with open(f"{filename}_results.json", "w", encoding="utf-8") as f:
            json.dump(result_dict, f, ensure_ascii=False, indent=2, default=str)
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        report = self.generate_comprehensive_report(result)
        with open(f"{filename}_report.txt", "w", encoding="utf-8") as f:
            f.write(report)
        
        logger.info(f"çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filename}_results.json, {filename}_report.txt")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    logger.info("=== å€‹åˆ¥éŠ˜æŸ„ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆè©³ç´°åŒ–ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹ ===")
    
    # è¨­å®š
    symbols = [
        "7203.T",  # ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Š
        "6758.T",  # ã‚½ãƒ‹ãƒ¼ã‚°ãƒ«ãƒ¼ãƒ—
        "9984.T",  # ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯ã‚°ãƒ«ãƒ¼ãƒ—
        "9432.T",  # æ—¥æœ¬é›»ä¿¡é›»è©±
        "6861.T",  # ã‚­ãƒ¼ã‚¨ãƒ³ã‚¹
    ]
    
    start_date = datetime(2020, 1, 1)
    end_date = datetime(2023, 12, 31)
    initial_capital = 1000000
    
    # å€‹åˆ¥éŠ˜æŸ„ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    system = IndividualStockBacktestSystem(initial_capital)
    
    try:
        # å€‹åˆ¥éŠ˜æŸ„åˆ†æå®Ÿè¡Œ
        for symbol in symbols:
            logger.info(f"å€‹åˆ¥éŠ˜æŸ„åˆ†æé–‹å§‹: {symbol}")
            
            result = system.analyze_individual_stock(symbol, start_date, end_date)
            
            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ»è¡¨ç¤º
            report = system.generate_comprehensive_report(result)
            print(report)
            
            # çµæœä¿å­˜
            system.save_results(result)
        
        # è¤‡æ•°éŠ˜æŸ„æ¯”è¼ƒåˆ†æ
        logger.info("è¤‡æ•°éŠ˜æŸ„æ¯”è¼ƒåˆ†æé–‹å§‹")
        comparison_results = system.compare_multiple_stocks(symbols, start_date, end_date)
        
        # æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        comparison_report = []
        comparison_report.append("=" * 100)
        comparison_report.append("ğŸ“Š è¤‡æ•°éŠ˜æŸ„æ¯”è¼ƒåˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
        comparison_report.append("=" * 100)
        
        for symbol, result in comparison_results.items():
            if result:
                comparison_report.append(f"\n{symbol}:")
                comparison_report.append(f"  ç·ãƒªã‚¿ãƒ¼ãƒ³: {result.basic_metrics['total_return']:.2%}")
                comparison_report.append(f"  ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª: {result.basic_metrics['sharpe_ratio']:.2f}")
                comparison_report.append(f"  æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³: {result.basic_metrics['max_drawdown']:.2%}")
        
        comparison_report_text = "\n".join(comparison_report)
        print(comparison_report_text)
        
        # æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        with open("multi_stock_comparison_report.txt", "w", encoding="utf-8") as f:
            f.write(comparison_report_text)
        
        logger.info("=== å€‹åˆ¥éŠ˜æŸ„ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆè©³ç´°åŒ–å®Œäº† ===")
        
    except Exception as e:
        logger.error(f"å€‹åˆ¥éŠ˜æŸ„ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        raise


if __name__ == "__main__":
    main()
