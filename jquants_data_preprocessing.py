#!/usr/bin/env python3
"""
æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆæŠ€è¡“æŒ‡æ¨™çµ±åˆç‰ˆï¼‰
ç”Ÿãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã¨é«˜åº¦ãªæŠ€è¡“æŒ‡æ¨™ã«ã‚ˆã‚‹ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œ
"""

import pandas as pd
import numpy as np
import logging
from config_loader import get_config
from technical_indicators import TechnicalIndicators, get_enhanced_features_list

# è¨­å®šã‚’èª­ã¿è¾¼ã¿
config = get_config()
preprocessing_config = config.get_preprocessing_config()

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def load_and_clean_data(input_file):
    """ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°"""
    logger.info(f"ğŸ“ ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­: {input_file}")
    df = pd.read_csv(input_file)
    
    # ãƒ‡ãƒ¼ã‚¿å‹ã®å¤‰æ›
    df['Date'] = pd.to_datetime(df['Date'])
    
    # å¿…è¦ãªã‚«ãƒ©ãƒ ã‚’é¸æŠ
    columns = preprocessing_config.get('columns', ['Date', 'Code', 'CompanyName', 'High', 'Low', 'Open', 'Close', 'Volume'])
    available_columns = [col for col in columns if col in df.columns]
    df = df[available_columns]
    
    # æ¬ æå€¤ã®ç¢ºèª
    missing_count = df.isnull().sum().sum()
    logger.info(f"ğŸ” æ¬ æå€¤ã®æ•°: {missing_count}")
    
    # æ¬ æå€¤ã®å‡¦ç†ï¼ˆå‰ã®å€¤ã§è£œå®Œï¼‰
    if missing_count > 0:
        df = df.fillna(method='ffill')
        logger.info("âœ… æ¬ æå€¤ã‚’å‰æ–¹è£œå®Œã§å‡¦ç†")
    
    # é‡è¤‡è¡Œã®å‰Šé™¤
    duplicates = df.duplicated().sum()
    if duplicates > 0:
        df = df.drop_duplicates()
        logger.info(f"ğŸ—‘ï¸ é‡è¤‡è¡Œã‚’å‰Šé™¤: {duplicates}è¡Œ")
    
    # ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬çµ±è¨ˆ
    logger.info(f"ğŸ“Š ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {df.shape}")
    logger.info(f"ğŸ“… ãƒ‡ãƒ¼ã‚¿æœŸé–“: {df['Date'].min()} ï½ {df['Date'].max()}")
    
    return df

def engineer_basic_features(df):
    """åŸºæœ¬çš„ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼‰"""
    logger.info("ğŸ”§ åŸºæœ¬ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’é–‹å§‹")
    
    # åŸºæœ¬çš„ãªç§»å‹•å¹³å‡ï¼ˆæŠ€è¡“æŒ‡æ¨™ã¨é‡è¤‡å›é¿ï¼‰
    basic_sma_windows = preprocessing_config.get('sma_windows', [5, 10, 25, 50])
    for window in basic_sma_windows:
        if f'SMA_{window}' not in df.columns:
            df[f'SMA_{window}'] = df['Close'].rolling(window=window).mean()
    
    # åŸºæœ¬çš„ãªãƒ©ã‚°ç‰¹å¾´é‡
    lag_days = preprocessing_config.get('lag_days', [1, 3, 5])
    for lag in lag_days:
        df[f'Close_lag_{lag}'] = df['Close'].shift(lag)
    
    logger.info("âœ… åŸºæœ¬ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å®Œäº†")
    return df

def engineer_advanced_features(df):
    """é«˜åº¦ãªæŠ€è¡“æŒ‡æ¨™ã«ã‚ˆã‚‹ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°"""
    logger.info("ğŸš€ é«˜åº¦ãªæŠ€è¡“æŒ‡æ¨™è¨ˆç®—ã‚’é–‹å§‹")
    
    # æŠ€è¡“æŒ‡æ¨™è¨ˆç®—å™¨ã‚’åˆæœŸåŒ–
    calculator = TechnicalIndicators()
    
    # æŠ€è¡“æŒ‡æ¨™è¨­å®šã‚’å–å¾—
    technical_config = preprocessing_config.get('technical_indicators', calculator._get_default_config())
    
    try:
        # å…¨ã¦ã®æŠ€è¡“æŒ‡æ¨™ã‚’è¨ˆç®—
        enhanced_df = calculator.calculate_all_indicators(df, technical_config)
        
        # æ–°ã—ãè¿½åŠ ã•ã‚ŒãŸæŒ‡æ¨™ã‚’ãƒ­ã‚°å‡ºåŠ›
        original_columns = set(df.columns)
        new_columns = [col for col in enhanced_df.columns if col not in original_columns]
        
        logger.info(f"ğŸ“ˆ è¿½åŠ ã•ã‚ŒãŸæŠ€è¡“æŒ‡æ¨™: {len(new_columns)}å€‹")
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«æŒ‡æ¨™ã‚’ãƒ­ã‚°å‡ºåŠ›
        momentum_indicators = [col for col in new_columns if any(x in col for x in ['RSI', 'MACD', 'Stoch'])]
        volatility_indicators = [col for col in new_columns if any(x in col for x in ['BB_', 'ATR'])]
        volume_indicators = [col for col in new_columns if any(x in col for x in ['Volume', 'VWAP', 'OBV', 'PVT'])]
        trend_indicators = [col for col in new_columns if any(x in col for x in ['ADX', 'DI', 'CCI'])]
        
        logger.info(f"  ğŸ“Š ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ç³»: {len(momentum_indicators)}å€‹")
        logger.info(f"  ğŸ“ˆ ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç³»: {len(volatility_indicators)}å€‹")
        logger.info(f"  ğŸ”Š ãƒœãƒªãƒ¥ãƒ¼ãƒ ç³»: {len(volume_indicators)}å€‹")
        logger.info(f"  ğŸ“‰ ãƒˆãƒ¬ãƒ³ãƒ‰ç³»: {len(trend_indicators)}å€‹")
        
        return enhanced_df
        
    except Exception as e:
        logger.error(f"âŒ æŠ€è¡“æŒ‡æ¨™è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        logger.warning("ğŸ”„ åŸºæœ¬ç‰¹å¾´é‡ã®ã¿ã§ç¶šè¡Œã—ã¾ã™")
        return df

def feature_selection_and_validation(df):
    """ç‰¹å¾´é‡é¸æŠã¨æ¤œè¨¼"""
    logger.info("ğŸ¯ ç‰¹å¾´é‡é¸æŠã¨æ¤œè¨¼ã‚’é–‹å§‹")
    
    # åˆ©ç”¨å¯èƒ½ãªæ‹¡å¼µç‰¹å¾´é‡ãƒªã‚¹ãƒˆ
    enhanced_features = get_enhanced_features_list()
    
    # å®Ÿéš›ã«å­˜åœ¨ã™ã‚‹ç‰¹å¾´é‡ã®ã¿ã‚’é¸æŠ
    available_features = [col for col in enhanced_features if col in df.columns]
    missing_features = [col for col in enhanced_features if col not in df.columns]
    
    logger.info(f"âœ… åˆ©ç”¨å¯èƒ½ãªç‰¹å¾´é‡: {len(available_features)}/{len(enhanced_features)}")
    
    if missing_features:
        logger.warning(f"âš ï¸ ä¸è¶³ã—ã¦ã„ã‚‹ç‰¹å¾´é‡: {len(missing_features)}å€‹")
        for feature in missing_features[:5]:  # æœ€åˆã®5å€‹ã®ã¿è¡¨ç¤º
            logger.warning(f"  - {feature}")
        if len(missing_features) > 5:
            logger.warning(f"  ... ãã®ä»– {len(missing_features) - 5}å€‹")
    
    # ç„¡é™å€¤ãƒ»ç•°å¸¸å€¤ã®ãƒã‚§ãƒƒã‚¯
    inf_count = np.isinf(df.select_dtypes(include=[np.number])).sum().sum()
    if inf_count > 0:
        logger.warning(f"âš ï¸ ç„¡é™å€¤ã‚’æ¤œå‡º: {inf_count}å€‹")
        df = df.replace([np.inf, -np.inf], np.nan)
    
    # åˆ†æ•£ãŒ0ã®ç‰¹å¾´é‡ã‚’ãƒã‚§ãƒƒã‚¯
    numeric_df = df.select_dtypes(include=[np.number])
    zero_variance_cols = [col for col in numeric_df.columns if numeric_df[col].var() == 0]
    
    if zero_variance_cols:
        logger.warning(f"âš ï¸ åˆ†æ•£0ã®ç‰¹å¾´é‡ã‚’æ¤œå‡º: {len(zero_variance_cols)}å€‹")
        for col in zero_variance_cols:
            logger.warning(f"  - {col}")
    
    return df, available_features

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    input_file = preprocessing_config.get('input_file', 'stock_data.csv')
    output_file = preprocessing_config.get('output_file', 'processed_stock_data.csv')
    
    try:
        logger.info("ğŸš€ ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚’é–‹å§‹")
        
        # 1. ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        df = load_and_clean_data(input_file)
        
        # 2. åŸºæœ¬çš„ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
        df = engineer_basic_features(df)
        
        # 3. é«˜åº¦ãªæŠ€è¡“æŒ‡æ¨™ã«ã‚ˆã‚‹ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
        df = engineer_advanced_features(df)
        
        # 4. ç‰¹å¾´é‡é¸æŠã¨æ¤œè¨¼
        df, available_features = feature_selection_and_validation(df)
        
        # 5. æ¬ æå€¤ã®æœ€çµ‚å‡¦ç†
        initial_rows = len(df)
        df = df.dropna()
        final_rows = len(df)
        dropped_rows = initial_rows - final_rows
        
        if dropped_rows > 0:
            logger.info(f"ğŸ—‘ï¸ æ¬ æå€¤ã‚’å«ã‚€è¡Œã‚’å‰Šé™¤: {initial_rows} -> {final_rows} è¡Œ ({dropped_rows} è¡Œå‰Šé™¤)")
        
        # 6. ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
        df.to_csv(output_file, index=False)
        logger.info(f"ğŸ’¾ å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜: {output_file}")
        
        # 7. æœ€çµ‚çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
        logger.info("ğŸ“Š æœ€çµ‚ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ:")
        logger.info(f"  ğŸ“ ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {df.shape}")
        logger.info(f"  ğŸ“… ãƒ‡ãƒ¼ã‚¿æœŸé–“: {df['Date'].min()} ï½ {df['Date'].max()}")
        logger.info(f"  ğŸ“ˆ ç‰¹å¾´é‡æ•°: {len(df.columns)}å€‹")
        logger.info(f"  ğŸ¯ æ¨å¥¨ç‰¹å¾´é‡: {len(available_features)}å€‹")
        
        # ç‰¹å¾´é‡ãƒªã‚¹ãƒˆã‚’ä¿å­˜ï¼ˆå‚è€ƒç”¨ï¼‰
        feature_list_file = output_file.replace('.csv', '_features.txt')
        with open(feature_list_file, 'w', encoding='utf-8') as f:
            f.write("# åˆ©ç”¨å¯èƒ½ãªç‰¹å¾´é‡ãƒªã‚¹ãƒˆ\n")
            f.write(f"# ç”Ÿæˆæ—¥æ™‚: {pd.Timestamp.now()}\n")
            f.write(f"# ç·ç‰¹å¾´é‡æ•°: {len(available_features)}\n\n")
            for i, feature in enumerate(available_features, 1):
                f.write(f"{i:3d}. {feature}\n")
        
        logger.info(f"ğŸ“ ç‰¹å¾´é‡ãƒªã‚¹ãƒˆã‚’ä¿å­˜: {feature_list_file}")
        logger.info("âœ… ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
        
    except Exception as e:
        logger.error(f"âŒ å‰å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        raise

if __name__ == "__main__":
    main()