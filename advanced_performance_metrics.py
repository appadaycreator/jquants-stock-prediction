#!/usr/bin/env python3
"""
é«˜åº¦ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã‚·ã‚¹ãƒ†ãƒ 
è©³ç´°ãªãƒªã‚¹ã‚¯åˆ†æã€çµ±è¨ˆæŒ‡æ¨™ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡

æ©Ÿèƒ½:
1. è©³ç´°ãªãƒªã‚¹ã‚¯æŒ‡æ¨™è¨ˆç®—
2. çµ±è¨ˆçš„æ¤œå®š
3. ãƒªã‚¹ã‚¯èª¿æ•´ãƒªã‚¿ãƒ¼ãƒ³
4. ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ
5. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†è§£
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Any
import json
import logging
from dataclasses import dataclass, asdict
from scipy import stats
from scipy.optimize import minimize
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

warnings.filterwarnings("ignore")

logger = logging.getLogger(__name__)


@dataclass
class AdvancedMetrics:
    """é«˜åº¦ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™"""

    # åŸºæœ¬æŒ‡æ¨™
    total_return: float
    annualized_return: float
    volatility: float
    sharpe_ratio: float
    sortino_ratio: float
    calmar_ratio: float

    # ãƒªã‚¹ã‚¯æŒ‡æ¨™
    max_drawdown: float
    max_drawdown_duration: int
    var_95: float  # Value at Risk 95%
    var_99: float  # Value at Risk 99%
    cvar_95: float  # Conditional VaR 95%
    cvar_99: float  # Conditional VaR 99%
    tail_ratio: float

    # çµ±è¨ˆæŒ‡æ¨™
    skewness: float
    kurtosis: float
    jarque_bera_stat: float
    jarque_bera_pvalue: float

    # ãƒªã‚¹ã‚¯èª¿æ•´æŒ‡æ¨™
    information_ratio: float
    treynor_ratio: float
    jensen_alpha: float
    beta: float
    tracking_error: float

    # åˆ†æ•£åˆ†æ
    systematic_risk: float
    unsystematic_risk: float
    r_squared: float

    # ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ
    worst_month: float
    worst_quarter: float
    worst_year: float
    consecutive_losses: int
    recovery_time: int

    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†è§£
    alpha: float
    beta_return: float
    residual_return: float
    market_timing: float
    stock_selection: float


class AdvancedPerformanceAnalyzer:
    """é«˜åº¦ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã‚¯ãƒ©ã‚¹"""

    def __init__(
        self,
        risk_free_rate: float = 0.02,
        benchmark_returns: Optional[pd.Series] = None,
    ):
        self.risk_free_rate = risk_free_rate
        self.benchmark_returns = benchmark_returns

    def calculate_advanced_metrics(
        self,
        returns: pd.Series,
        equity_curve: pd.Series,
        benchmark_returns: Optional[pd.Series] = None,
    ) -> AdvancedMetrics:
        """é«˜åº¦ãªæŒ‡æ¨™è¨ˆç®—"""
        logger.info("é«˜åº¦ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™è¨ˆç®—é–‹å§‹")

        # åŸºæœ¬æŒ‡æ¨™
        basic_metrics = self._calculate_basic_metrics(returns, equity_curve)

        # ãƒªã‚¹ã‚¯æŒ‡æ¨™
        risk_metrics = self._calculate_risk_metrics(returns, equity_curve)

        # çµ±è¨ˆæŒ‡æ¨™
        statistical_metrics = self._calculate_statistical_metrics(returns)

        # ãƒªã‚¹ã‚¯èª¿æ•´æŒ‡æ¨™
        risk_adjusted_metrics = self._calculate_risk_adjusted_metrics(
            returns, benchmark_returns
        )

        # åˆ†æ•£åˆ†æ
        variance_metrics = self._calculate_variance_analysis(returns, benchmark_returns)

        # ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ
        stress_metrics = self._calculate_stress_test(returns, equity_curve)

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†è§£
        performance_decomposition = self._calculate_performance_decomposition(
            returns, benchmark_returns
        )

        return AdvancedMetrics(
            # åŸºæœ¬æŒ‡æ¨™
            total_return=basic_metrics["total_return"],
            annualized_return=basic_metrics["annualized_return"],
            volatility=basic_metrics["volatility"],
            sharpe_ratio=basic_metrics["sharpe_ratio"],
            sortino_ratio=basic_metrics["sortino_ratio"],
            calmar_ratio=basic_metrics["calmar_ratio"],
            # ãƒªã‚¹ã‚¯æŒ‡æ¨™
            max_drawdown=risk_metrics["max_drawdown"],
            max_drawdown_duration=risk_metrics["max_drawdown_duration"],
            var_95=risk_metrics["var_95"],
            var_99=risk_metrics["var_99"],
            cvar_95=risk_metrics["cvar_95"],
            cvar_99=risk_metrics["cvar_99"],
            tail_ratio=risk_metrics["tail_ratio"],
            # çµ±è¨ˆæŒ‡æ¨™
            skewness=statistical_metrics["skewness"],
            kurtosis=statistical_metrics["kurtosis"],
            jarque_bera_stat=statistical_metrics["jarque_bera_stat"],
            jarque_bera_pvalue=statistical_metrics["jarque_bera_pvalue"],
            # ãƒªã‚¹ã‚¯èª¿æ•´æŒ‡æ¨™
            information_ratio=risk_adjusted_metrics["information_ratio"],
            treynor_ratio=risk_adjusted_metrics["treynor_ratio"],
            jensen_alpha=risk_adjusted_metrics["jensen_alpha"],
            beta=risk_adjusted_metrics["beta"],
            tracking_error=risk_adjusted_metrics["tracking_error"],
            # åˆ†æ•£åˆ†æ
            systematic_risk=variance_metrics["systematic_risk"],
            unsystematic_risk=variance_metrics["unsystematic_risk"],
            r_squared=variance_metrics["r_squared"],
            # ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ
            worst_month=stress_metrics["worst_month"],
            worst_quarter=stress_metrics["worst_quarter"],
            worst_year=stress_metrics["worst_year"],
            consecutive_losses=stress_metrics["consecutive_losses"],
            recovery_time=stress_metrics["recovery_time"],
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†è§£
            alpha=performance_decomposition["alpha"],
            beta_return=performance_decomposition["beta_return"],
            residual_return=performance_decomposition["residual_return"],
            market_timing=performance_decomposition["market_timing"],
            stock_selection=performance_decomposition["stock_selection"],
        )

    def _calculate_basic_metrics(
        self, returns: pd.Series, equity_curve: pd.Series
    ) -> Dict[str, float]:
        """åŸºæœ¬æŒ‡æ¨™è¨ˆç®—"""
        total_return = (equity_curve.iloc[-1] / equity_curve.iloc[0]) - 1
        annualized_return = (1 + total_return) ** (252 / len(returns)) - 1
        volatility = returns.std() * np.sqrt(252)

        # ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª
        excess_returns = returns - self.risk_free_rate / 252
        sharpe_ratio = (
            excess_returns.mean() / returns.std() * np.sqrt(252)
            if returns.std() > 0
            else 0
        )

        # ã‚½ãƒ«ãƒ†ã‚£ãƒãƒ¬ã‚·ã‚ªï¼ˆä¸‹æ–¹ãƒªã‚¹ã‚¯èª¿æ•´ï¼‰
        downside_returns = returns[returns < 0]
        downside_volatility = (
            downside_returns.std() * np.sqrt(252) if len(downside_returns) > 0 else 0
        )
        sortino_ratio = (
            (annualized_return - self.risk_free_rate) / downside_volatility
            if downside_volatility > 0
            else 0
        )

        # ã‚«ãƒ«ãƒãƒ¼ãƒ¬ã‚·ã‚ª
        peak = equity_curve.expanding().max()
        drawdown = (equity_curve - peak) / peak
        max_drawdown = abs(drawdown.min())
        calmar_ratio = annualized_return / max_drawdown if max_drawdown > 0 else 0

        return {
            "total_return": total_return,
            "annualized_return": annualized_return,
            "volatility": volatility,
            "sharpe_ratio": sharpe_ratio,
            "sortino_ratio": sortino_ratio,
            "calmar_ratio": calmar_ratio,
        }

    def _calculate_risk_metrics(
        self, returns: pd.Series, equity_curve: pd.Series
    ) -> Dict[str, float]:
        """ãƒªã‚¹ã‚¯æŒ‡æ¨™è¨ˆç®—"""
        # æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³
        peak = equity_curve.expanding().max()
        drawdown = (equity_curve - peak) / peak
        max_drawdown = abs(drawdown.min())

        # æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³æœŸé–“
        max_dd_duration = self._calculate_max_drawdown_duration(drawdown)

        # VaRè¨ˆç®—
        var_95 = np.percentile(returns, 5)
        var_99 = np.percentile(returns, 1)

        # CVaRè¨ˆç®—
        cvar_95 = (
            returns[returns <= var_95].mean()
            if len(returns[returns <= var_95]) > 0
            else 0
        )
        cvar_99 = (
            returns[returns <= var_99].mean()
            if len(returns[returns <= var_99]) > 0
            else 0
        )

        # ãƒ†ãƒ¼ãƒ«ãƒ¬ã‚·ã‚ª
        tail_ratio = abs(var_95 / var_99) if var_99 != 0 else 0

        return {
            "max_drawdown": max_drawdown,
            "max_drawdown_duration": max_dd_duration,
            "var_95": var_95,
            "var_99": var_99,
            "cvar_95": cvar_95,
            "cvar_99": cvar_99,
            "tail_ratio": tail_ratio,
        }

    def _calculate_max_drawdown_duration(self, drawdown: pd.Series) -> int:
        """æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³æœŸé–“è¨ˆç®—"""
        in_drawdown = drawdown < 0
        drawdown_periods = []
        current_period = 0

        for is_dd in in_drawdown:
            if is_dd:
                current_period += 1
            else:
                if current_period > 0:
                    drawdown_periods.append(current_period)
                current_period = 0

        if current_period > 0:
            drawdown_periods.append(current_period)

        return max(drawdown_periods) if drawdown_periods else 0

    def _calculate_statistical_metrics(self, returns: pd.Series) -> Dict[str, float]:
        """çµ±è¨ˆæŒ‡æ¨™è¨ˆç®—"""
        # æ­ªåº¦ãƒ»å°–åº¦
        skewness = returns.skew()
        kurtosis = returns.kurtosis()

        # Jarque-Beraæ¤œå®šï¼ˆæ­£è¦æ€§æ¤œå®šï¼‰
        jb_stat, jb_pvalue = stats.jarque_bera(returns.dropna())

        return {
            "skewness": skewness,
            "kurtosis": kurtosis,
            "jarque_bera_stat": jb_stat,
            "jarque_bera_pvalue": jb_pvalue,
        }

    def _calculate_risk_adjusted_metrics(
        self, returns: pd.Series, benchmark_returns: Optional[pd.Series]
    ) -> Dict[str, float]:
        """ãƒªã‚¹ã‚¯èª¿æ•´æŒ‡æ¨™è¨ˆç®—"""
        if benchmark_returns is None:
            return {
                "information_ratio": 0,
                "treynor_ratio": 0,
                "jensen_alpha": 0,
                "beta": 0,
                "tracking_error": 0,
            }

        # å…±é€šæœŸé–“ã§ãƒ‡ãƒ¼ã‚¿ã‚’æƒãˆã‚‹
        common_index = returns.index.intersection(benchmark_returns.index)
        if len(common_index) == 0:
            return {
                "information_ratio": 0,
                "treynor_ratio": 0,
                "jensen_alpha": 0,
                "beta": 0,
                "tracking_error": 0,
            }

        aligned_returns = returns.loc[common_index]
        aligned_benchmark = benchmark_returns.loc[common_index]

        # ãƒ™ãƒ¼ã‚¿è¨ˆç®—
        covariance = np.cov(aligned_returns, aligned_benchmark)[0, 1]
        benchmark_variance = np.var(aligned_benchmark)
        beta = covariance / benchmark_variance if benchmark_variance > 0 else 0

        # ã‚¢ãƒ«ãƒ•ã‚¡è¨ˆç®—
        alpha = aligned_returns.mean() - (
            self.risk_free_rate / 252
            + beta * (aligned_benchmark.mean() - self.risk_free_rate / 252)
        )

        # æƒ…å ±ãƒ¬ã‚·ã‚ª
        excess_returns = aligned_returns - aligned_benchmark
        tracking_error = excess_returns.std() * np.sqrt(252)
        information_ratio = (
            excess_returns.mean() / excess_returns.std() * np.sqrt(252)
            if excess_returns.std() > 0
            else 0
        )

        # ãƒˆãƒ¬ã‚¤ãƒŠãƒ¼ãƒ¬ã‚·ã‚ª
        treynor_ratio = (
            (aligned_returns.mean() * 252 - self.risk_free_rate) / beta
            if beta > 0
            else 0
        )

        return {
            "information_ratio": information_ratio,
            "treynor_ratio": treynor_ratio,
            "jensen_alpha": alpha,
            "beta": beta,
            "tracking_error": tracking_error,
        }

    def _calculate_variance_analysis(
        self, returns: pd.Series, benchmark_returns: Optional[pd.Series]
    ) -> Dict[str, float]:
        """åˆ†æ•£åˆ†æ"""
        if benchmark_returns is None:
            return {"systematic_risk": 0, "unsystematic_risk": 0, "r_squared": 0}

        # å…±é€šæœŸé–“ã§ãƒ‡ãƒ¼ã‚¿ã‚’æƒãˆã‚‹
        common_index = returns.index.intersection(benchmark_returns.index)
        if len(common_index) == 0:
            return {"systematic_risk": 0, "unsystematic_risk": 0, "r_squared": 0}

        aligned_returns = returns.loc[common_index]
        aligned_benchmark = benchmark_returns.loc[common_index]

        # å›å¸°åˆ†æ
        slope, intercept, r_value, p_value, std_err = stats.linregress(
            aligned_benchmark, aligned_returns
        )

        # åˆ†æ•£åˆ†è§£
        total_variance = np.var(aligned_returns)
        systematic_risk = (slope**2) * np.var(aligned_benchmark)
        unsystematic_risk = total_variance - systematic_risk

        return {
            "systematic_risk": systematic_risk,
            "unsystematic_risk": unsystematic_risk,
            "r_squared": r_value**2,
        }

    def _calculate_stress_test(
        self, returns: pd.Series, equity_curve: pd.Series
    ) -> Dict[str, float]:
        """ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ"""
        # æœˆæ¬¡ãƒªã‚¿ãƒ¼ãƒ³
        monthly_returns = equity_curve.resample("M").last().pct_change().dropna()
        worst_month = monthly_returns.min() if len(monthly_returns) > 0 else 0

        # å››åŠæœŸãƒªã‚¿ãƒ¼ãƒ³
        quarterly_returns = equity_curve.resample("Q").last().pct_change().dropna()
        worst_quarter = quarterly_returns.min() if len(quarterly_returns) > 0 else 0

        # å¹´æ¬¡ãƒªã‚¿ãƒ¼ãƒ³
        yearly_returns = equity_curve.resample("Y").last().pct_change().dropna()
        worst_year = yearly_returns.min() if len(yearly_returns) > 0 else 0

        # é€£ç¶šæå¤±
        consecutive_losses = self._calculate_consecutive_losses(returns)

        # å›å¾©æ™‚é–“
        recovery_time = self._calculate_recovery_time(equity_curve)

        return {
            "worst_month": worst_month,
            "worst_quarter": worst_quarter,
            "worst_year": worst_year,
            "consecutive_losses": consecutive_losses,
            "recovery_time": recovery_time,
        }

    def _calculate_consecutive_losses(self, returns: pd.Series) -> int:
        """é€£ç¶šæå¤±è¨ˆç®—"""
        negative_returns = returns < 0
        max_consecutive = 0
        current_consecutive = 0

        for is_negative in negative_returns:
            if is_negative:
                current_consecutive += 1
                max_consecutive = max(max_consecutive, current_consecutive)
            else:
                current_consecutive = 0

        return max_consecutive

    def _calculate_recovery_time(self, equity_curve: pd.Series) -> int:
        """å›å¾©æ™‚é–“è¨ˆç®—"""
        peak = equity_curve.expanding().max()
        drawdown = (equity_curve - peak) / peak

        max_dd_idx = drawdown.idxmin()
        recovery_idx = None

        for idx in equity_curve.index[equity_curve.index > max_dd_idx]:
            if equity_curve.loc[idx] >= peak.loc[max_dd_idx]:
                recovery_idx = idx
                break

        if recovery_idx:
            return (recovery_idx - max_dd_idx).days
        else:
            return len(equity_curve) - equity_curve.index.get_loc(max_dd_idx)

    def _calculate_performance_decomposition(
        self, returns: pd.Series, benchmark_returns: Optional[pd.Series]
    ) -> Dict[str, float]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†è§£"""
        if benchmark_returns is None:
            return {
                "alpha": 0,
                "beta_return": 0,
                "residual_return": 0,
                "market_timing": 0,
                "stock_selection": 0,
            }

        # å…±é€šæœŸé–“ã§ãƒ‡ãƒ¼ã‚¿ã‚’æƒãˆã‚‹
        common_index = returns.index.intersection(benchmark_returns.index)
        if len(common_index) == 0:
            return {
                "alpha": 0,
                "beta_return": 0,
                "residual_return": 0,
                "market_timing": 0,
                "stock_selection": 0,
            }

        aligned_returns = returns.loc[common_index]
        aligned_benchmark = benchmark_returns.loc[common_index]

        # å›å¸°åˆ†æ
        slope, intercept, r_value, p_value, std_err = stats.linregress(
            aligned_benchmark, aligned_returns
        )

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†è§£
        alpha = intercept
        beta_return = slope * aligned_benchmark.mean()
        residual_return = aligned_returns.mean() - alpha - beta_return

        # å¸‚å ´ã‚¿ã‚¤ãƒŸãƒ³ã‚°åŠ¹æœï¼ˆç°¡æ˜“ç‰ˆï¼‰
        market_timing = 0  # ã‚ˆã‚Šè¤‡é›‘ãªè¨ˆç®—ãŒå¿…è¦

        # éŠ˜æŸ„é¸æŠåŠ¹æœ
        stock_selection = alpha + residual_return

        return {
            "alpha": alpha,
            "beta_return": beta_return,
            "residual_return": residual_return,
            "market_timing": market_timing,
            "stock_selection": stock_selection,
        }


class PerformanceVisualizer:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å¯è¦–åŒ–ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.setup_style()

    def setup_style(self):
        """ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š"""
        plt.style.use("seaborn-v0_8")
        sns.set_palette("husl")

    def plot_comprehensive_analysis(
        self,
        returns: pd.Series,
        equity_curve: pd.Series,
        metrics: AdvancedMetrics,
        save_path: str = None,
    ):
        """åŒ…æ‹¬çš„åˆ†æãƒ—ãƒ­ãƒƒãƒˆ"""
        fig, axes = plt.subplots(3, 3, figsize=(20, 15))
        fig.suptitle("é«˜åº¦ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ", fontsize=16, fontweight="bold")

        # 1. ã‚¨ã‚¯ã‚¤ãƒ†ã‚£ã‚«ãƒ¼ãƒ–
        axes[0, 0].plot(
            equity_curve.index, equity_curve.values, linewidth=2, color="blue"
        )
        axes[0, 0].set_title("ã‚¨ã‚¯ã‚¤ãƒ†ã‚£ã‚«ãƒ¼ãƒ–")
        axes[0, 0].set_ylabel("ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªä¾¡å€¤")
        axes[0, 0].grid(True, alpha=0.3)

        # 2. ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³
        peak = equity_curve.expanding().max()
        drawdown = (equity_curve - peak) / peak * 100
        axes[0, 1].fill_between(equity_curve.index, drawdown, 0, alpha=0.7, color="red")
        axes[0, 1].set_title(f"ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ (æœ€å¤§: {metrics.max_drawdown:.1%})")
        axes[0, 1].set_ylabel("ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ (%)")
        axes[0, 1].grid(True, alpha=0.3)

        # 3. ãƒªã‚¿ãƒ¼ãƒ³åˆ†å¸ƒ
        axes[0, 2].hist(
            returns * 100, bins=30, alpha=0.7, color="skyblue", edgecolor="black"
        )
        axes[0, 2].axvline(
            returns.mean() * 100,
            color="red",
            linestyle="--",
            label=f"å¹³å‡: {returns.mean()*100:.2f}%",
        )
        axes[0, 2].set_title("ãƒªã‚¿ãƒ¼ãƒ³åˆ†å¸ƒ")
        axes[0, 2].set_xlabel("ãƒªã‚¿ãƒ¼ãƒ³ (%)")
        axes[0, 2].set_ylabel("é »åº¦")
        axes[0, 2].legend()
        axes[0, 2].grid(True, alpha=0.3)

        # 4. ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³
        cumulative_returns = (1 + returns).cumprod() - 1
        axes[1, 0].plot(
            cumulative_returns.index,
            cumulative_returns.values * 100,
            linewidth=2,
            color="green",
        )
        axes[1, 0].set_title("ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³")
        axes[1, 0].set_ylabel("ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³ (%)")
        axes[1, 0].grid(True, alpha=0.3)

        # 5. æœˆæ¬¡ãƒªã‚¿ãƒ¼ãƒ³
        monthly_returns = equity_curve.resample("M").last().pct_change().dropna() * 100
        colors = ["green" if x > 0 else "red" for x in monthly_returns.values]
        axes[1, 1].bar(
            range(len(monthly_returns)), monthly_returns.values, color=colors, alpha=0.7
        )
        axes[1, 1].set_title("æœˆæ¬¡ãƒªã‚¿ãƒ¼ãƒ³")
        axes[1, 1].set_ylabel("ãƒªã‚¿ãƒ¼ãƒ³ (%)")
        axes[1, 1].grid(True, alpha=0.3)

        # 6. ãƒªã‚¹ã‚¯æŒ‡æ¨™
        risk_metrics = ["VaR 95%", "VaR 99%", "CVaR 95%", "CVaR 99%"]
        risk_values = [
            metrics.var_95 * 100,
            metrics.var_99 * 100,
            metrics.cvar_95 * 100,
            metrics.cvar_99 * 100,
        ]
        bars = axes[1, 2].bar(
            risk_metrics, risk_values, color=["lightcoral", "red", "darkred", "maroon"]
        )
        axes[1, 2].set_title("ãƒªã‚¹ã‚¯æŒ‡æ¨™")
        axes[1, 2].set_ylabel("ãƒªã‚¿ãƒ¼ãƒ³ (%)")
        axes[1, 2].tick_params(axis="x", rotation=45)
        for bar, value in zip(bars, risk_values):
            axes[1, 2].text(
                bar.get_x() + bar.get_width() / 2,
                bar.get_height() + 0.01,
                f"{value:.2f}%",
                ha="center",
                va="bottom",
            )

        # 7. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™
        perf_metrics = ["ã‚·ãƒ£ãƒ¼ãƒ—", "ã‚½ãƒ«ãƒ†ã‚£ãƒ", "ã‚«ãƒ«ãƒãƒ¼", "æƒ…å ±ãƒ¬ã‚·ã‚ª"]
        perf_values = [
            metrics.sharpe_ratio,
            metrics.sortino_ratio,
            metrics.calmar_ratio,
            metrics.information_ratio,
        ]
        bars = axes[2, 0].bar(
            perf_metrics,
            perf_values,
            color=["skyblue", "lightgreen", "orange", "purple"],
        )
        axes[2, 0].set_title("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™")
        axes[2, 0].set_ylabel("ãƒ¬ã‚·ã‚ª")
        for bar, value in zip(bars, perf_values):
            axes[2, 0].text(
                bar.get_x() + bar.get_width() / 2,
                bar.get_height() + 0.01,
                f"{value:.2f}",
                ha="center",
                va="bottom",
            )

        # 8. çµ±è¨ˆæŒ‡æ¨™
        stat_metrics = ["æ­ªåº¦", "å°–åº¦", "JBçµ±è¨ˆé‡", "JB på€¤"]
        stat_values = [
            metrics.skewness,
            metrics.kurtosis,
            metrics.jarque_bera_stat,
            metrics.jarque_bera_pvalue,
        ]
        bars = axes[2, 1].bar(
            stat_metrics,
            stat_values,
            color=["lightblue", "lightcoral", "lightgreen", "lightyellow"],
        )
        axes[2, 1].set_title("çµ±è¨ˆæŒ‡æ¨™")
        axes[2, 1].set_ylabel("å€¤")
        axes[2, 1].tick_params(axis="x", rotation=45)
        for bar, value in zip(bars, stat_values):
            axes[2, 1].text(
                bar.get_x() + bar.get_width() / 2,
                bar.get_height() + 0.01,
                f"{value:.2f}",
                ha="center",
                va="bottom",
            )

        # 9. ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ
        stress_metrics = ["æœ€æ‚ªæœˆ", "æœ€æ‚ªå››åŠæœŸ", "æœ€æ‚ªå¹´", "é€£ç¶šæå¤±", "å›å¾©æ™‚é–“"]
        stress_values = [
            metrics.worst_month * 100,
            metrics.worst_quarter * 100,
            metrics.worst_year * 100,
            metrics.consecutive_losses,
            metrics.recovery_time,
        ]
        bars = axes[2, 2].bar(
            stress_metrics,
            stress_values,
            color=["red", "darkred", "maroon", "orange", "yellow"],
        )
        axes[2, 2].set_title("ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ")
        axes[2, 2].set_ylabel("å€¤")
        axes[2, 2].tick_params(axis="x", rotation=45)
        for bar, value in zip(bars, stress_values):
            axes[2, 2].text(
                bar.get_x() + bar.get_width() / 2,
                bar.get_height() + 0.01,
                f"{value:.1f}",
                ha="center",
                va="bottom",
            )

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches="tight")
            logger.info(f"åŒ…æ‹¬çš„åˆ†æã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {save_path}")

        plt.show()

    def plot_risk_analysis(
        self, returns: pd.Series, metrics: AdvancedMetrics, save_path: str = None
    ):
        """ãƒªã‚¹ã‚¯åˆ†æãƒ—ãƒ­ãƒƒãƒˆ"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle("ãƒªã‚¹ã‚¯åˆ†æ", fontsize=16, fontweight="bold")

        # 1. VaRåˆ†æ
        axes[0, 0].hist(
            returns * 100, bins=50, alpha=0.7, color="skyblue", density=True
        )
        axes[0, 0].axvline(
            metrics.var_95 * 100,
            color="red",
            linestyle="--",
            label=f"VaR 95%: {metrics.var_95*100:.2f}%",
        )
        axes[0, 0].axvline(
            metrics.var_99 * 100,
            color="darkred",
            linestyle="--",
            label=f"VaR 99%: {metrics.var_99*100:.2f}%",
        )
        axes[0, 0].set_title("VaRåˆ†æ")
        axes[0, 0].set_xlabel("ãƒªã‚¿ãƒ¼ãƒ³ (%)")
        axes[0, 0].set_ylabel("å¯†åº¦")
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)

        # 2. ãƒ†ãƒ¼ãƒ«ãƒªã‚¹ã‚¯
        tail_returns = returns[returns <= metrics.var_95]
        axes[0, 1].hist(
            tail_returns * 100, bins=20, alpha=0.7, color="red", edgecolor="black"
        )
        axes[0, 1].axvline(
            metrics.cvar_95 * 100,
            color="darkred",
            linestyle="--",
            label=f"CVaR 95%: {metrics.cvar_95*100:.2f}%",
        )
        axes[0, 1].set_title("ãƒ†ãƒ¼ãƒ«ãƒªã‚¹ã‚¯åˆ†æ")
        axes[0, 1].set_xlabel("ãƒªã‚¿ãƒ¼ãƒ³ (%)")
        axes[0, 1].set_ylabel("é »åº¦")
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)

        # 3. ãƒªã‚¹ã‚¯æŒ‡æ¨™æ¯”è¼ƒ
        risk_indicators = [
            "VaR 95%",
            "VaR 99%",
            "CVaR 95%",
            "CVaR 99%",
            "æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³",
        ]
        risk_values = [
            abs(metrics.var_95) * 100,
            abs(metrics.var_99) * 100,
            abs(metrics.cvar_95) * 100,
            abs(metrics.cvar_99) * 100,
            metrics.max_drawdown * 100,
        ]
        bars = axes[1, 0].bar(
            risk_indicators,
            risk_values,
            color=["lightcoral", "red", "darkred", "maroon", "black"],
        )
        axes[1, 0].set_title("ãƒªã‚¹ã‚¯æŒ‡æ¨™æ¯”è¼ƒ")
        axes[1, 0].set_ylabel("ãƒªã‚¹ã‚¯ (%)")
        axes[1, 0].tick_params(axis="x", rotation=45)
        for bar, value in zip(bars, risk_values):
            axes[1, 0].text(
                bar.get_x() + bar.get_width() / 2,
                bar.get_height() + 0.01,
                f"{value:.2f}%",
                ha="center",
                va="bottom",
            )

        # 4. ãƒªã‚¹ã‚¯èª¿æ•´ãƒªã‚¿ãƒ¼ãƒ³
        risk_adjusted_metrics = [
            "ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª",
            "ã‚½ãƒ«ãƒ†ã‚£ãƒãƒ¬ã‚·ã‚ª",
            "ã‚«ãƒ«ãƒãƒ¼ãƒ¬ã‚·ã‚ª",
            "æƒ…å ±ãƒ¬ã‚·ã‚ª",
        ]
        risk_adjusted_values = [
            metrics.sharpe_ratio,
            metrics.sortino_ratio,
            metrics.calmar_ratio,
            metrics.information_ratio,
        ]
        bars = axes[1, 1].bar(
            risk_adjusted_metrics,
            risk_adjusted_values,
            color=["skyblue", "lightgreen", "orange", "purple"],
        )
        axes[1, 1].set_title("ãƒªã‚¹ã‚¯èª¿æ•´ãƒªã‚¿ãƒ¼ãƒ³")
        axes[1, 1].set_ylabel("ãƒ¬ã‚·ã‚ª")
        axes[1, 1].tick_params(axis="x", rotation=45)
        for bar, value in zip(bars, risk_adjusted_values):
            axes[1, 1].text(
                bar.get_x() + bar.get_width() / 2,
                bar.get_height() + 0.01,
                f"{value:.2f}",
                ha="center",
                va="bottom",
            )

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches="tight")
            logger.info(f"ãƒªã‚¹ã‚¯åˆ†æã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {save_path}")

        plt.show()


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    logger.info("=== é«˜åº¦ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹ ===")

    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    np.random.seed(42)
    dates = pd.date_range("2020-01-01", "2023-12-31", freq="D")
    returns = np.random.normal(0.0005, 0.02, len(dates))  # æ—¥æ¬¡ãƒªã‚¿ãƒ¼ãƒ³
    equity_curve = pd.Series(1000000 * (1 + returns).cumprod(), index=dates)
    returns_series = pd.Series(returns, index=dates)

    # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ï¼ˆç°¡æ˜“ç‰ˆï¼‰
    benchmark_returns = np.random.normal(0.0003, 0.015, len(dates))
    benchmark_series = pd.Series(benchmark_returns, index=dates)

    # é«˜åº¦ãªæŒ‡æ¨™è¨ˆç®—
    analyzer = AdvancedPerformanceAnalyzer(
        risk_free_rate=0.02, benchmark_returns=benchmark_series
    )
    metrics = analyzer.calculate_advanced_metrics(
        returns_series, equity_curve, benchmark_series
    )

    # çµæœè¡¨ç¤º
    print("=" * 80)
    print("ğŸ“Š é«˜åº¦ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™")
    print("=" * 80)

    print(f"\nğŸ’° åŸºæœ¬æŒ‡æ¨™:")
    print(f"  ç·ãƒªã‚¿ãƒ¼ãƒ³: {metrics.total_return:.2%}")
    print(f"  å¹´ç‡ãƒªã‚¿ãƒ¼ãƒ³: {metrics.annualized_return:.2%}")
    print(f"  ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: {metrics.volatility:.2%}")
    print(f"  ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª: {metrics.sharpe_ratio:.2f}")
    print(f"  ã‚½ãƒ«ãƒ†ã‚£ãƒãƒ¬ã‚·ã‚ª: {metrics.sortino_ratio:.2f}")
    print(f"  ã‚«ãƒ«ãƒãƒ¼ãƒ¬ã‚·ã‚ª: {metrics.calmar_ratio:.2f}")

    print(f"\nâš ï¸ ãƒªã‚¹ã‚¯æŒ‡æ¨™:")
    print(f"  æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³: {metrics.max_drawdown:.2%}")
    print(f"  æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³æœŸé–“: {metrics.max_drawdown_duration}æ—¥")
    print(f"  VaR 95%: {metrics.var_95:.2%}")
    print(f"  VaR 99%: {metrics.var_99:.2%}")
    print(f"  CVaR 95%: {metrics.cvar_95:.2%}")
    print(f"  CVaR 99%: {metrics.cvar_99:.2%}")
    print(f"  ãƒ†ãƒ¼ãƒ«ãƒ¬ã‚·ã‚ª: {metrics.tail_ratio:.2f}")

    print(f"\nğŸ“ˆ çµ±è¨ˆæŒ‡æ¨™:")
    print(f"  æ­ªåº¦: {metrics.skewness:.2f}")
    print(f"  å°–åº¦: {metrics.kurtosis:.2f}")
    print(f"  Jarque-Beraçµ±è¨ˆé‡: {metrics.jarque_bera_stat:.2f}")
    print(f"  Jarque-Bera på€¤: {metrics.jarque_bera_pvalue:.4f}")

    print(f"\nğŸ¯ ãƒªã‚¹ã‚¯èª¿æ•´æŒ‡æ¨™:")
    print(f"  æƒ…å ±ãƒ¬ã‚·ã‚ª: {metrics.information_ratio:.2f}")
    print(f"  ãƒˆãƒ¬ã‚¤ãƒŠãƒ¼ãƒ¬ã‚·ã‚ª: {metrics.treynor_ratio:.2f}")
    print(f"  ã‚¸ã‚§ãƒ³ã‚»ãƒ³ã®ã‚¢ãƒ«ãƒ•ã‚¡: {metrics.jensen_alpha:.2%}")
    print(f"  ãƒ™ãƒ¼ã‚¿: {metrics.beta:.2f}")
    print(f"  ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {metrics.tracking_error:.2%}")

    print(f"\nğŸ“Š åˆ†æ•£åˆ†æ:")
    print(f"  ã‚·ã‚¹ãƒ†ãƒãƒ†ã‚£ãƒƒã‚¯ãƒªã‚¹ã‚¯: {metrics.systematic_risk:.4f}")
    print(f"  ã‚¢ãƒ³ã‚·ã‚¹ãƒ†ãƒãƒ†ã‚£ãƒƒã‚¯ãƒªã‚¹ã‚¯: {metrics.unsystematic_risk:.4f}")
    print(f"  RÂ²: {metrics.r_squared:.2%}")

    print(f"\nğŸ”¥ ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ:")
    print(f"  æœ€æ‚ªæœˆ: {metrics.worst_month:.2%}")
    print(f"  æœ€æ‚ªå››åŠæœŸ: {metrics.worst_quarter:.2%}")
    print(f"  æœ€æ‚ªå¹´: {metrics.worst_year:.2%}")
    print(f"  é€£ç¶šæå¤±: {metrics.consecutive_losses}æ—¥")
    print(f"  å›å¾©æ™‚é–“: {metrics.recovery_time}æ—¥")

    print(f"\nğŸ” ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†è§£:")
    print(f"  ã‚¢ãƒ«ãƒ•ã‚¡: {metrics.alpha:.2%}")
    print(f"  ãƒ™ãƒ¼ã‚¿ãƒªã‚¿ãƒ¼ãƒ³: {metrics.beta_return:.2%}")
    print(f"  æ®‹å·®ãƒªã‚¿ãƒ¼ãƒ³: {metrics.residual_return:.2%}")
    print(f"  å¸‚å ´ã‚¿ã‚¤ãƒŸãƒ³ã‚°: {metrics.market_timing:.2%}")
    print(f"  éŠ˜æŸ„é¸æŠ: {metrics.stock_selection:.2%}")

    # å¯è¦–åŒ–
    visualizer = PerformanceVisualizer()
    visualizer.plot_comprehensive_analysis(
        returns_series, equity_curve, metrics, "advanced_performance_analysis.png"
    )
    visualizer.plot_risk_analysis(returns_series, metrics, "risk_analysis.png")

    # çµæœä¿å­˜
    metrics_dict = asdict(metrics)
    with open("advanced_metrics.json", "w", encoding="utf-8") as f:
        json.dump(metrics_dict, f, ensure_ascii=False, indent=2, default=str)

    logger.info("=== é«˜åº¦ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™è¨ˆç®—å®Œäº† ===")


if __name__ == "__main__":
    main()
