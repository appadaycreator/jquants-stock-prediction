#!/usr/bin/env python3
"""
ä¸¦åˆ—å‡¦ç†æ€§èƒ½ãƒ†ã‚¹ãƒˆ
æœ€é©åŒ–å¾Œã®æ€§èƒ½ã‚’ãƒ†ã‚¹ãƒˆã—ã€æ¤œè¨¼ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ 
"""

import os
import sys
import time
import logging
import multiprocessing as mp
from typing import Dict, List, Any, Callable
from dataclasses import dataclass
import numpy as np
import pandas as pd
import psutil
import matplotlib.pyplot as plt
import seaborn as sns
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import threading
import gc

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class PerformanceTestResult:
    """æ€§èƒ½ãƒ†ã‚¹ãƒˆçµæœ"""
    test_name: str
    execution_time: float
    cpu_usage: float
    memory_usage: float
    throughput: float
    efficiency: float
    success_rate: float
    worker_count: int
    task_count: int


class ParallelPerformanceTester:
    """ä¸¦åˆ—å‡¦ç†æ€§èƒ½ãƒ†ã‚¹ã‚¿ãƒ¼"""
    
    def __init__(self):
        self.test_results: List[PerformanceTestResult] = []
        self.baseline_results: Dict[str, Any] = {}
        
    def run_comprehensive_tests(self):
        """åŒ…æ‹¬çš„ãªæ€§èƒ½ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        logger.info("ğŸš€ åŒ…æ‹¬çš„ãªä¸¦åˆ—å‡¦ç†æ€§èƒ½ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ
        self._run_baseline_tests()
        
        # çµ±åˆã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ
        self._run_unified_system_tests()
        
        # é«˜åº¦ãªæœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ
        self._run_advanced_optimization_tests()
        
        # æ¯”è¼ƒãƒ†ã‚¹ãƒˆ
        self._run_comparison_tests()
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        self._generate_performance_report()
        
        logger.info("âœ… åŒ…æ‹¬çš„ãªä¸¦åˆ—å‡¦ç†æ€§èƒ½ãƒ†ã‚¹ãƒˆå®Œäº†")
    
    def _run_baseline_tests(self):
        """ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        logger.info("ğŸ“Š ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        # é€æ¬¡å‡¦ç†ãƒ†ã‚¹ãƒˆ
        sequential_result = self._test_sequential_processing()
        self.baseline_results["sequential"] = sequential_result
        
        # åŸºæœ¬çš„ãªä¸¦åˆ—å‡¦ç†ãƒ†ã‚¹ãƒˆ
        basic_parallel_result = self._test_basic_parallel_processing()
        self.baseline_results["basic_parallel"] = basic_parallel_result
        
        logger.info("âœ… ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå®Œäº†")
    
    def _run_unified_system_tests(self):
        """çµ±åˆã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        logger.info("ğŸ”§ çµ±åˆã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            from unified_parallel_processing_system import get_unified_system, parallel_execute_unified
            
            system = get_unified_system()
            
            # CPUé›†ç´„çš„ã‚¿ã‚¹ã‚¯ãƒ†ã‚¹ãƒˆ
            cpu_intensive_result = self._test_cpu_intensive_tasks(system)
            self.test_results.append(cpu_intensive_result)
            
            # I/Oé›†ç´„çš„ã‚¿ã‚¹ã‚¯ãƒ†ã‚¹ãƒˆ
            io_intensive_result = self._test_io_intensive_tasks(system)
            self.test_results.append(io_intensive_result)
            
            # æ··åˆã‚¿ã‚¹ã‚¯ãƒ†ã‚¹ãƒˆ
            mixed_task_result = self._test_mixed_tasks(system)
            self.test_results.append(mixed_task_result)
            
            logger.info("âœ… çµ±åˆã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆå®Œäº†")
            
        except ImportError as e:
            logger.error(f"çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def _run_advanced_optimization_tests(self):
        """é«˜åº¦ãªæœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        logger.info("âš¡ é«˜åº¦ãªæœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            from advanced_parallel_optimizer import get_advanced_optimizer, execute_optimized_parallel
            
            optimizer = get_advanced_optimizer()
            
            # æœ€é©åŒ–ã•ã‚ŒãŸä¸¦åˆ—å‡¦ç†ãƒ†ã‚¹ãƒˆ
            optimized_result = self._test_optimized_parallel_processing(optimizer)
            self.test_results.append(optimized_result)
            
            # å‹•çš„èª¿æ•´ãƒ†ã‚¹ãƒˆ
            dynamic_adjustment_result = self._test_dynamic_adjustment(optimizer)
            self.test_results.append(dynamic_adjustment_result)
            
            # ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ãƒ†ã‚¹ãƒˆ
            memory_optimization_result = self._test_memory_optimization(optimizer)
            self.test_results.append(memory_optimization_result)
            
            logger.info("âœ… é«˜åº¦ãªæœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆå®Œäº†")
            
        except ImportError as e:
            logger.error(f"é«˜åº¦ãªæœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def _run_comparison_tests(self):
        """æ¯”è¼ƒãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        logger.info("ğŸ“ˆ æ¯”è¼ƒãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        # ç•°ãªã‚‹ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã§ã®æ€§èƒ½æ¯”è¼ƒ
        worker_comparison_result = self._test_worker_count_comparison()
        self.test_results.append(worker_comparison_result)
        
        # ç•°ãªã‚‹ã‚¿ã‚¹ã‚¯ã‚µã‚¤ã‚ºã§ã®æ€§èƒ½æ¯”è¼ƒ
        task_size_comparison_result = self._test_task_size_comparison()
        self.test_results.append(task_size_comparison_result)
        
        logger.info("âœ… æ¯”è¼ƒãƒ†ã‚¹ãƒˆå®Œäº†")
    
    def _test_sequential_processing(self) -> PerformanceTestResult:
        """é€æ¬¡å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ”„ é€æ¬¡å‡¦ç†ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
        
        def cpu_task(x):
            # CPUé›†ç´„çš„ã‚¿ã‚¹ã‚¯
            result = 0
            for i in range(100000):
                result += i * x
            return result
        
        start_time = time.time()
        start_cpu = psutil.cpu_percent()
        start_memory = psutil.virtual_memory().percent
        
        # é€æ¬¡å®Ÿè¡Œ
        results = [cpu_task(i) for i in range(10)]
        
        end_time = time.time()
        end_cpu = psutil.cpu_percent()
        end_memory = psutil.virtual_memory().percent
        
        execution_time = end_time - start_time
        cpu_usage = (start_cpu + end_cpu) / 2
        memory_usage = (start_memory + end_memory) / 2
        throughput = len(results) / execution_time
        efficiency = throughput / (cpu_usage / 100) if cpu_usage > 0 else 0
        
        return PerformanceTestResult(
            test_name="Sequential Processing",
            execution_time=execution_time,
            cpu_usage=cpu_usage,
            memory_usage=memory_usage,
            throughput=throughput,
            efficiency=efficiency,
            success_rate=100.0,
            worker_count=1,
            task_count=len(results)
        )
    
    def _test_basic_parallel_processing(self) -> PerformanceTestResult:
        """åŸºæœ¬çš„ãªä¸¦åˆ—å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ”„ åŸºæœ¬çš„ãªä¸¦åˆ—å‡¦ç†ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
        
        def cpu_task(x):
            result = 0
            for i in range(100000):
                result += i * x
            return result
        
        start_time = time.time()
        start_cpu = psutil.cpu_percent()
        start_memory = psutil.virtual_memory().percent
        
        # åŸºæœ¬çš„ãªä¸¦åˆ—å®Ÿè¡Œ
        with ThreadPoolExecutor(max_workers=4) as executor:
            futures = [executor.submit(cpu_task, i) for i in range(10)]
            results = [future.result() for future in futures]
        
        end_time = time.time()
        end_cpu = psutil.cpu_percent()
        end_memory = psutil.virtual_memory().percent
        
        execution_time = end_time - start_time
        cpu_usage = (start_cpu + end_cpu) / 2
        memory_usage = (start_memory + end_memory) / 2
        throughput = len(results) / execution_time
        efficiency = throughput / (cpu_usage / 100) if cpu_usage > 0 else 0
        
        return PerformanceTestResult(
            test_name="Basic Parallel Processing",
            execution_time=execution_time,
            cpu_usage=cpu_usage,
            memory_usage=memory_usage,
            throughput=throughput,
            efficiency=efficiency,
            success_rate=100.0,
            worker_count=4,
            task_count=len(results)
        )
    
    def _test_cpu_intensive_tasks(self, system) -> PerformanceTestResult:
        """CPUé›†ç´„çš„ã‚¿ã‚¹ã‚¯ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ”„ CPUé›†ç´„çš„ã‚¿ã‚¹ã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
        
        def cpu_intensive_task(x):
            result = 0
            for i in range(200000):
                result += i * x * np.sin(i)
            return result
        
        start_time = time.time()
        start_cpu = psutil.cpu_percent()
        start_memory = psutil.virtual_memory().percent
        
        # çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã§ã®ä¸¦åˆ—å®Ÿè¡Œï¼ˆThreadPoolExecutorã‚’ä½¿ç”¨ï¼‰
        tasks = [lambda x=i: cpu_intensive_task(x) for i in range(10)]
        results = system.execute_parallel(tasks, task_type="mixed")  # mixedã«å¤‰æ›´
        
        end_time = time.time()
        end_cpu = psutil.cpu_percent()
        end_memory = psutil.virtual_memory().percent
        
        execution_time = end_time - start_time
        cpu_usage = (start_cpu + end_cpu) / 2
        memory_usage = (start_memory + end_memory) / 2
        throughput = len(results) / execution_time
        efficiency = throughput / (cpu_usage / 100) if cpu_usage > 0 else 0
        success_rate = len([r for r in results if r is not None]) / len(results) * 100
        
        return PerformanceTestResult(
            test_name="CPU Intensive Tasks (Unified System)",
            execution_time=execution_time,
            cpu_usage=cpu_usage,
            memory_usage=memory_usage,
            throughput=throughput,
            efficiency=efficiency,
            success_rate=success_rate,
            worker_count=system.current_workers,
            task_count=len(results)
        )
    
    def _test_io_intensive_tasks(self, system) -> PerformanceTestResult:
        """I/Oé›†ç´„çš„ã‚¿ã‚¹ã‚¯ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ”„ I/Oé›†ç´„çš„ã‚¿ã‚¹ã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
        
        def io_intensive_task(x):
            time.sleep(0.1)  # I/Oå¾…æ©Ÿã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
            return x * 2
        
        start_time = time.time()
        start_cpu = psutil.cpu_percent()
        start_memory = psutil.virtual_memory().percent
        
        # çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã§ã®ä¸¦åˆ—å®Ÿè¡Œ
        tasks = [lambda x=i: io_intensive_task(x) for i in range(10)]
        results = system.execute_parallel(tasks, task_type="io_intensive")
        
        end_time = time.time()
        end_cpu = psutil.cpu_percent()
        end_memory = psutil.virtual_memory().percent
        
        execution_time = end_time - start_time
        cpu_usage = (start_cpu + end_cpu) / 2
        memory_usage = (start_memory + end_memory) / 2
        throughput = len(results) / execution_time
        efficiency = throughput / (cpu_usage / 100) if cpu_usage > 0 else 0
        success_rate = len([r for r in results if r is not None]) / len(results) * 100
        
        return PerformanceTestResult(
            test_name="I/O Intensive Tasks (Unified System)",
            execution_time=execution_time,
            cpu_usage=cpu_usage,
            memory_usage=memory_usage,
            throughput=throughput,
            efficiency=efficiency,
            success_rate=success_rate,
            worker_count=system.current_workers,
            task_count=len(results)
        )
    
    def _test_mixed_tasks(self, system) -> PerformanceTestResult:
        """æ··åˆã‚¿ã‚¹ã‚¯ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ”„ æ··åˆã‚¿ã‚¹ã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
        
        def mixed_task(x):
            # CPUé›†ç´„çš„å‡¦ç†
            result = 0
            for i in range(50000):
                result += i * x
            # I/Oå¾…æ©Ÿ
            time.sleep(0.05)
            return result
        
        start_time = time.time()
        start_cpu = psutil.cpu_percent()
        start_memory = psutil.virtual_memory().percent
        
        # çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã§ã®ä¸¦åˆ—å®Ÿè¡Œ
        tasks = [lambda x=i: mixed_task(x) for i in range(10)]
        results = system.execute_parallel(tasks, task_type="mixed")
        
        end_time = time.time()
        end_cpu = psutil.cpu_percent()
        end_memory = psutil.virtual_memory().percent
        
        execution_time = end_time - start_time
        cpu_usage = (start_cpu + end_cpu) / 2
        memory_usage = (start_memory + end_memory) / 2
        throughput = len(results) / execution_time
        efficiency = throughput / (cpu_usage / 100) if cpu_usage > 0 else 0
        success_rate = len([r for r in results if r is not None]) / len(results) * 100
        
        return PerformanceTestResult(
            test_name="Mixed Tasks (Unified System)",
            execution_time=execution_time,
            cpu_usage=cpu_usage,
            memory_usage=memory_usage,
            throughput=throughput,
            efficiency=efficiency,
            success_rate=success_rate,
            worker_count=system.current_workers,
            task_count=len(results)
        )
    
    def _test_optimized_parallel_processing(self, optimizer) -> PerformanceTestResult:
        """æœ€é©åŒ–ã•ã‚ŒãŸä¸¦åˆ—å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ”„ æœ€é©åŒ–ã•ã‚ŒãŸä¸¦åˆ—å‡¦ç†ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
        
        def optimized_task(x):
            result = 0
            for i in range(100000):
                result += i * x * np.cos(i)
            return result
        
        start_time = time.time()
        start_cpu = psutil.cpu_percent()
        start_memory = psutil.virtual_memory().percent
        
        # æœ€é©åŒ–ã•ã‚ŒãŸä¸¦åˆ—å®Ÿè¡Œï¼ˆThreadPoolExecutorã‚’ä½¿ç”¨ï¼‰
        tasks = [lambda x=i: optimized_task(x) for i in range(10)]
        results = optimizer.execute_optimized_parallel(tasks, task_type="mixed")  # mixedã«å¤‰æ›´
        
        end_time = time.time()
        end_cpu = psutil.cpu_percent()
        end_memory = psutil.virtual_memory().percent
        
        execution_time = end_time - start_time
        cpu_usage = (start_cpu + end_cpu) / 2
        memory_usage = (start_memory + end_memory) / 2
        throughput = len(results) / execution_time
        efficiency = throughput / (cpu_usage / 100) if cpu_usage > 0 else 0
        success_rate = len([r for r in results if r is not None]) / len(results) * 100
        
        return PerformanceTestResult(
            test_name="Optimized Parallel Processing",
            execution_time=execution_time,
            cpu_usage=cpu_usage,
            memory_usage=memory_usage,
            throughput=throughput,
            efficiency=efficiency,
            success_rate=success_rate,
            worker_count=optimizer.current_workers,
            task_count=len(results)
        )
    
    def _test_dynamic_adjustment(self, optimizer) -> PerformanceTestResult:
        """å‹•çš„èª¿æ•´ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ”„ å‹•çš„èª¿æ•´ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
        
        def adjustment_task(x):
            time.sleep(0.1)
            return x * 3
        
        start_time = time.time()
        start_cpu = psutil.cpu_percent()
        start_memory = psutil.virtual_memory().percent
        
        # å‹•çš„èª¿æ•´ã‚’æœ‰åŠ¹ã«ã—ãŸä¸¦åˆ—å®Ÿè¡Œ
        tasks = [lambda x=i: adjustment_task(x) for i in range(15)]
        results = optimizer.execute_optimized_parallel(tasks, task_type="mixed")
        
        end_time = time.time()
        end_cpu = psutil.cpu_percent()
        end_memory = psutil.virtual_memory().percent
        
        execution_time = end_time - start_time
        cpu_usage = (start_cpu + end_cpu) / 2
        memory_usage = (start_memory + end_memory) / 2
        throughput = len(results) / execution_time
        efficiency = throughput / (cpu_usage / 100) if cpu_usage > 0 else 0
        success_rate = len([r for r in results if r is not None]) / len(results) * 100
        
        return PerformanceTestResult(
            test_name="Dynamic Adjustment",
            execution_time=execution_time,
            cpu_usage=cpu_usage,
            memory_usage=memory_usage,
            throughput=throughput,
            efficiency=efficiency,
            success_rate=success_rate,
            worker_count=optimizer.current_workers,
            task_count=len(results)
        )
    
    def _test_memory_optimization(self, optimizer) -> PerformanceTestResult:
        """ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ”„ ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
        
        def memory_intensive_task(x):
            # ãƒ¡ãƒ¢ãƒªé›†ç´„çš„ã‚¿ã‚¹ã‚¯
            data = np.random.random((1000, 1000))
            result = np.sum(data * x)
            return result
        
        start_time = time.time()
        start_cpu = psutil.cpu_percent()
        start_memory = psutil.virtual_memory().percent
        
        # ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã‚’æœ‰åŠ¹ã«ã—ãŸä¸¦åˆ—å®Ÿè¡Œ
        tasks = [lambda x=i: memory_intensive_task(x) for i in range(8)]
        results = optimizer.execute_optimized_parallel(tasks, task_type="mixed")
        
        end_time = time.time()
        end_cpu = psutil.cpu_percent()
        end_memory = psutil.virtual_memory().percent
        
        execution_time = end_time - start_time
        cpu_usage = (start_cpu + end_cpu) / 2
        memory_usage = (start_memory + end_memory) / 2
        throughput = len(results) / execution_time
        efficiency = throughput / (cpu_usage / 100) if cpu_usage > 0 else 0
        success_rate = len([r for r in results if r is not None]) / len(results) * 100
        
        return PerformanceTestResult(
            test_name="Memory Optimization",
            execution_time=execution_time,
            cpu_usage=cpu_usage,
            memory_usage=memory_usage,
            throughput=throughput,
            efficiency=efficiency,
            success_rate=success_rate,
            worker_count=optimizer.current_workers,
            task_count=len(results)
        )
    
    def _test_worker_count_comparison(self) -> PerformanceTestResult:
        """ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°æ¯”è¼ƒãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ”„ ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°æ¯”è¼ƒãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
        
        def comparison_task(x):
            result = 0
            for i in range(50000):
                result += i * x
            return result
        
        worker_counts = [1, 2, 4, 8]
        best_result = None
        best_throughput = 0
        
        for workers in worker_counts:
            start_time = time.time()
            
            with ThreadPoolExecutor(max_workers=workers) as executor:
                futures = [executor.submit(comparison_task, i) for i in range(10)]
                results = [future.result() for future in futures]
            
            execution_time = time.time() - start_time
            throughput = len(results) / execution_time
            
            if throughput > best_throughput:
                best_throughput = throughput
                best_result = PerformanceTestResult(
                    test_name=f"Worker Count Comparison (Best: {workers})",
                    execution_time=execution_time,
                    cpu_usage=psutil.cpu_percent(),
                    memory_usage=psutil.virtual_memory().percent,
                    throughput=throughput,
                    efficiency=throughput / (psutil.cpu_percent() / 100) if psutil.cpu_percent() > 0 else 0,
                    success_rate=100.0,
                    worker_count=workers,
                    task_count=len(results)
                )
        
        return best_result
    
    def _test_task_size_comparison(self) -> PerformanceTestResult:
        """ã‚¿ã‚¹ã‚¯ã‚µã‚¤ã‚ºæ¯”è¼ƒãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ”„ ã‚¿ã‚¹ã‚¯ã‚µã‚¤ã‚ºæ¯”è¼ƒãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
        
        def task_size_task(x, size):
            result = 0
            for i in range(size):
                result += i * x
            return result
        
        task_sizes = [1000, 5000, 10000, 50000]
        best_result = None
        best_efficiency = 0
        
        for size in task_sizes:
            start_time = time.time()
            
            with ThreadPoolExecutor(max_workers=4) as executor:
                futures = [executor.submit(task_size_task, i, size) for i in range(10)]
                results = [future.result() for future in futures]
            
            execution_time = time.time() - start_time
            throughput = len(results) / execution_time
            efficiency = throughput / (psutil.cpu_percent() / 100) if psutil.cpu_percent() > 0 else 0
            
            if efficiency > best_efficiency:
                best_efficiency = efficiency
                best_result = PerformanceTestResult(
                    test_name=f"Task Size Comparison (Best: {size})",
                    execution_time=execution_time,
                    cpu_usage=psutil.cpu_percent(),
                    memory_usage=psutil.virtual_memory().percent,
                    throughput=throughput,
                    efficiency=efficiency,
                    success_rate=100.0,
                    worker_count=4,
                    task_count=len(results)
                )
        
        return best_result
    
    def _generate_performance_report(self):
        """æ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        logger.info("ğŸ“Š æ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–‹å§‹")
        
        # çµæœã‚’DataFrameã«å¤‰æ›ï¼ˆNoneã‚’é™¤å¤–ï¼‰
        valid_results = [result for result in self.test_results if result is not None]
        
        if not valid_results:
            logger.warning("âš ï¸ æœ‰åŠ¹ãªãƒ†ã‚¹ãƒˆçµæœãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        df_results = pd.DataFrame([
            {
                "Test Name": result.test_name,
                "Execution Time (s)": result.execution_time,
                "CPU Usage (%)": result.cpu_usage,
                "Memory Usage (%)": result.memory_usage,
                "Throughput (tasks/s)": result.throughput,
                "Efficiency": result.efficiency,
                "Success Rate (%)": result.success_rate,
                "Worker Count": result.worker_count,
                "Task Count": result.task_count
            }
            for result in valid_results
        ])
        
        # ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        report_path = "PARALLEL_PERFORMANCE_REPORT.md"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# ä¸¦åˆ—å‡¦ç†æ€§èƒ½ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆ\n\n")
            f.write(f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ—¥æ™‚: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("## ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼\n\n")
            f.write("| ãƒ†ã‚¹ãƒˆå | å®Ÿè¡Œæ™‚é–“(s) | CPUä½¿ç”¨ç‡(%) | ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡(%) | ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ(tasks/s) | åŠ¹ç‡æ€§ | æˆåŠŸç‡(%) |\n")
            f.write("|---------|-------------|-------------|----------------|---------------------|--------|----------|\n")
            
            for _, row in df_results.iterrows():
                f.write(f"| {row['Test Name']} | {row['Execution Time (s)']:.2f} | {row['CPU Usage (%)']:.1f} | {row['Memory Usage (%)']:.1f} | {row['Throughput (tasks/s)']:.2f} | {row['Efficiency']:.2f} | {row['Success Rate (%)']:.1f} |\n")
            
            f.write("\n## æ€§èƒ½åˆ†æ\n\n")
            
            # æœ€é©ãªçµæœã‚’ç‰¹å®š
            best_throughput = df_results.loc[df_results['Throughput (tasks/s)'].idxmax()]
            best_efficiency = df_results.loc[df_results['Efficiency'].idxmax()]
            best_success_rate = df_results.loc[df_results['Success Rate (%)'].idxmax()]
            
            f.write(f"### æœ€é«˜ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ\n")
            f.write(f"- ãƒ†ã‚¹ãƒˆå: {best_throughput['Test Name']}\n")
            f.write(f"- ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {best_throughput['Throughput (tasks/s)']:.2f} tasks/s\n")
            f.write(f"- å®Ÿè¡Œæ™‚é–“: {best_throughput['Execution Time (s)']:.2f}s\n\n")
            
            f.write(f"### æœ€é«˜åŠ¹ç‡æ€§\n")
            f.write(f"- ãƒ†ã‚¹ãƒˆå: {best_efficiency['Test Name']}\n")
            f.write(f"- åŠ¹ç‡æ€§: {best_efficiency['Efficiency']:.2f}\n")
            f.write(f"- CPUä½¿ç”¨ç‡: {best_efficiency['CPU Usage (%)']:.1f}%\n\n")
            
            f.write(f"### æœ€é«˜æˆåŠŸç‡\n")
            f.write(f"- ãƒ†ã‚¹ãƒˆå: {best_success_rate['Test Name']}\n")
            f.write(f"- æˆåŠŸç‡: {best_success_rate['Success Rate (%)']:.1f}%\n")
            f.write(f"- ã‚¿ã‚¹ã‚¯æ•°: {best_success_rate['Task Count']}\n\n")
            
            f.write("## æ¨å¥¨äº‹é …\n\n")
            
            # æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ
            recommendations = []
            
            if best_throughput['Test Name'] != 'Sequential Processing':
                recommendations.append("ä¸¦åˆ—å‡¦ç†ã«ã‚ˆã‚Šå¤§å¹…ãªæ€§èƒ½å‘ä¸ŠãŒç¢ºèªã•ã‚Œã¾ã—ãŸ")
            
            if best_efficiency['Efficiency'] > 1.0:
                recommendations.append("åŠ¹ç‡æ€§ãŒè‰¯å¥½ã§ã™ã€‚ç¾åœ¨ã®è¨­å®šã‚’ç¶­æŒã—ã¦ãã ã•ã„")
            else:
                recommendations.append("åŠ¹ç‡æ€§ã®æ”¹å–„ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
            
            if best_success_rate['Success Rate (%)'] < 100.0:
                recommendations.append("ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®æ”¹å–„ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
            
            for i, rec in enumerate(recommendations, 1):
                f.write(f"{i}. {rec}\n")
            
            f.write("\n## ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±\n\n")
            f.write(f"- CPUæ•°: {mp.cpu_count()}\n")
            f.write(f"- ç·ãƒ¡ãƒ¢ãƒª: {psutil.virtual_memory().total / (1024**3):.1f} GB\n")
            f.write(f"- åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒª: {psutil.virtual_memory().available / (1024**3):.1f} GB\n")
            f.write(f"- ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {psutil.virtual_memory().percent:.1f}%\n")
        
        logger.info(f"ğŸ“Š æ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report_path}")
        
        # çµæœã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚‚ä¿å­˜
        csv_path = "parallel_performance_results.csv"
        df_results.to_csv(csv_path, index=False)
        logger.info(f"ğŸ“Š çµæœã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜: {csv_path}")
    
    def create_performance_visualization(self):
        """æ€§èƒ½å¯è¦–åŒ–ã‚’ä½œæˆ"""
        logger.info("ğŸ“ˆ æ€§èƒ½å¯è¦–åŒ–ä½œæˆé–‹å§‹")
        
        try:
            # çµæœã‚’DataFrameã«å¤‰æ›
            df_results = pd.DataFrame([
                {
                    "Test Name": result.test_name,
                    "Execution Time": result.execution_time,
                    "CPU Usage": result.cpu_usage,
                    "Memory Usage": result.memory_usage,
                    "Throughput": result.throughput,
                    "Efficiency": result.efficiency,
                    "Success Rate": result.success_rate,
                    "Worker Count": result.worker_count
                }
                for result in self.test_results
            ])
            
            # å¯è¦–åŒ–ã‚’ä½œæˆ
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            fig.suptitle('ä¸¦åˆ—å‡¦ç†æ€§èƒ½ãƒ†ã‚¹ãƒˆçµæœ', fontsize=16)
            
            # ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆæ¯”è¼ƒ
            axes[0, 0].bar(df_results['Test Name'], df_results['Throughput'])
            axes[0, 0].set_title('ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆæ¯”è¼ƒ')
            axes[0, 0].set_ylabel('ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ (tasks/s)')
            axes[0, 0].tick_params(axis='x', rotation=45)
            
            # åŠ¹ç‡æ€§æ¯”è¼ƒ
            axes[0, 1].bar(df_results['Test Name'], df_results['Efficiency'])
            axes[0, 1].set_title('åŠ¹ç‡æ€§æ¯”è¼ƒ')
            axes[0, 1].set_ylabel('åŠ¹ç‡æ€§')
            axes[0, 1].tick_params(axis='x', rotation=45)
            
            # CPUä½¿ç”¨ç‡æ¯”è¼ƒ
            axes[1, 0].bar(df_results['Test Name'], df_results['CPU Usage'])
            axes[1, 0].set_title('CPUä½¿ç”¨ç‡æ¯”è¼ƒ')
            axes[1, 0].set_ylabel('CPUä½¿ç”¨ç‡ (%)')
            axes[1, 0].tick_params(axis='x', rotation=45)
            
            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡æ¯”è¼ƒ
            axes[1, 1].bar(df_results['Test Name'], df_results['Memory Usage'])
            axes[1, 1].set_title('ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡æ¯”è¼ƒ')
            axes[1, 1].set_ylabel('ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ (%)')
            axes[1, 1].tick_params(axis='x', rotation=45)
            
            plt.tight_layout()
            
            # ç”»åƒã‚’ä¿å­˜
            image_path = "parallel_performance_visualization.png"
            plt.savefig(image_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            logger.info(f"ğŸ“ˆ æ€§èƒ½å¯è¦–åŒ–ä½œæˆå®Œäº†: {image_path}")
            
        except Exception as e:
            logger.error(f"æ€§èƒ½å¯è¦–åŒ–ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    logger.info("ğŸš€ ä¸¦åˆ—å‡¦ç†æ€§èƒ½ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    # ãƒ†ã‚¹ã‚¿ãƒ¼ã‚’ä½œæˆ
    tester = ParallelPerformanceTester()
    
    # åŒ…æ‹¬çš„ãªãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
    tester.run_comprehensive_tests()
    
    # æ€§èƒ½å¯è¦–åŒ–ã‚’ä½œæˆ
    tester.create_performance_visualization()
    
    logger.info("âœ… ä¸¦åˆ—å‡¦ç†æ€§èƒ½ãƒ†ã‚¹ãƒˆå®Œäº†")


if __name__ == "__main__":
    main()
