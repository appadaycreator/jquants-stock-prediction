#!/usr/bin/env python3
"""
ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©ã€å­¦ç¿’ã€è©•ä¾¡ã‚’ç®¡ç†
"""

import numpy as np
from typing import Dict, Any, List
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from datetime import datetime


class ModelManager:
    """æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ç®¡ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self, logger=None, error_handler=None):
        """åˆæœŸåŒ–"""
        self.logger = logger
        self.error_handler = error_handler
        self.model_definitions = self._get_model_definitions()

    def _get_model_definitions(self) -> Dict[str, Any]:
        """ãƒ¢ãƒ‡ãƒ«å®šç¾©ã®å–å¾—"""
        return {
            "random_forest": RandomForestRegressor(
                n_estimators=100,
                random_state=42,
                max_depth=10,
                min_samples_split=5,
                min_samples_leaf=2,
            ),
            "linear_regression": LinearRegression(),
            "ridge": Ridge(alpha=1.0),
            "lasso": Lasso(alpha=0.1),
        }

    def get_model(self, model_name: str) -> Any:
        """æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®å–å¾—"""
        return self.model_definitions.get(
            model_name, self.model_definitions["random_forest"]
        )

    def train_model(self, model_name: str, X_train, y_train) -> Any:
        """ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’"""
        try:
            model = self.get_model(model_name)
            model.fit(X_train, y_train)
            return model
        except Exception as e:
            if self.error_handler:
                self.error_handler.handle_model_error(e, model_name, "å­¦ç¿’")
            raise

    def make_predictions(self, model: Any, X_data) -> np.ndarray:
        """äºˆæ¸¬ã®å®Ÿè¡Œ"""
        try:
            return model.predict(X_data)
        except Exception as e:
            if self.error_handler:
                self.error_handler.handle_model_error(e, "äºˆæ¸¬", "å®Ÿè¡Œ")
            raise

    def evaluate_model(
        self, model: Any, X_train, X_val, X_test, y_train, y_val, y_test
    ) -> Dict[str, Any]:
        """ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡"""
        try:
            # å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®äºˆæ¸¬
            predictions = {
                "train": self.make_predictions(model, X_train),
                "val": self.make_predictions(model, X_val),
                "test": self.make_predictions(model, X_test),
            }

            # è©•ä¾¡æŒ‡æ¨™ã®è¨ˆç®—
            metrics = self._calculate_metrics(y_train, y_val, y_test, predictions)

            return {
                "predictions": predictions,
                "metrics": metrics,
                "model_name": type(model).__name__,
            }

        except Exception as e:
            if self.error_handler:
                self.error_handler.handle_model_error(e, "è©•ä¾¡", "å®Ÿè¡Œ")
            raise

    def _calculate_metrics(
        self, y_train, y_val, y_test, predictions: Dict[str, np.ndarray]
    ) -> Dict[str, float]:
        """è©•ä¾¡æŒ‡æ¨™ã®è¨ˆç®—"""
        return {
            "train_mae": mean_absolute_error(y_train, predictions["train"]),
            "val_mae": mean_absolute_error(y_val, predictions["val"]),
            "test_mae": mean_absolute_error(y_test, predictions["test"]),
            "train_rmse": np.sqrt(mean_squared_error(y_train, predictions["train"])),
            "val_rmse": np.sqrt(mean_squared_error(y_val, predictions["val"])),
            "test_rmse": np.sqrt(mean_squared_error(y_test, predictions["test"])),
            "train_r2": r2_score(y_train, predictions["train"]),
            "val_r2": r2_score(y_val, predictions["val"]),
            "test_r2": r2_score(y_test, predictions["test"]),
        }

    def compare_models(
        self, X_train, X_val, X_test, y_train, y_val, y_test
    ) -> Dict[str, Any]:
        """è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒ"""
        try:
            results = self._train_and_evaluate_models(
                X_train, X_val, X_test, y_train, y_val, y_test
            )

            if results:
                best_result = self._select_best_model(results)
                return self._create_comparison_result(best_result, results)
            else:
                return self._create_fallback_result()

        except Exception as e:
            if self.error_handler:
                self.error_handler.handle_model_error(e, "ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ", "å®Ÿè¡Œ")
            return {"best_model": "random_forest", "results": []}

    def _select_best_model(self, results: List[Dict]) -> Dict:
        """æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«ã®é¸æŠ"""
        # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§ã®MAEãŒæœ€å°ã®ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ
        best_result = min(results, key=lambda x: x["metrics"]["val_mae"])

        if self.logger:
            self.logger.log_info(
                f"ğŸ† æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«: {best_result['model_name']} "
                f"(æ¤œè¨¼MAE: {best_result['metrics']['val_mae']:.4f})"
            )

        return best_result

    def _train_and_evaluate_models(
        self, X_train, X_val, X_test, y_train, y_val, y_test
    ) -> List[Dict]:
        """ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã¨è©•ä¾¡"""
        results = []

        for model_name in self.model_definitions.keys():
            try:
                model = self.train_model(model_name, X_train, y_train)
                evaluation = self.evaluate_model(
                    model, X_train, X_val, X_test, y_train, y_val, y_test
                )
                evaluation["model_name"] = model_name
                results.append(evaluation)
            except Exception as e:
                if self.logger:
                    self.logger.log_warning(f"ãƒ¢ãƒ‡ãƒ« {model_name} ã®å­¦ç¿’ã«å¤±æ•—: {e}")
                continue

        return results

    def _create_comparison_result(
        self, best_result: Dict, results: List[Dict]
    ) -> Dict[str, Any]:
        """æ¯”è¼ƒçµæœã®ä½œæˆ"""
        return {
            "best_model": best_result["model_name"],
            "results": results,
            "comparison_timestamp": datetime.now().isoformat(),
        }

    def _create_fallback_result(self) -> Dict[str, Any]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯çµæœã®ä½œæˆ"""
        if self.logger:
            self.logger.log_warning(
                "æœ‰åŠ¹ãªãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚"
            )
        return {"best_model": "random_forest", "results": []}

    def get_supported_models(self) -> List[str]:
        """ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã®å–å¾—"""
        return list(self.model_definitions.keys())

    def get_model_info(self) -> Dict[str, Any]:
        """ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã®å–å¾—"""
        return {
            "supported_models": self.get_supported_models(),
            "model_count": len(self.model_definitions),
            "timestamp": datetime.now().isoformat(),
        }
