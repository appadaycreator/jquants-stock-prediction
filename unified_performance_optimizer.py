#!/usr/bin/env python3
"""
çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ 
ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã€ä¸¦åˆ—å‡¦ç†ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ã‚’çµ±åˆã—ãŸåŒ…æ‹¬çš„ãªæœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ 
"""

import pandas as pd
import numpy as np
import logging
from typing import Dict, List, Optional, Any, Callable
import time
import psutil
import gc
from dataclasses import dataclass
from unified_system import UnifiedSystem
from advanced_performance_optimizer import UnifiedPerformanceOptimizer
from enhanced_model_comparator import EnhancedModelComparator
from ultra_efficient_dataframe_processor import MemoryEfficientDataFrameProcessor

logger = logging.getLogger(__name__)


@dataclass
class UnifiedOptimizationMetrics:
    """çµ±åˆæœ€é©åŒ–ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""

    total_processing_time: float
    memory_usage_peak: float
    memory_usage_average: float
    cache_hit_rate: float
    parallel_efficiency: float
    copy_operations_saved: int
    inplace_operations: int
    dtype_optimizations: int
    models_processed: int
    data_rows_processed: int


class UnifiedPerformanceOptimizer:
    """çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(
        self,
        memory_limit_mb: int = 2048,
        chunk_size: int = 10000,
        max_workers: int = None,
        use_cache: bool = True,
        use_parallel: bool = True,
    ):
        self.memory_limit_mb = memory_limit_mb
        self.chunk_size = chunk_size
        self.max_workers = max_workers
        self.use_cache = use_cache
        self.use_parallel = use_parallel

        # å„æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–
        self.performance_optimizer = UnifiedPerformanceOptimizer(
            memory_limit_mb, chunk_size
        )
        self.model_comparator = EnhancedModelComparator(
            max_workers, use_cache, use_parallel
        )
        self.dataframe_processor = MemoryEfficientDataFrameProcessor(
            chunk_size, memory_limit_mb
        )

        self.system = UnifiedSystem("UnifiedPerformanceOptimizer")
        self.logger = logging.getLogger(__name__)

        # çµ±åˆãƒ¡ãƒˆãƒªã‚¯ã‚¹
        self.metrics = UnifiedOptimizationMetrics(
            total_processing_time=0.0,
            memory_usage_peak=0.0,
            memory_usage_average=0.0,
            cache_hit_rate=0.0,
            parallel_efficiency=0.0,
            copy_operations_saved=0,
            inplace_operations=0,
            dtype_optimizations=0,
            models_processed=0,
            data_rows_processed=0,
        )

    def optimize_data_pipeline(
        self, df: pd.DataFrame, operations: List[Dict]
    ) -> pd.DataFrame:
        """ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®çµ±åˆæœ€é©åŒ–"""
        self.logger.info(f"ğŸš€ çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æœ€é©åŒ–é–‹å§‹: {len(operations)}æ“ä½œ")

        start_time = time.time()
        start_memory = psutil.Process().memory_info().rss / 1024 / 1024

        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã®æœ€é©åŒ–
            optimized_df = self.dataframe_processor.process_dataframe_ultra_efficient(
                df, operations
            )

            # ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–
            memory_optimized_df = (
                self.performance_optimizer.memory_optimizer.optimize_dataframe_memory(
                    optimized_df
                )
            )

            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
            with self.performance_optimizer.performance_monitor.monitor_performance(
                "data_pipeline"
            ):
                result_df = memory_optimized_df

            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°
            self._update_metrics(start_time, start_memory, len(df), 0)

            self.logger.info("âœ… çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æœ€é©åŒ–å®Œäº†")
            return result_df

        except Exception as e:
            self.system.log_error(e, "çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼")
            return df

    def optimize_model_comparison(
        self,
        models_config: Dict,
        X_train: np.ndarray,
        X_test: np.ndarray,
        y_train: np.ndarray,
        y_test: np.ndarray,
        feature_names: List[str] = None,
    ) -> pd.DataFrame:
        """ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã®çµ±åˆæœ€é©åŒ–"""
        self.logger.info(f"ğŸš€ çµ±åˆãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒæœ€é©åŒ–é–‹å§‹: {len(models_config)}ãƒ¢ãƒ‡ãƒ«")

        start_time = time.time()
        start_memory = psutil.Process().memory_info().rss / 1024 / 1024

        try:
            # å¼·åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã‚’å®Ÿè¡Œ
            results_df = self.model_comparator.compare_models_enhanced(
                models_config, X_train, X_test, y_train, y_test, feature_names
            )

            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°
            self._update_metrics(start_time, start_memory, 0, len(models_config))

            self.logger.info("âœ… çµ±åˆãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒæœ€é©åŒ–å®Œäº†")
            return results_df

        except Exception as e:
            self.system.log_error(e, "çµ±åˆãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒæœ€é©åŒ–ã‚¨ãƒ©ãƒ¼")
            return pd.DataFrame()

    def optimize_technical_indicators(
        self, df: pd.DataFrame, config: Dict = None
    ) -> pd.DataFrame:
        """æŠ€è¡“æŒ‡æ¨™è¨ˆç®—ã®çµ±åˆæœ€é©åŒ–"""
        self.logger.info("ğŸš€ çµ±åˆæŠ€è¡“æŒ‡æ¨™è¨ˆç®—æœ€é©åŒ–é–‹å§‹")

        start_time = time.time()
        start_memory = psutil.Process().memory_info().rss / 1024 / 1024

        try:
            # æœ€é©åŒ–ã•ã‚ŒãŸæŠ€è¡“æŒ‡æ¨™è¨ˆç®—
            optimized_df = self.performance_optimizer.technical_indicators.calculate_indicators_optimized(
                df, config
            )

            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°
            self._update_metrics(start_time, start_memory, len(df), 0)

            self.logger.info("âœ… çµ±åˆæŠ€è¡“æŒ‡æ¨™è¨ˆç®—æœ€é©åŒ–å®Œäº†")
            return optimized_df

        except Exception as e:
            self.system.log_error(e, "çµ±åˆæŠ€è¡“æŒ‡æ¨™è¨ˆç®—æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼")
            return df

    def _update_metrics(
        self, start_time: float, start_memory: float, data_rows: int, models_count: int
    ):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’æ›´æ–°"""
        processing_time = time.time() - start_time
        current_memory = psutil.Process().memory_info().rss / 1024 / 1024

        self.metrics.total_processing_time += processing_time
        self.metrics.memory_usage_peak = max(
            self.metrics.memory_usage_peak, current_memory
        )
        self.metrics.memory_usage_average = (
            self.metrics.memory_usage_average + current_memory
        ) / 2
        self.metrics.data_rows_processed += data_rows
        self.metrics.models_processed += models_count

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆã‚’å–å¾—
        if (
            hasattr(self.model_comparator, "cache_manager")
            and self.model_comparator.cache_manager
        ):
            cache_stats = self.model_comparator.cache_manager.get_cache_stats()
            self.metrics.cache_hit_rate = cache_stats.get("hit_rate", 0)

        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†çµ±è¨ˆã‚’å–å¾—
        if hasattr(self.dataframe_processor, "ultra_processor"):
            df_stats = self.dataframe_processor.ultra_processor.get_optimization_stats()
            self.metrics.copy_operations_saved += df_stats.copy_operations_saved
            self.metrics.inplace_operations += df_stats.inplace_operations
            self.metrics.dtype_optimizations += df_stats.dtype_optimizations

    def get_comprehensive_report(self) -> Dict[str, Any]:
        """åŒ…æ‹¬çš„ãªæœ€é©åŒ–ãƒ¬ãƒãƒ¼ãƒˆã‚’å–å¾—"""
        return {
            "performance_metrics": {
                "total_processing_time": self.metrics.total_processing_time,
                "memory_usage_peak_mb": self.metrics.memory_usage_peak,
                "memory_usage_average_mb": self.metrics.memory_usage_average,
                "cache_hit_rate_percent": self.metrics.cache_hit_rate,
                "parallel_efficiency_percent": self.metrics.parallel_efficiency,
            },
            "optimization_stats": {
                "copy_operations_saved": self.metrics.copy_operations_saved,
                "inplace_operations": self.metrics.inplace_operations,
                "dtype_optimizations": self.metrics.dtype_optimizations,
                "data_rows_processed": self.metrics.data_rows_processed,
                "models_processed": self.metrics.models_processed,
            },
            "system_config": {
                "memory_limit_mb": self.memory_limit_mb,
                "chunk_size": self.chunk_size,
                "max_workers": self.max_workers,
                "use_cache": self.use_cache,
                "use_parallel": self.use_parallel,
            },
        }

    def log_optimization_summary(self):
        """æœ€é©åŒ–ã‚µãƒãƒªãƒ¼ã‚’ãƒ­ã‚°å‡ºåŠ›"""
        report = self.get_comprehensive_report()

        self.logger.info("ğŸ“Š çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚µãƒãƒªãƒ¼:")
        self.logger.info(
            f"  â±ï¸ ç·å‡¦ç†æ™‚é–“: {report['performance_metrics']['total_processing_time']:.2f}ç§’"
        )
        self.logger.info(
            f"  ğŸ’¾ ãƒ”ãƒ¼ã‚¯ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {report['performance_metrics']['memory_usage_peak_mb']:.1f}MB"
        )
        self.logger.info(
            f"  ğŸ“ˆ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡: {report['performance_metrics']['cache_hit_rate_percent']:.1f}%"
        )
        self.logger.info(
            f"  â™»ï¸ ã‚³ãƒ”ãƒ¼æ“ä½œå‰Šæ¸›: {report['optimization_stats']['copy_operations_saved']}å›"
        )
        self.logger.info(
            f"  ğŸ”§ ã‚¤ãƒ³ãƒ—ãƒ¬ãƒ¼ã‚¹æ“ä½œ: {report['optimization_stats']['inplace_operations']}å›"
        )
        self.logger.info(
            f"  ğŸ“Š ãƒ‡ãƒ¼ã‚¿è¡Œå‡¦ç†: {report['optimization_stats']['data_rows_processed']}è¡Œ"
        )
        self.logger.info(
            f"  ğŸ¤– ãƒ¢ãƒ‡ãƒ«å‡¦ç†: {report['optimization_stats']['models_processed']}å€‹"
        )

    def clear_all_caches(self):
        """å…¨ã¦ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"""
        try:
            if hasattr(self.performance_optimizer, "cache_manager"):
                self.performance_optimizer.cache_manager.clear_cache()

            if (
                hasattr(self.model_comparator, "cache_manager")
                and self.model_comparator.cache_manager
            ):
                self.model_comparator.cache_manager.clear_cache()

            self.logger.info("ğŸ§¹ å…¨ã¦ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
        except Exception as e:
            self.logger.error(f"âŒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ã‚¨ãƒ©ãƒ¼: {e}")

    def reset_metrics(self):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        self.metrics = UnifiedOptimizationMetrics(
            total_processing_time=0.0,
            memory_usage_peak=0.0,
            memory_usage_average=0.0,
            cache_hit_rate=0.0,
            parallel_efficiency=0.0,
            copy_operations_saved=0,
            inplace_operations=0,
            dtype_optimizations=0,
            models_processed=0,
            data_rows_processed=0,
        )
        self.logger.info("ğŸ”„ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")


def create_unified_performance_optimizer(
    memory_limit_mb: int = 2048,
    chunk_size: int = 10000,
    max_workers: int = None,
    use_cache: bool = True,
    use_parallel: bool = True,
) -> UnifiedPerformanceOptimizer:
    """çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œæˆ"""
    return UnifiedPerformanceOptimizer(
        memory_limit_mb, chunk_size, max_workers, use_cache, use_parallel
    )


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆç”¨ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
    import pandas as pd
    import numpy as np
    from sklearn.model_selection import train_test_split

    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    np.random.seed(42)
    n_samples = 5000
    n_features = 15

    X = np.random.randn(n_samples, n_features)
    y = np.random.randn(n_samples)

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    # çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ
    optimizer = create_unified_performance_optimizer(use_cache=True, use_parallel=True)

    # ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æœ€é©åŒ–ã®ãƒ†ã‚¹ãƒˆ
    sample_df = pd.DataFrame({f"feature_{i}": np.random.randn(1000) for i in range(10)})

    operations = [
        {"type": "dtype_optimization", "params": {}},
        {
            "type": "inplace",
            "params": {"type": "fillna", "params": {"method": "ffill"}},
        },
    ]

    optimized_df = optimizer.optimize_data_pipeline(sample_df, operations)

    # ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒæœ€é©åŒ–ã®ãƒ†ã‚¹ãƒˆ
    models_config = {
        "random_forest": {
            "type": "random_forest",
            "params": {"n_estimators": 50, "random_state": 42},
        },
        "linear_regression": {"type": "linear_regression", "params": {}},
    }

    model_results = optimizer.optimize_model_comparison(
        models_config, X_train, X_test, y_train, y_test
    )

    # æœ€é©åŒ–ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
    optimizer.log_optimization_summary()

    print("ğŸ“Š çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ãƒ†ã‚¹ãƒˆå®Œäº†")
    print(f"ğŸ“ˆ æœ€é©åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿: {len(optimized_df)}è¡Œ, {len(optimized_df.columns)}åˆ—")
    print(f"ğŸ¤– ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒçµæœ: {len(model_results)}ãƒ¢ãƒ‡ãƒ«")
