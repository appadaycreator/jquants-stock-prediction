#!/usr/bin/env python3
"""
ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ 
ä¸è¦ãªã‚³ãƒ”ãƒ¼ã‚’æ’é™¤ã—ã€ã‚¤ãƒ³ãƒ—ãƒ¬ãƒ¼ã‚¹æ“ä½œã‚’æ´»ç”¨ã—ãŸåŠ¹ç‡çš„ãªãƒ‡ãƒ¼ã‚¿å‡¦ç†
"""

import pandas as pd
import numpy as np
import logging
from typing import Dict, List, Optional, Union, Callable, Any, Tuple
from contextlib import contextmanager
import gc
import psutil
from functools import wraps
import time
from dataclasses import dataclass
from unified_system import UnifiedSystem

logger = logging.getLogger(__name__)


@dataclass
class OptimizationStats:
    """æœ€é©åŒ–çµ±è¨ˆæƒ…å ±"""

    original_memory_mb: float
    optimized_memory_mb: float
    memory_reduction_mb: float
    memory_reduction_pct: float
    copy_operations_saved: int
    processing_time_saved: float


class DataFrameOptimizer:
    """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ æœ€é©åŒ–ã‚¯ãƒ©ã‚¹"""

    def __init__(self, track_operations: bool = True):
        self.track_operations = track_operations
        self.operation_count = 0
        self.copy_operations_saved = 0
        self.memory_saved = 0.0
        self.system = UnifiedSystem("DataFrameOptimizer")
        self.logger = logging.getLogger(__name__)

    def optimize_inplace(
        self, df: pd.DataFrame, operation: str, *args, **kwargs
    ) -> pd.DataFrame:
        """ã‚¤ãƒ³ãƒ—ãƒ¬ãƒ¼ã‚¹æ“ä½œã®æœ€é©åŒ–"""
        if self.track_operations:
            self.operation_count += 1

        try:
            # ã‚¤ãƒ³ãƒ—ãƒ¬ãƒ¼ã‚¹æ“ä½œã‚’å®Ÿè¡Œ
            if operation == "fillna":
                df.fillna(*args, inplace=True, **kwargs)
            elif operation == "dropna":
                df.dropna(*args, inplace=True, **kwargs)
            elif operation == "drop_duplicates":
                df.drop_duplicates(*args, inplace=True, **kwargs)
            elif operation == "sort_values":
                df.sort_values(*args, inplace=True, **kwargs)
            elif operation == "reset_index":
                df.reset_index(*args, inplace=True, **kwargs)
            elif operation == "astype":
                for col, dtype in args[0].items():
                    df[col] = df[col].astype(dtype)
            else:
                self.logger.warning(f"âš ï¸ æœªå¯¾å¿œã®ã‚¤ãƒ³ãƒ—ãƒ¬ãƒ¼ã‚¹æ“ä½œ: {operation}")
                return df

            if self.track_operations:
                self.copy_operations_saved += 1
                self.logger.debug(f"âœ… ã‚¤ãƒ³ãƒ—ãƒ¬ãƒ¼ã‚¹æ“ä½œå®Ÿè¡Œ: {operation}")

            return df

        except Exception as e:
            self.system.log_error(e, f"ã‚¤ãƒ³ãƒ—ãƒ¬ãƒ¼ã‚¹æ“ä½œã‚¨ãƒ©ãƒ¼ ({operation})")
            self.logger.error(f"âŒ ã‚¤ãƒ³ãƒ—ãƒ¬ãƒ¼ã‚¹æ“ä½œã‚¨ãƒ©ãƒ¼: {e}")
            return df

    def smart_copy(self, df: pd.DataFrame, operation_name: str = "") -> pd.DataFrame:
        """å¿…è¦æ™‚ã®ã¿ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆ"""
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ãŒå¤‰æ›´ã•ã‚Œã‚‹å¯èƒ½æ€§ã‚’ãƒã‚§ãƒƒã‚¯
        if self._will_modify_dataframe(df, operation_name):
            self.logger.debug(f"ğŸ“‹ ã‚³ãƒ”ãƒ¼ä½œæˆ: {operation_name}")
            return df.copy()
        else:
            self.logger.debug(f"â™»ï¸ ã‚³ãƒ”ãƒ¼å›é¿: {operation_name}")
            self.copy_operations_saved += 1
            return df

    def _will_modify_dataframe(self, df: pd.DataFrame, operation: str) -> bool:
        """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ãŒå¤‰æ›´ã•ã‚Œã‚‹ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
        # å¤‰æ›´ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒé«˜ã„æ“ä½œ
        modifying_operations = [
            "fillna",
            "dropna",
            "drop_duplicates",
            "sort_values",
            "reset_index",
            "astype",
            "assign",
            "eval",
            "query",
        ]

        # å¤‰æ›´ã•ã‚Œãªã„å¯èƒ½æ€§ãŒé«˜ã„æ“ä½œ
        non_modifying_operations = [
            "head",
            "tail",
            "sample",
            "nlargest",
            "nsmallest",
            "describe",
            "info",
            "shape",
            "dtypes",
            "columns",
        ]

        if any(op in operation.lower() for op in modifying_operations):
            return True
        elif any(op in operation.lower() for op in non_modifying_operations):
            return False
        else:
            # ä¸æ˜ãªå ´åˆã¯å®‰å…¨ã®ãŸã‚ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆ
            return True


class InPlaceProcessor:
    """ã‚¤ãƒ³ãƒ—ãƒ¬ãƒ¼ã‚¹å‡¦ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self, optimizer: DataFrameOptimizer):
        self.optimizer = optimizer
        self.logger = logging.getLogger(__name__)

    def process_dataframe_inplace(
        self, df: pd.DataFrame, operations: List[Dict]
    ) -> pd.DataFrame:
        """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚¤ãƒ³ãƒ—ãƒ¬ãƒ¼ã‚¹ã§å‡¦ç†"""
        self.logger.info(f"ğŸ”§ ã‚¤ãƒ³ãƒ—ãƒ¬ãƒ¼ã‚¹å‡¦ç†é–‹å§‹: {len(operations)}æ“ä½œ")

        for i, operation in enumerate(operations):
            try:
                op_name = operation.get("operation")
                args = operation.get("args", [])
                kwargs = operation.get("kwargs", {})

                self.logger.debug(f"  {i+1}. {op_name}")

                # ã‚¤ãƒ³ãƒ—ãƒ¬ãƒ¼ã‚¹æ“ä½œã‚’å®Ÿè¡Œ
                df = self.optimizer.optimize_inplace(df, op_name, *args, **kwargs)

            except Exception as e:
                self.logger.error(f"âŒ æ“ä½œ {i+1} ã§ã‚¨ãƒ©ãƒ¼: {e}")
                continue

        self.logger.info(f"âœ… ã‚¤ãƒ³ãƒ—ãƒ¬ãƒ¼ã‚¹å‡¦ç†å®Œäº†: {len(operations)}æ“ä½œ")
        return df

    def add_column_inplace(
        self,
        df: pd.DataFrame,
        column_name: str,
        values: Union[pd.Series, np.ndarray, List],
    ) -> pd.DataFrame:
        """ã‚«ãƒ©ãƒ ã‚’ã‚¤ãƒ³ãƒ—ãƒ¬ãƒ¼ã‚¹ã§è¿½åŠ """
        try:
            df[column_name] = values
            self.logger.debug(f"âœ… ã‚«ãƒ©ãƒ è¿½åŠ : {column_name}")
            return df
        except Exception as e:
            self.logger.error(f"âŒ ã‚«ãƒ©ãƒ è¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
            return df

    def modify_column_inplace(
        self, df: pd.DataFrame, column_name: str, operation: str, *args, **kwargs
    ) -> pd.DataFrame:
        """ã‚«ãƒ©ãƒ ã‚’ã‚¤ãƒ³ãƒ—ãƒ¬ãƒ¼ã‚¹ã§å¤‰æ›´"""
        try:
            if operation == "fillna":
                df[column_name].fillna(*args, inplace=True, **kwargs)
            elif operation == "astype":
                df[column_name] = df[column_name].astype(*args, **kwargs)
            elif operation == "clip":
                df[column_name] = df[column_name].clip(*args, **kwargs)
            elif operation == "replace":
                df[column_name].replace(*args, inplace=True, **kwargs)
            else:
                self.logger.warning(f"âš ï¸ æœªå¯¾å¿œã®ã‚«ãƒ©ãƒ æ“ä½œ: {operation}")

            self.logger.debug(f"âœ… ã‚«ãƒ©ãƒ å¤‰æ›´: {column_name} ({operation})")
            return df

        except Exception as e:
            self.logger.error(f"âŒ ã‚«ãƒ©ãƒ å¤‰æ›´ã‚¨ãƒ©ãƒ¼: {e}")
            return df


class MemoryEfficientProcessor:
    """ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.process = psutil.Process()

    def process_with_memory_monitoring(
        self, df: pd.DataFrame, processing_func: Callable, *args, **kwargs
    ) -> pd.DataFrame:
        """ãƒ¡ãƒ¢ãƒªç›£è¦–ä»˜ãå‡¦ç†"""
        initial_memory = self._get_memory_usage()
        self.logger.info(f"ğŸ”§ å‡¦ç†é–‹å§‹ (ãƒ¡ãƒ¢ãƒª: {initial_memory:.1f}MB)")

        try:
            result = processing_func(df, *args, **kwargs)

            final_memory = self._get_memory_usage()
            memory_increase = final_memory - initial_memory

            self.logger.info(f"âœ… å‡¦ç†å®Œäº† (ãƒ¡ãƒ¢ãƒªå¢—åŠ : {memory_increase:.1f}MB)")

            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒå¤§ãã„å ´åˆã¯ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
            if memory_increase > 100:  # 100MBä»¥ä¸Šå¢—åŠ 
                self.logger.info("ğŸ§¹ ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ")
                gc.collect()

            return result

        except Exception as e:
            self.logger.error(f"âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def _get_memory_usage(self) -> float:
        """ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å–å¾—ï¼ˆMBï¼‰"""
        return self.process.memory_info().rss / 1024 / 1024

    def chunk_processing(
        self, df: pd.DataFrame, chunk_size: int, processing_func: Callable
    ) -> pd.DataFrame:
        """ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã«ã‚ˆã‚‹å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿å‡¦ç†"""
        self.logger.info(f"ğŸ“Š ãƒãƒ£ãƒ³ã‚¯å‡¦ç†é–‹å§‹ (ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: {chunk_size})")

        results = []
        total_chunks = len(df) // chunk_size + (1 if len(df) % chunk_size > 0 else 0)

        for i in range(0, len(df), chunk_size):
            chunk = df.iloc[i : i + chunk_size]
            processed_chunk = processing_func(chunk)
            results.append(processed_chunk)

            # ãƒ¡ãƒ¢ãƒªç›£è¦–
            current_memory = self._get_memory_usage()
            if current_memory > 2048:  # 2GBä»¥ä¸Š
                self.logger.warning(
                    "âš ï¸ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒé«˜ã„ãŸã‚ã€ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ"
                )
                gc.collect()

            self.logger.debug(f"  ãƒãƒ£ãƒ³ã‚¯ {i//chunk_size + 1}/{total_chunks} å®Œäº†")

        # çµæœã‚’çµåˆ
        final_result = pd.concat(results, ignore_index=True)
        self.logger.info(f"âœ… ãƒãƒ£ãƒ³ã‚¯å‡¦ç†å®Œäº†: {len(final_result)}è¡Œ")

        return final_result


class OptimizedTechnicalIndicators:
    """æœ€é©åŒ–ã•ã‚ŒãŸæŠ€è¡“æŒ‡æ¨™è¨ˆç®—ï¼ˆã‚³ãƒ”ãƒ¼æœ€å°åŒ–ç‰ˆï¼‰"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.optimizer = DataFrameOptimizer()
        self.inplace_processor = InPlaceProcessor(self.optimizer)

    def calculate_indicators_optimized(
        self, df: pd.DataFrame, config: Dict = None
    ) -> pd.DataFrame:
        """ã‚³ãƒ”ãƒ¼ã‚’æœ€å°åŒ–ã—ãŸæŠ€è¡“æŒ‡æ¨™è¨ˆç®—"""
        self.logger.info("ğŸš€ æœ€é©åŒ–ã•ã‚ŒãŸæŠ€è¡“æŒ‡æ¨™è¨ˆç®—é–‹å§‹")

        # å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç›´æ¥æ“ä½œï¼ˆå¿…è¦æœ€å°é™ã®ã‚³ãƒ”ãƒ¼ï¼‰
        result_df = self.optimizer.smart_copy(df, "technical_indicators")

        try:
            # ç§»å‹•å¹³å‡ç³»ï¼ˆã‚¤ãƒ³ãƒ—ãƒ¬ãƒ¼ã‚¹ï¼‰
            result_df = self._calculate_moving_averages_inplace(result_df, config)

            # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ç³»æŒ‡æ¨™ï¼ˆã‚¤ãƒ³ãƒ—ãƒ¬ãƒ¼ã‚¹ï¼‰
            result_df = self._calculate_momentum_indicators_inplace(result_df, config)

            # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç³»æŒ‡æ¨™ï¼ˆã‚¤ãƒ³ãƒ—ãƒ¬ãƒ¼ã‚¹ï¼‰
            result_df = self._calculate_volatility_indicators_inplace(result_df, config)

            # ãƒœãƒªãƒ¥ãƒ¼ãƒ ç³»æŒ‡æ¨™ï¼ˆã‚¤ãƒ³ãƒ—ãƒ¬ãƒ¼ã‚¹ï¼‰
            result_df = self._calculate_volume_indicators_inplace(result_df, config)

            self.logger.info("âœ… æœ€é©åŒ–ã•ã‚ŒãŸæŠ€è¡“æŒ‡æ¨™è¨ˆç®—å®Œäº†")
            return result_df

        except Exception as e:
            self.logger.error(f"âŒ æŠ€è¡“æŒ‡æ¨™è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return df

    def _calculate_moving_averages_inplace(
        self, df: pd.DataFrame, config: Dict
    ) -> pd.DataFrame:
        """ç§»å‹•å¹³å‡ã‚’ã‚¤ãƒ³ãƒ—ãƒ¬ãƒ¼ã‚¹ã§è¨ˆç®—"""
        windows = (
            config.get("sma_windows", [5, 10, 20, 50]) if config else [5, 10, 20, 50]
        )

        for window in windows:
            if len(df) >= window:
                df[f"SMA_{window}"] = (
                    df["Close"].rolling(window=window, min_periods=1).mean()
                )

        return df

    def _calculate_momentum_indicators_inplace(
        self, df: pd.DataFrame, config: Dict
    ) -> pd.DataFrame:
        """ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ æŒ‡æ¨™ã‚’ã‚¤ãƒ³ãƒ—ãƒ¬ãƒ¼ã‚¹ã§è¨ˆç®—"""
        # RSI
        if len(df) >= 14:
            delta = df["Close"].diff()
            gain = delta.where(delta > 0, 0)
            loss = -delta.where(delta < 0, 0)

            avg_gain = gain.ewm(span=14, min_periods=1).mean()
            avg_loss = loss.ewm(span=14, min_periods=1).mean()

            rs = avg_gain / avg_loss
            df["RSI"] = 100 - (100 / (1 + rs))

        # MACD
        if len(df) >= 26:
            ema_12 = df["Close"].ewm(span=12, min_periods=1).mean()
            ema_26 = df["Close"].ewm(span=26, min_periods=1).mean()

            df["MACD"] = ema_12 - ema_26
            df["MACD_Signal"] = df["MACD"].ewm(span=9, min_periods=1).mean()
            df["MACD_Histogram"] = df["MACD"] - df["MACD_Signal"]

        return df

    def _calculate_volatility_indicators_inplace(
        self, df: pd.DataFrame, config: Dict
    ) -> pd.DataFrame:
        """ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æŒ‡æ¨™ã‚’ã‚¤ãƒ³ãƒ—ãƒ¬ãƒ¼ã‚¹ã§è¨ˆç®—"""
        # ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰
        if len(df) >= 20:
            sma = df["Close"].rolling(window=20, min_periods=1).mean()
            std = df["Close"].rolling(window=20, min_periods=1).std()

            df["BB_Middle"] = sma
            df["BB_Upper"] = sma + (std * 2)
            df["BB_Lower"] = sma - (std * 2)
            df["BB_Width"] = (df["BB_Upper"] - df["BB_Lower"]) / df["BB_Middle"]

        # ATR
        if len(df) >= 14:
            high_low = df["High"] - df["Low"]
            high_close_prev = np.abs(df["High"] - df["Close"].shift(1))
            low_close_prev = np.abs(df["Low"] - df["Close"].shift(1))

            true_range = np.maximum(
                high_low, np.maximum(high_close_prev, low_close_prev)
            )
            df["ATR"] = true_range.rolling(window=14, min_periods=1).mean()
            df["ATR_Percent"] = df["ATR"] / df["Close"] * 100

        return df

    def _calculate_volume_indicators_inplace(
        self, df: pd.DataFrame, config: Dict
    ) -> pd.DataFrame:
        """ãƒœãƒªãƒ¥ãƒ¼ãƒ æŒ‡æ¨™ã‚’ã‚¤ãƒ³ãƒ—ãƒ¬ãƒ¼ã‚¹ã§è¨ˆç®—"""
        # ãƒœãƒªãƒ¥ãƒ¼ãƒ ç§»å‹•å¹³å‡
        df["Volume_SMA"] = df["Volume"].rolling(window=20, min_periods=1).mean()
        df["Volume_Rate"] = df["Volume"] / df["Volume_SMA"]

        # VWAP
        typical_price = (df["High"] + df["Low"] + df["Close"]) / 3
        df["VWAP"] = (typical_price * df["Volume"]).cumsum() / df["Volume"].cumsum()
        df["VWAP_Deviation"] = (df["Close"] - df["VWAP"]) / df["VWAP"] * 100

        return df


class OptimizedDataProcessor:
    """æœ€é©åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ï¼ˆçµ±åˆç‰ˆï¼‰"""

    def __init__(self, chunk_size: int = 10000, memory_limit_mb: int = 2048):
        self.chunk_size = chunk_size
        self.memory_limit_mb = memory_limit_mb
        self.optimizer = DataFrameOptimizer()
        self.inplace_processor = InPlaceProcessor(self.optimizer)
        self.memory_processor = MemoryEfficientProcessor()
        self.technical_indicators = OptimizedTechnicalIndicators()
        self.logger = logging.getLogger(__name__)

    def process_data_optimized(
        self, df: pd.DataFrame, operations: List[Dict]
    ) -> pd.DataFrame:
        """æœ€é©åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿å‡¦ç†"""
        self.logger.info(f"ğŸš€ æœ€é©åŒ–ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–‹å§‹: {len(operations)}æ“ä½œ")

        # ãƒ¡ãƒ¢ãƒªç›£è¦–ä»˜ãå‡¦ç†
        result = self.memory_processor.process_with_memory_monitoring(
            df, self._execute_operations, operations
        )

        # æœ€é©åŒ–çµ±è¨ˆã‚’ãƒ­ã‚°å‡ºåŠ›
        self._log_optimization_stats()

        return result

    def _execute_operations(
        self, df: pd.DataFrame, operations: List[Dict]
    ) -> pd.DataFrame:
        """æ“ä½œã‚’å®Ÿè¡Œ"""
        result_df = df

        for operation in operations:
            op_type = operation.get("type")

            if op_type == "inplace":
                result_df = self.inplace_processor.process_dataframe_inplace(
                    result_df, [operation]
                )
            elif op_type == "technical_indicators":
                result_df = self.technical_indicators.calculate_indicators_optimized(
                    result_df, operation.get("config")
                )
            elif op_type == "chunk_processing":
                result_df = self.memory_processor.chunk_processing(
                    result_df,
                    operation.get("chunk_size", self.chunk_size),
                    operation.get("processing_func"),
                )
            else:
                self.logger.warning(f"âš ï¸ æœªå¯¾å¿œã®æ“ä½œã‚¿ã‚¤ãƒ—: {op_type}")

        return result_df

    def _log_optimization_stats(self):
        """æœ€é©åŒ–çµ±è¨ˆã‚’ãƒ­ã‚°å‡ºåŠ›"""
        stats = OptimizationStats(
            original_memory_mb=0.0,  # å®Ÿéš›ã®å®Ÿè£…ã§ã¯è¿½è·¡
            optimized_memory_mb=0.0,
            memory_reduction_mb=0.0,
            memory_reduction_pct=0.0,
            copy_operations_saved=self.optimizer.copy_operations_saved,
            processing_time_saved=0.0,
        )

        self.logger.info(f"ğŸ“Š æœ€é©åŒ–çµ±è¨ˆ:")
        self.logger.info(f"  â™»ï¸ ã‚³ãƒ”ãƒ¼æ“ä½œå‰Šæ¸›: {stats.copy_operations_saved}å›")
        self.logger.info(f"  ğŸ’¾ ãƒ¡ãƒ¢ãƒªå‰Šæ¸›: {stats.memory_reduction_pct:.1f}%")


def create_optimized_processor(
    chunk_size: int = 10000, memory_limit_mb: int = 2048
) -> OptimizedDataProcessor:
    """æœ€é©åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã‚’ä½œæˆ"""
    return OptimizedDataProcessor(
        chunk_size=chunk_size, memory_limit_mb=memory_limit_mb
    )


def optimize_dataframe_operations(
    df: pd.DataFrame, operations: List[Dict]
) -> pd.DataFrame:
    """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ æ“ä½œã‚’æœ€é©åŒ–"""
    processor = create_optimized_processor()
    return processor.process_data_optimized(df, operations)


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    logging.basicConfig(level=logging.INFO)

    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    dates = pd.date_range("2020-01-01", periods=1000, freq="D")
    np.random.seed(42)

    sample_data = pd.DataFrame(
        {
            "Date": dates,
            "Open": np.random.uniform(100, 200, 1000),
            "High": np.random.uniform(100, 200, 1000),
            "Low": np.random.uniform(100, 200, 1000),
            "Close": np.random.uniform(100, 200, 1000),
            "Volume": np.random.randint(1000000, 10000000, 1000),
        }
    )

    # æœ€é©åŒ–ã•ã‚ŒãŸå‡¦ç†
    processor = create_optimized_processor()

    operations = [
        {"type": "technical_indicators", "config": {"sma_windows": [5, 10, 20]}},
        {
            "type": "inplace",
            "operation": "fillna",
            "args": [],
            "kwargs": {"method": "ffill"},
        },
    ]

    result = processor.process_data_optimized(sample_data, operations)

    print(f"ğŸ“Š å‡¦ç†çµæœ: {result.shape}")
    print(f"â™»ï¸ ã‚³ãƒ”ãƒ¼æ“ä½œå‰Šæ¸›: {processor.optimizer.copy_operations_saved}å›")
