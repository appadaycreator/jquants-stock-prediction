#!/usr/bin/env python3
"""
ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±åˆãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ 
æœ€é©åŒ–å¾Œã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã€DoDã‚’æ¤œè¨¼ã™ã‚‹
"""

import time
import psutil
import pandas as pd
import numpy as np
import logging
import json
import os
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from concurrent.futures import ThreadPoolExecutor, as_completed
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import sys

# æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from enhanced_memory_optimizer import (
    EnhancedMemoryOptimizer,
    create_enhanced_memory_optimizer,
)
from enhanced_parallel_processor import EnhancedParallelProcessor, parallel_context
from enhanced_chart_optimizer import EnhancedChartOptimizer, create_chart_optimizer

logger = logging.getLogger(__name__)


@dataclass
class PerformanceTestResult:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆçµæœ"""

    test_name: str
    execution_time: float
    memory_usage_mb: float
    memory_reduction_percent: float
    processing_speed_improvement: float
    chart_render_time: float
    success: bool
    error_message: Optional[str] = None
    metrics: Dict[str, Any] = None


@dataclass
class DoDValidation:
    """DoDæ¤œè¨¼çµæœ"""

    memory_reduction_achieved: bool
    processing_speed_achieved: bool
    chart_render_time_achieved: bool
    ui_responsiveness_achieved: bool
    overall_success: bool
    details: Dict[str, Any]


class PerformanceIntegrationTester:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±åˆãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, test_data_size: int = 100000):
        self.test_data_size = test_data_size
        self.results = []
        self.baseline_metrics = {}
        self.optimized_metrics = {}

        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
        self.test_data = self._generate_test_data()

        logger.info(f"ğŸ§ª ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±åˆãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
        logger.info(f"   - ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {test_data_size}è¡Œ")

    def _generate_test_data(self) -> pd.DataFrame:
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ"""
        np.random.seed(42)
        dates = pd.date_range("2020-01-01", periods=self.test_data_size, freq="D")

        base_price = (
            1000 + np.cumsum(np.random.randn(self.test_data_size) * 0.02) * 1000
        )

        data = pd.DataFrame(
            {
                "Date": dates,
                "Open": base_price,
                "High": base_price
                * (1 + np.random.uniform(0, 0.05, self.test_data_size)),
                "Low": base_price
                * (1 - np.random.uniform(0, 0.05, self.test_data_size)),
                "Close": base_price + np.random.uniform(-20, 20, self.test_data_size),
                "Volume": np.random.randint(1000000, 10000000, self.test_data_size),
                "SMA_5": base_price.rolling(window=5).mean(),
                "SMA_20": base_price.rolling(window=20).mean(),
                "SMA_50": base_price.rolling(window=50).mean(),
                "RSI": np.random.uniform(0, 100, self.test_data_size),
                "MACD": np.random.uniform(-10, 10, self.test_data_size),
                "BB_Upper": base_price * 1.02,
                "BB_Lower": base_price * 0.98,
                "ATR": np.random.uniform(1, 10, self.test_data_size),
            }
        )

        return data

    def run_baseline_tests(self) -> Dict[str, Any]:
        """ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ"""
        logger.info("ğŸ“Š ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆé–‹å§‹")

        baseline_results = {}

        # 1. ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®š
        baseline_results["memory_baseline"] = self._test_memory_baseline()

        # 2. å‡¦ç†é€Ÿåº¦ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®š
        baseline_results["processing_baseline"] = self._test_processing_baseline()

        # 3. ãƒãƒ£ãƒ¼ãƒˆæç”»ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®š
        baseline_results["chart_baseline"] = self._test_chart_baseline()

        self.baseline_metrics = baseline_results

        logger.info("âœ… ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå®Œäº†")
        return baseline_results

    def run_optimized_tests(self) -> Dict[str, Any]:
        """æœ€é©åŒ–ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ"""
        logger.info("ğŸš€ æœ€é©åŒ–ãƒ†ã‚¹ãƒˆé–‹å§‹")

        optimized_results = {}

        # 1. ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ãƒ†ã‚¹ãƒˆ
        optimized_results["memory_optimized"] = self._test_memory_optimization()

        # 2. ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ
        optimized_results["processing_optimized"] = self._test_processing_optimization()

        # 3. ãƒãƒ£ãƒ¼ãƒˆæœ€é©åŒ–ãƒ†ã‚¹ãƒˆ
        optimized_results["chart_optimized"] = self._test_chart_optimization()

        # 4. çµ±åˆæœ€é©åŒ–ãƒ†ã‚¹ãƒˆ
        optimized_results["integrated"] = self._test_integrated_optimization()

        self.optimized_metrics = optimized_results

        logger.info("âœ… æœ€é©åŒ–ãƒ†ã‚¹ãƒˆå®Œäº†")
        return optimized_results

    def _test_memory_baseline(self) -> Dict[str, Any]:
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®š"""
        start_memory = psutil.Process().memory_info().rss / 1024 / 1024
        start_time = time.time()

        # é€šå¸¸ã®ãƒ‡ãƒ¼ã‚¿å‡¦ç†
        processed_data = self.test_data.copy()
        processed_data = processed_data.dropna()
        processed_data = processed_data.astype(
            {
                "Open": "float64",
                "High": "float64",
                "Low": "float64",
                "Close": "float64",
                "Volume": "int64",
            }
        )

        end_memory = psutil.Process().memory_info().rss / 1024 / 1024
        end_time = time.time()

        return {
            "start_memory_mb": start_memory,
            "end_memory_mb": end_memory,
            "memory_usage_mb": end_memory - start_memory,
            "execution_time": end_time - start_time,
            "data_size": len(processed_data),
        }

    def _test_processing_baseline(self) -> Dict[str, Any]:
        """å‡¦ç†é€Ÿåº¦ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®š"""
        start_time = time.time()

        # é€šå¸¸ã®æŠ€è¡“æŒ‡æ¨™è¨ˆç®—
        def calculate_indicators(df):
            df = df.copy()
            df["SMA_5"] = df["Close"].rolling(window=5).mean()
            df["SMA_20"] = df["Close"].rolling(window=20).mean()
            df["RSI"] = self._calculate_rsi(df["Close"])
            df["MACD"] = self._calculate_macd(df["Close"])
            return df

        processed_data = calculate_indicators(self.test_data)

        end_time = time.time()

        return {
            "execution_time": end_time - start_time,
            "data_size": len(processed_data),
            "throughput": len(processed_data) / (end_time - start_time),
        }

    def _test_chart_baseline(self) -> Dict[str, Any]:
        """ãƒãƒ£ãƒ¼ãƒˆæç”»ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®š"""
        start_time = time.time()

        # é€šå¸¸ã®ãƒãƒ£ãƒ¼ãƒˆæç”»ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
        import matplotlib.pyplot as plt

        fig, ax = plt.subplots(figsize=(12, 8))

        # ãƒ­ãƒ¼ã‚½ã‚¯è¶³ãƒãƒ£ãƒ¼ãƒˆã®æç”»
        ax.plot(self.test_data.index, self.test_data["Close"], label="Close Price")
        ax.plot(self.test_data.index, self.test_data["SMA_20"], label="SMA 20")

        ax.set_title("Baseline Chart")
        ax.set_xlabel("Date")
        ax.set_ylabel("Price")
        ax.legend()

        # ãƒãƒ£ãƒ¼ãƒˆã‚’ãƒ¡ãƒ¢ãƒªã«ä¿å­˜
        import io

        buffer = io.BytesIO()
        plt.savefig(buffer, format="png", dpi=100)
        buffer.seek(0)

        plt.close(fig)

        end_time = time.time()

        return {
            "render_time": end_time - start_time,
            "data_points": len(self.test_data),
            "chart_size_bytes": len(buffer.getvalue()),
        }

    def _test_memory_optimization(self) -> Dict[str, Any]:
        """ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ãƒ†ã‚¹ãƒˆ"""
        start_memory = psutil.Process().memory_info().rss / 1024 / 1024
        start_time = time.time()

        # å¼·åŒ–ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®ä½¿ç”¨
        optimizer = create_enhanced_memory_optimizer(
            memory_limit_mb=512, aggressive_mode=True
        )

        with optimizer.memory_monitoring("memory_optimization_test"):
            optimized_data = optimizer.optimize_dataframe_aggressive(self.test_data)

        end_memory = psutil.Process().memory_info().rss / 1024 / 1024
        end_time = time.time()

        # ãƒ¡ãƒ¢ãƒªå‰Šæ¸›ç‡ã®è¨ˆç®—
        baseline_memory = self.baseline_metrics.get("memory_baseline", {}).get(
            "memory_usage_mb", 0
        )
        current_memory = end_memory - start_memory
        memory_reduction = (
            ((baseline_memory - current_memory) / baseline_memory * 100)
            if baseline_memory > 0
            else 0
        )

        return {
            "start_memory_mb": start_memory,
            "end_memory_mb": end_memory,
            "memory_usage_mb": current_memory,
            "execution_time": end_time - start_time,
            "data_size": len(optimized_data),
            "memory_reduction_percent": memory_reduction,
            "optimization_stats": optimizer.get_optimization_report(),
        }

    def _test_processing_optimization(self) -> Dict[str, Any]:
        """ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()

        # å¼·åŒ–ä¸¦åˆ—å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®ä½¿ç”¨
        with parallel_context(max_workers=8, adaptive_mode=True) as processor:
            # ä¸¦åˆ—å‡¦ç†ã«ã‚ˆã‚‹æŠ€è¡“æŒ‡æ¨™è¨ˆç®—
            def calculate_indicators_parallel(df):
                return processor.parallel_map_optimized(
                    self._calculate_single_indicator,
                    df.iterrows(),
                    task_type="cpu_intensive",
                )

            results = calculate_indicators_parallel(self.test_data)

        end_time = time.time()

        # å‡¦ç†é€Ÿåº¦å‘ä¸Šç‡ã®è¨ˆç®—
        baseline_time = self.baseline_metrics.get("processing_baseline", {}).get(
            "execution_time", 1
        )
        current_time = end_time - start_time
        speed_improvement = (baseline_time / current_time) if current_time > 0 else 1

        return {
            "execution_time": current_time,
            "data_size": len(results),
            "throughput": len(results) / current_time,
            "speed_improvement": speed_improvement,
            "processor_stats": processor.get_performance_report(),
        }

    def _test_chart_optimization(self) -> Dict[str, Any]:
        """ãƒãƒ£ãƒ¼ãƒˆæœ€é©åŒ–ãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()

        # å¼·åŒ–ãƒãƒ£ãƒ¼ãƒˆæœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®ä½¿ç”¨
        chart_optimizer = create_chart_optimizer(
            max_data_points=3000, target_render_time=3.0, quality_level="high"
        )

        result = chart_optimizer.optimize_chart_rendering(
            self.test_data, chart_type="candlestick", title="æœ€é©åŒ–ã•ã‚ŒãŸãƒãƒ£ãƒ¼ãƒˆ"
        )

        end_time = time.time()

        return {
            "render_time": result["render_time"],
            "total_optimization_time": result["total_optimization_time"],
            "data_points": result["data_points"],
            "optimization_applied": result["optimization_applied"],
            "target_achieved": result["render_time"] <= 3.0,
        }

    def _test_integrated_optimization(self) -> Dict[str, Any]:
        """çµ±åˆæœ€é©åŒ–ãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()
        start_memory = psutil.Process().memory_info().rss / 1024 / 1024

        # å…¨ã‚·ã‚¹ãƒ†ãƒ ã®çµ±åˆãƒ†ã‚¹ãƒˆ
        memory_optimizer = create_enhanced_memory_optimizer(aggressive_mode=True)
        chart_optimizer = create_chart_optimizer(target_render_time=3.0)

        with parallel_context(max_workers=8) as processor:
            # 1. ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–
            optimized_data = memory_optimizer.optimize_dataframe_aggressive(
                self.test_data
            )

            # 2. ä¸¦åˆ—å‡¦ç†
            processed_data = processor.parallel_map_optimized(
                self._process_data_chunk,
                [
                    optimized_data.iloc[i : i + 1000]
                    for i in range(0, len(optimized_data), 1000)
                ],
                task_type="mixed",
            )

            # 3. ãƒãƒ£ãƒ¼ãƒˆæœ€é©åŒ–
            chart_result = chart_optimizer.optimize_chart_rendering(
                pd.concat(processed_data, ignore_index=True), chart_type="candlestick"
            )

        end_time = time.time()
        end_memory = psutil.Process().memory_info().rss / 1024 / 1024

        return {
            "total_execution_time": end_time - start_time,
            "memory_usage_mb": end_memory - start_memory,
            "chart_render_time": chart_result["render_time"],
            "data_processed": len(processed_data),
            "success": chart_result["render_time"] <= 3.0,
        }

    def _calculate_single_indicator(self, row_data) -> Dict[str, Any]:
        """å˜ä¸€ã®æŠ€è¡“æŒ‡æ¨™è¨ˆç®—"""
        # ç°¡æ˜“çš„ãªæŠ€è¡“æŒ‡æ¨™è¨ˆç®—
        return {
            "rsi": np.random.uniform(0, 100),
            "macd": np.random.uniform(-10, 10),
            "sma": row_data[1]["Close"] * np.random.uniform(0.95, 1.05),
        }

    def _process_data_chunk(self, chunk: pd.DataFrame) -> pd.DataFrame:
        """ãƒ‡ãƒ¼ã‚¿ãƒãƒ£ãƒ³ã‚¯ã®å‡¦ç†"""
        return chunk.copy()

    def _calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:
        """RSIè¨ˆç®—"""
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / loss
        return 100 - (100 / (1 + rs))

    def _calculate_macd(
        self, prices: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9
    ) -> pd.Series:
        """MACDè¨ˆç®—"""
        ema_fast = prices.ewm(span=fast).mean()
        ema_slow = prices.ewm(span=slow).mean()
        macd = ema_fast - ema_slow
        return macd

    def validate_dod(self) -> DoDValidation:
        """DoDï¼ˆå—ã‘å…¥ã‚ŒåŸºæº–ï¼‰ã®æ¤œè¨¼"""
        logger.info("ğŸ” DoDæ¤œè¨¼é–‹å§‹")

        # 1. ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®30%ä»¥ä¸Šå‰Šæ¸›
        baseline_memory = self.baseline_metrics.get("memory_baseline", {}).get(
            "memory_usage_mb", 0
        )
        optimized_memory = self.optimized_metrics.get("memory_optimized", {}).get(
            "memory_usage_mb", 0
        )
        memory_reduction = (
            ((baseline_memory - optimized_memory) / baseline_memory * 100)
            if baseline_memory > 0
            else 0
        )
        memory_reduction_achieved = memory_reduction >= 30

        # 2. å‡¦ç†é€Ÿåº¦ã®2å€ä»¥ä¸Šå‘ä¸Š
        baseline_processing = self.baseline_metrics.get("processing_baseline", {}).get(
            "execution_time", 1
        )
        optimized_processing = self.optimized_metrics.get(
            "processing_optimized", {}
        ).get("execution_time", 1)
        speed_improvement = (
            baseline_processing / optimized_processing
            if optimized_processing > 0
            else 1
        )
        processing_speed_achieved = speed_improvement >= 2.0

        # 3. ãƒãƒ£ãƒ¼ãƒˆæç”»ã®3ç§’ä»¥å†…å®Œäº†
        chart_render_time = self.optimized_metrics.get("chart_optimized", {}).get(
            "render_time", 0
        )
        chart_render_time_achieved = chart_render_time <= 3.0

        # 4. UIã®å¿œç­”æ€§ï¼ˆå¤§é‡ãƒ‡ãƒ¼ã‚¿ã§ã‚‚UIãŒå›ºã¾ã‚‰ãªã„ï¼‰
        ui_responsiveness_achieved = self._test_ui_responsiveness()

        # ç·åˆåˆ¤å®š
        overall_success = (
            memory_reduction_achieved
            and processing_speed_achieved
            and chart_render_time_achieved
            and ui_responsiveness_achieved
        )

        validation_result = DoDValidation(
            memory_reduction_achieved=memory_reduction_achieved,
            processing_speed_achieved=processing_speed_achieved,
            chart_render_time_achieved=chart_render_time_achieved,
            ui_responsiveness_achieved=ui_responsiveness_achieved,
            overall_success=overall_success,
            details={
                "memory_reduction_percent": memory_reduction,
                "speed_improvement": speed_improvement,
                "chart_render_time": chart_render_time,
                "baseline_memory_mb": baseline_memory,
                "optimized_memory_mb": optimized_memory,
                "baseline_processing_time": baseline_processing,
                "optimized_processing_time": optimized_processing,
            },
        )

        logger.info("âœ… DoDæ¤œè¨¼å®Œäº†")
        logger.info(
            f"   - ãƒ¡ãƒ¢ãƒªå‰Šæ¸›: {memory_reduction:.1f}% ({'âœ…' if memory_reduction_achieved else 'âŒ'})"
        )
        logger.info(
            f"   - å‡¦ç†é€Ÿåº¦å‘ä¸Š: {speed_improvement:.1f}å€ ({'âœ…' if processing_speed_achieved else 'âŒ'})"
        )
        logger.info(
            f"   - ãƒãƒ£ãƒ¼ãƒˆæç”»: {chart_render_time:.2f}ç§’ ({'âœ…' if chart_render_time_achieved else 'âŒ'})"
        )
        logger.info(f"   - UIå¿œç­”æ€§: {'âœ…' if ui_responsiveness_achieved else 'âŒ'}")
        logger.info(f"   - ç·åˆåˆ¤å®š: {'âœ… æˆåŠŸ' if overall_success else 'âŒ å¤±æ•—'}")

        return validation_result

    def _test_ui_responsiveness(self) -> bool:
        """UIå¿œç­”æ€§ãƒ†ã‚¹ãƒˆ"""
        # å¤§é‡ãƒ‡ãƒ¼ã‚¿ã§ã®UIå¿œç­”æ€§ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        try:
            start_time = time.time()

            # å¤§é‡ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†
            large_data = pd.concat([self.test_data] * 10, ignore_index=True)

            # éåŒæœŸå‡¦ç†ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            with ThreadPoolExecutor(max_workers=4) as executor:
                futures = []
                for i in range(0, len(large_data), 1000):
                    chunk = large_data.iloc[i : i + 1000]
                    future = executor.submit(self._process_data_chunk, chunk)
                    futures.append(future)

                # çµæœã®åé›†
                results = []
                for future in as_completed(futures):
                    results.append(future.result())

            end_time = time.time()
            processing_time = end_time - start_time

            # 3ç§’ä»¥å†…ã§å®Œäº†ã™ã‚Œã°å¿œç­”æ€§è‰¯å¥½
            return processing_time <= 3.0

        except Exception as e:
            logger.error(f"UIå¿œç­”æ€§ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def generate_performance_report(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        logger.info("ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–‹å§‹")

        # DoDæ¤œè¨¼çµæœ
        dod_validation = self.validate_dod()

        # ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
        report = {
            "test_summary": {
                "test_data_size": self.test_data_size,
                "baseline_tests": len(self.baseline_metrics),
                "optimized_tests": len(self.optimized_metrics),
                "dod_validation": dod_validation.overall_success,
            },
            "baseline_metrics": self.baseline_metrics,
            "optimized_metrics": self.optimized_metrics,
            "dod_validation": asdict(dod_validation),
            "improvements": self._calculate_improvements(),
            "recommendations": self._generate_recommendations(),
        }

        # ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        self._save_report(report)

        logger.info("âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†")
        return report

    def _calculate_improvements(self) -> Dict[str, Any]:
        """æ”¹å–„åº¦ã®è¨ˆç®—"""
        improvements = {}

        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æ”¹å–„
        baseline_memory = self.baseline_metrics.get("memory_baseline", {}).get(
            "memory_usage_mb", 0
        )
        optimized_memory = self.optimized_metrics.get("memory_optimized", {}).get(
            "memory_usage_mb", 0
        )
        if baseline_memory > 0:
            improvements["memory_reduction_percent"] = (
                (baseline_memory - optimized_memory) / baseline_memory * 100
            )

        # å‡¦ç†é€Ÿåº¦ã®æ”¹å–„
        baseline_processing = self.baseline_metrics.get("processing_baseline", {}).get(
            "execution_time", 1
        )
        optimized_processing = self.optimized_metrics.get(
            "processing_optimized", {}
        ).get("execution_time", 1)
        if optimized_processing > 0:
            improvements["speed_improvement"] = (
                baseline_processing / optimized_processing
            )

        # ãƒãƒ£ãƒ¼ãƒˆæç”»ã®æ”¹å–„
        baseline_chart = self.baseline_metrics.get("chart_baseline", {}).get(
            "render_time", 0
        )
        optimized_chart = self.optimized_metrics.get("chart_optimized", {}).get(
            "render_time", 0
        )
        if baseline_chart > 0:
            improvements["chart_render_improvement"] = baseline_chart / optimized_chart

        return improvements

    def _generate_recommendations(self) -> List[str]:
        """æ¨å¥¨äº‹é …ã®ç”Ÿæˆ"""
        recommendations = []

        # DoDæ¤œè¨¼çµæœã«åŸºã¥ãæ¨å¥¨äº‹é …
        dod_validation = self.validate_dod()

        if not dod_validation.memory_reduction_achieved:
            recommendations.append(
                "ãƒ¡ãƒ¢ãƒªå‰Šæ¸›ãŒ30%æœªæº€ã§ã™ã€‚ã‚ˆã‚Šç©æ¥µçš„ãªãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã‚’æ¨å¥¨ã—ã¾ã™ã€‚"
            )

        if not dod_validation.processing_speed_achieved:
            recommendations.append(
                "å‡¦ç†é€Ÿåº¦å‘ä¸ŠãŒ2å€æœªæº€ã§ã™ã€‚ä¸¦åˆ—å‡¦ç†ã®æœ€é©åŒ–ã‚’æ¨å¥¨ã—ã¾ã™ã€‚"
            )

        if not dod_validation.chart_render_time_achieved:
            recommendations.append(
                "ãƒãƒ£ãƒ¼ãƒˆæç”»ãŒ3ç§’ã‚’è¶…ãˆã¦ã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’æ¨å¥¨ã—ã¾ã™ã€‚"
            )

        if not dod_validation.ui_responsiveness_achieved:
            recommendations.append(
                "UIå¿œç­”æ€§ãŒä¸ååˆ†ã§ã™ã€‚éåŒæœŸå‡¦ç†ã¨ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã‚’æ¨å¥¨ã—ã¾ã™ã€‚"
            )

        return recommendations

    def _save_report(self, report: Dict[str, Any]):
        """ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        report_file = f"performance_report_{timestamp}.json"

        try:
            with open(report_file, "w", encoding="utf-8") as f:
                json.dump(report, f, indent=2, ensure_ascii=False, default=str)

            logger.info(f"ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜: {report_file}")
        except Exception as e:
            logger.error(f"ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    def run_full_test_suite(self) -> Dict[str, Any]:
        """å®Œå…¨ãªãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆã®å®Ÿè¡Œ"""
        logger.info("ğŸš€ å®Œå…¨ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆé–‹å§‹")

        # 1. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ
        baseline_results = self.run_baseline_tests()

        # 2. æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ
        optimized_results = self.run_optimized_tests()

        # 3. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = self.generate_performance_report()

        logger.info("âœ… å®Œå…¨ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå®Œäº†")
        return report


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    # ãƒ­ã‚°è¨­å®š
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    )

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã®è¨­å®š
    test_data_size = 50000  # 5ä¸‡è¡Œã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿

    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±åˆãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
    tester = PerformanceIntegrationTester(test_data_size)

    try:
        # å®Œå…¨ãªãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆã®å®Ÿè¡Œ
        report = tester.run_full_test_suite()

        # çµæœã®è¡¨ç¤º
        print("\n" + "=" * 80)
        print("ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ãƒ†ã‚¹ãƒˆçµæœ")
        print("=" * 80)

        dod_validation = report["dod_validation"]
        print(
            f"ğŸ¯ DoDæ¤œè¨¼çµæœ: {'âœ… æˆåŠŸ' if dod_validation['overall_success'] else 'âŒ å¤±æ•—'}"
        )
        print(
            f"   - ãƒ¡ãƒ¢ãƒªå‰Šæ¸›: {dod_validation['details']['memory_reduction_percent']:.1f}%"
        )
        print(
            f"   - å‡¦ç†é€Ÿåº¦å‘ä¸Š: {dod_validation['details']['speed_improvement']:.1f}å€"
        )
        print(
            f"   - ãƒãƒ£ãƒ¼ãƒˆæç”»: {dod_validation['details']['chart_render_time']:.2f}ç§’"
        )

        improvements = report["improvements"]
        print(f"\nğŸ“ˆ æ”¹å–„åº¦:")
        print(
            f"   - ãƒ¡ãƒ¢ãƒªå‰Šæ¸›: {improvements.get('memory_reduction_percent', 0):.1f}%"
        )
        print(f"   - å‡¦ç†é€Ÿåº¦å‘ä¸Š: {improvements.get('speed_improvement', 1):.1f}å€")
        print(
            f"   - ãƒãƒ£ãƒ¼ãƒˆæç”»æ”¹å–„: {improvements.get('chart_render_improvement', 1):.1f}å€"
        )

        recommendations = report["recommendations"]
        if recommendations:
            print(f"\nğŸ’¡ æ¨å¥¨äº‹é …:")
            for i, rec in enumerate(recommendations, 1):
                print(f"   {i}. {rec}")

        print("\n" + "=" * 80)
        print("âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ãƒ†ã‚¹ãƒˆå®Œäº†")
        print("=" * 80)

    except Exception as e:
        logger.error(f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        return 1

    return 0


if __name__ == "__main__":
    sys.exit(main())
