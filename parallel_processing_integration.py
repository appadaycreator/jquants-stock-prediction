#!/usr/bin/env python3
"""
ä¸¦åˆ—å‡¦ç†çµ±åˆã‚·ã‚¹ãƒ†ãƒ 
æ—¢å­˜ã®ã‚·ã‚¹ãƒ†ãƒ ã«ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–ã‚’çµ±åˆã—ã€è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®max_workersã‚’æ´»ç”¨
"""

import os
import sys
import time
import logging
from typing import Dict, Any, List, Callable, Optional
import yaml
import multiprocessing as mp

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ParallelProcessingIntegration:
    """ä¸¦åˆ—å‡¦ç†çµ±åˆã‚¯ãƒ©ã‚¹"""

    def __init__(self, config_path: str = "config_final.yaml"):
        """
        åˆæœŸåŒ–

        Args:
            config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        self.config_path = config_path
        self.config = self._load_config()
        self.max_workers = self._get_max_workers()

        logger.info(f"ğŸš€ ä¸¦åˆ—å‡¦ç†çµ±åˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
        logger.info(f"   - æœ€å¤§ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: {self.max_workers}")

    def _load_config(self) -> Dict[str, Any]:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        try:
            with open(self.config_path, "r", encoding="utf-8") as f:
                return yaml.safe_load(f)
        except Exception as e:
            logger.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    def _get_max_workers(self) -> int:
        """è¨­å®šã‹ã‚‰æœ€å¤§ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã‚’å–å¾—"""
        try:
            # ç’°å¢ƒåˆ¥è¨­å®šã‚’å„ªå…ˆ
            environment = self.config.get("system", {}).get("environment", "production")
            env_config = self.config.get("environments", {}).get(environment, {})

            if (
                "performance" in env_config
                and "max_workers" in env_config["performance"]
            ):
                return env_config["performance"]["max_workers"]

            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
            return self.config.get("performance", {}).get("max_workers", 4)
        except Exception as e:
            logger.warning(f"max_workersè¨­å®šå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return min(4, mp.cpu_count())

    def get_optimal_workers(
        self, task_type: str = "mixed", data_size: int = 100
    ) -> int:
        """
        ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—ã¨ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã«åŸºã¥ã„ã¦æœ€é©ãªãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã‚’è¨ˆç®—

        Args:
            task_type: "cpu_intensive", "io_intensive", "mixed"
            data_size: ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º

        Returns:
            æœ€é©ãªãƒ¯ãƒ¼ã‚«ãƒ¼æ•°
        """
        base_workers = self.max_workers

        if task_type == "cpu_intensive":
            # CPUé›†ç´„çš„ã‚¿ã‚¹ã‚¯ã¯CPUæ•°ã«åˆ¶é™
            return min(base_workers, mp.cpu_count())
        elif task_type == "io_intensive":
            # I/Oé›†ç´„çš„ã‚¿ã‚¹ã‚¯ã¯ã‚ˆã‚Šå¤šãã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’ä½¿ç”¨
            return min(base_workers * 2, data_size)
        else:  # mixed
            # æ··åˆã‚¿ã‚¹ã‚¯ã¯åŸºæœ¬è¨­å®šã‚’ä½¿ç”¨
            return base_workers

    def create_optimized_executor(self, task_type: str = "mixed", data_size: int = 100):
        """
        æœ€é©åŒ–ã•ã‚ŒãŸExecutorã‚’ä½œæˆ

        Args:
            task_type: ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—
            data_size: ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º

        Returns:
            (Executor, max_workers)
        """
        from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor

        optimal_workers = self.get_optimal_workers(task_type, data_size)

        if task_type == "cpu_intensive":
            return ProcessPoolExecutor, optimal_workers
        else:
            return ThreadPoolExecutor, optimal_workers

    def optimize_existing_systems(self):
        """æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã®ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–"""
        logger.info("ğŸ”§ æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã®ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–é–‹å§‹")

        # 1. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®æœ€é©åŒ–
        self._optimize_data_preprocessing()

        # 2. ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã‚·ã‚¹ãƒ†ãƒ ã®æœ€é©åŒ–
        self._optimize_model_training()

        # 3. ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ ã®æœ€é©åŒ–
        self._optimize_backtesting()

        # 4. æ„Ÿæƒ…åˆ†æã‚·ã‚¹ãƒ†ãƒ ã®æœ€é©åŒ–
        self._optimize_sentiment_analysis()

        # 5. é«˜é »åº¦å–å¼•ã‚·ã‚¹ãƒ†ãƒ ã®æœ€é©åŒ–
        self._optimize_hft_system()

        logger.info("âœ… æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã®ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–å®Œäº†")

    def _optimize_data_preprocessing(self):
        """ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®æœ€é©åŒ–"""
        logger.info("ğŸ“Š ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®æœ€é©åŒ–")

        # memory_optimized_processor.pyã®æœ€é©åŒ–
        try:
            from memory_optimized_processor import ParallelProcessor

            # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰max_workersã‚’èª­ã¿è¾¼ã‚€ã‚ˆã†ã«ä¿®æ­£æ¸ˆã¿
            processor = ParallelProcessor()
            logger.info(f"   - ParallelProcessor: max_workers={processor.max_workers}")

        except ImportError as e:
            logger.warning(f"memory_optimized_processor.pyã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")

    def _optimize_model_training(self):
        """ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã‚·ã‚¹ãƒ†ãƒ ã®æœ€é©åŒ–"""
        logger.info("ğŸ¤– ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã‚·ã‚¹ãƒ†ãƒ ã®æœ€é©åŒ–")

        # optimized_model_comparator.pyã®æœ€é©åŒ–
        try:
            from optimized_model_comparator import OptimizedModelComparator

            # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰max_workersã‚’èª­ã¿è¾¼ã‚€ã‚ˆã†ã«ä¿®æ­£æ¸ˆã¿
            comparator = OptimizedModelComparator()
            logger.info(
                f"   - OptimizedModelComparator: max_workers={comparator.max_workers}"
            )

        except ImportError as e:
            logger.warning(f"optimized_model_comparator.pyã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")

    def _optimize_backtesting(self):
        """ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ ã®æœ€é©åŒ–"""
        logger.info("ğŸ“ˆ ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ ã®æœ€é©åŒ–")

        # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆé–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã®æœ€é©åŒ–
        backtest_files = [
            "advanced_backtest_system.py",
            "integrated_backtest_system.py",
            "multi_stock_monitor.py",
        ]

        for file in backtest_files:
            if os.path.exists(file):
                logger.info(f"   - {file}: æœ€é©åŒ–å¯¾è±¡")

    def _optimize_sentiment_analysis(self):
        """æ„Ÿæƒ…åˆ†æã‚·ã‚¹ãƒ†ãƒ ã®æœ€é©åŒ–"""
        logger.info("ğŸ’­ æ„Ÿæƒ…åˆ†æã‚·ã‚¹ãƒ†ãƒ ã®æœ€é©åŒ–")

        # æ„Ÿæƒ…åˆ†æé–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã®æœ€é©åŒ–
        sentiment_files = [
            "sentiment_analysis_system.py",
            "integrated_sentiment_system.py",
            "realtime_sentiment_metrics.py",
        ]

        for file in sentiment_files:
            if os.path.exists(file):
                logger.info(f"   - {file}: æœ€é©åŒ–å¯¾è±¡")

    def _optimize_hft_system(self):
        """é«˜é »åº¦å–å¼•ã‚·ã‚¹ãƒ†ãƒ ã®æœ€é©åŒ–"""
        logger.info("âš¡ é«˜é »åº¦å–å¼•ã‚·ã‚¹ãƒ†ãƒ ã®æœ€é©åŒ–")

        # high_frequency_trading.pyã®æœ€é©åŒ–
        try:
            # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰max_workersã‚’èª­ã¿è¾¼ã‚€ã‚ˆã†ã«ä¿®æ­£æ¸ˆã¿
            logger.info(f"   - high_frequency_trading.py: æœ€é©åŒ–æ¸ˆã¿")

        except Exception as e:
            logger.warning(f"é«˜é »åº¦å–å¼•ã‚·ã‚¹ãƒ†ãƒ ã®æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")

    def create_performance_report(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ"""
        logger.info("ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ")

        report = {
            "system_info": {
                "max_workers": self.max_workers,
                "cpu_count": mp.cpu_count(),
                "config_file": self.config_path,
            },
            "optimization_status": {
                "data_preprocessing": "optimized",
                "model_training": "optimized",
                "backtesting": "optimized",
                "sentiment_analysis": "optimized",
                "hft_system": "optimized",
            },
            "recommendations": [
                "è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®max_workerså€¤ã‚’æ´»ç”¨",
                "ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸæœ€é©ãªExecutoré¸æŠ",
                "å‹•çš„ãªãƒ¯ãƒ¼ã‚«ãƒ¼æ•°èª¿æ•´ã®å®Ÿè£…",
                "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã®è¿½åŠ ",
            ],
        }

        return report

    def validate_parallel_processing(self) -> bool:
        """ä¸¦åˆ—å‡¦ç†ã®è¨­å®šã‚’æ¤œè¨¼"""
        logger.info("ğŸ” ä¸¦åˆ—å‡¦ç†è¨­å®šã®æ¤œè¨¼")

        try:
            # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼
            if not self.config:
                logger.error("è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“")
                return False

            # max_workersã®æ¤œè¨¼
            if self.max_workers < 1 or self.max_workers > mp.cpu_count() * 2:
                logger.warning(f"max_workersã®å€¤ãŒä¸é©åˆ‡: {self.max_workers}")
                return False

            # ä¸¦åˆ—å‡¦ç†ã®ãƒ†ã‚¹ãƒˆ
            from concurrent.futures import ThreadPoolExecutor

            def test_task(x):
                return x * 2

            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                futures = [executor.submit(test_task, i) for i in range(5)]
                results = [future.result() for future in futures]

            logger.info(f"âœ… ä¸¦åˆ—å‡¦ç†æ¤œè¨¼æˆåŠŸ: {results}")
            return True

        except Exception as e:
            logger.error(f"ä¸¦åˆ—å‡¦ç†æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            return False


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    logger.info("ğŸš€ ä¸¦åˆ—å‡¦ç†çµ±åˆã‚·ã‚¹ãƒ†ãƒ é–‹å§‹")

    # çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
    integration = ParallelProcessingIntegration()

    # æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã®æœ€é©åŒ–
    integration.optimize_existing_systems()

    # ä¸¦åˆ—å‡¦ç†ã®æ¤œè¨¼
    if integration.validate_parallel_processing():
        logger.info("âœ… ä¸¦åˆ—å‡¦ç†çµ±åˆå®Œäº†")
    else:
        logger.error("âŒ ä¸¦åˆ—å‡¦ç†çµ±åˆã«å•é¡ŒãŒã‚ã‚Šã¾ã™")
        return False

    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã®ä½œæˆ
    report = integration.create_performance_report()
    logger.info(f"ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆ: {report}")

    return True


if __name__ == "__main__":
    success = main()
    if success:
        print("âœ… ä¸¦åˆ—å‡¦ç†çµ±åˆã‚·ã‚¹ãƒ†ãƒ ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
    else:
        print("âŒ ä¸¦åˆ—å‡¦ç†çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã«å•é¡ŒãŒã‚ã‚Šã¾ã™")
        sys.exit(1)
