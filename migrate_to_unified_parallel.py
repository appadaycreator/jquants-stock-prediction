#!/usr/bin/env python3
"""
çµ±åˆä¸¦åˆ—å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã¸ã®ç§»è¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
æ—¢å­˜ã®åˆ†æ•£ã—ãŸä¸¦åˆ—å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã«ç§»è¡Œ
"""

import os
import sys
import logging
import shutil
from typing import Dict, List, Any
from pathlib import Path

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ParallelProcessingMigration:
    """ä¸¦åˆ—å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ç§»è¡Œã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.migration_log = []
        self.backup_dir = "backup/parallel_migration"
        self.unified_system_path = "unified_parallel_processing_system.py"
        
    def migrate_all_systems(self):
        """å…¨ã‚·ã‚¹ãƒ†ãƒ ã®ç§»è¡Œã‚’å®Ÿè¡Œ"""
        logger.info("ğŸš€ çµ±åˆä¸¦åˆ—å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã¸ã®ç§»è¡Œé–‹å§‹")
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self._create_backup_directory()
        
        # å„ã‚·ã‚¹ãƒ†ãƒ ã®ç§»è¡Œ
        migration_tasks = [
            ("memory_optimized_processor.py", self._migrate_memory_processor),
            ("optimized_model_comparator.py", self._migrate_model_comparator),
            ("high_frequency_trading.py", self._migrate_hft_system),
            ("parallel_processing_optimizer.py", self._migrate_optimizer),
            ("enhanced_parallel_system.py", self._migrate_enhanced_system),
            ("parallel_processing_integration.py", self._migrate_integration),
        ]
        
        for file_path, migration_func in migration_tasks:
            if os.path.exists(file_path):
                try:
                    migration_func(file_path)
                    self.migration_log.append(f"âœ… {file_path}: ç§»è¡Œå®Œäº†")
                except Exception as e:
                    self.migration_log.append(f"âŒ {file_path}: ç§»è¡Œã‚¨ãƒ©ãƒ¼ - {e}")
                    logger.error(f"ç§»è¡Œã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
            else:
                self.migration_log.append(f"âš ï¸ {file_path}: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # ç§»è¡Œãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
        self._create_migration_report()
        
        logger.info("âœ… çµ±åˆä¸¦åˆ—å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã¸ã®ç§»è¡Œå®Œäº†")
        return True
    
    def _create_backup_directory(self):
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
        os.makedirs(self.backup_dir, exist_ok=True)
        logger.info(f"ğŸ“ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ: {self.backup_dir}")
    
    def _migrate_memory_processor(self, file_path: str):
        """ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã®ç§»è¡Œ"""
        logger.info(f"ğŸ”„ {file_path} ã®ç§»è¡Œé–‹å§‹")
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
        backup_path = os.path.join(self.backup_dir, os.path.basename(file_path))
        shutil.copy2(file_path, backup_path)
        
        # çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã¸ã®ç§»è¡Œ
        self._update_imports(file_path, "unified_parallel_processing_system")
        self._replace_parallel_processing_calls(file_path)
        
        logger.info(f"âœ… {file_path} ã®ç§»è¡Œå®Œäº†")
    
    def _migrate_model_comparator(self, file_path: str):
        """ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒå™¨ã®ç§»è¡Œ"""
        logger.info(f"ğŸ”„ {file_path} ã®ç§»è¡Œé–‹å§‹")
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
        backup_path = os.path.join(self.backup_dir, os.path.basename(file_path))
        shutil.copy2(file_path, backup_path)
        
        # çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã¸ã®ç§»è¡Œ
        self._update_imports(file_path, "unified_parallel_processing_system")
        self._replace_parallel_processing_calls(file_path)
        
        logger.info(f"âœ… {file_path} ã®ç§»è¡Œå®Œäº†")
    
    def _migrate_hft_system(self, file_path: str):
        """é«˜é »åº¦å–å¼•ã‚·ã‚¹ãƒ†ãƒ ã®ç§»è¡Œ"""
        logger.info(f"ğŸ”„ {file_path} ã®ç§»è¡Œé–‹å§‹")
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
        backup_path = os.path.join(self.backup_dir, os.path.basename(file_path))
        shutil.copy2(file_path, backup_path)
        
        # çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã¸ã®ç§»è¡Œ
        self._update_imports(file_path, "unified_parallel_processing_system")
        self._replace_parallel_processing_calls(file_path)
        
        logger.info(f"âœ… {file_path} ã®ç§»è¡Œå®Œäº†")
    
    def _migrate_optimizer(self, file_path: str):
        """ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®ç§»è¡Œ"""
        logger.info(f"ğŸ”„ {file_path} ã®ç§»è¡Œé–‹å§‹")
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
        backup_path = os.path.join(self.backup_dir, os.path.basename(file_path))
        shutil.copy2(file_path, backup_path)
        
        # çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã¸ã®ç§»è¡Œ
        self._update_imports(file_path, "unified_parallel_processing_system")
        self._replace_parallel_processing_calls(file_path)
        
        logger.info(f"âœ… {file_path} ã®ç§»è¡Œå®Œäº†")
    
    def _migrate_enhanced_system(self, file_path: str):
        """æ‹¡å¼µä¸¦åˆ—å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®ç§»è¡Œ"""
        logger.info(f"ğŸ”„ {file_path} ã®ç§»è¡Œé–‹å§‹")
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
        backup_path = os.path.join(self.backup_dir, os.path.basename(file_path))
        shutil.copy2(file_path, backup_path)
        
        # çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã¸ã®ç§»è¡Œ
        self._update_imports(file_path, "unified_parallel_processing_system")
        self._replace_parallel_processing_calls(file_path)
        
        logger.info(f"âœ… {file_path} ã®ç§»è¡Œå®Œäº†")
    
    def _migrate_integration(self, file_path: str):
        """ä¸¦åˆ—å‡¦ç†çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®ç§»è¡Œ"""
        logger.info(f"ğŸ”„ {file_path} ã®ç§»è¡Œé–‹å§‹")
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
        backup_path = os.path.join(self.backup_dir, os.path.basename(file_path))
        shutil.copy2(file_path, backup_path)
        
        # çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã¸ã®ç§»è¡Œ
        self._update_imports(file_path, "unified_parallel_processing_system")
        self._replace_parallel_processing_calls(file_path)
        
        logger.info(f"âœ… {file_path} ã®ç§»è¡Œå®Œäº†")
    
    def _update_imports(self, file_path: str, new_module: str):
        """ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã‚’æ›´æ–°"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ—¢å­˜ã®ä¸¦åˆ—å‡¦ç†ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã«ç½®æ›
            old_imports = [
                "from parallel_processing_optimizer import",
                "from enhanced_parallel_system import",
                "from parallel_processing_integration import",
                "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor",
            ]
            
            new_import = f"from {new_module} import"
            
            for old_import in old_imports:
                if old_import in content:
                    content = content.replace(old_import, new_import)
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
                
        except Exception as e:
            logger.error(f"ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ›´æ–°ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
    
    def _replace_parallel_processing_calls(self, file_path: str):
        """ä¸¦åˆ—å‡¦ç†å‘¼ã³å‡ºã—ã‚’çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã«ç½®æ›"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ—¢å­˜ã®ä¸¦åˆ—å‡¦ç†å‘¼ã³å‡ºã—ã‚’çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã«ç½®æ›
            replacements = {
                "ParallelProcessingOptimizer()": "get_unified_system()",
                "EnhancedParallelSystem()": "get_unified_system()",
                "ParallelProcessingIntegration()": "get_unified_system()",
                "parallel_execute_optimized": "parallel_execute_unified",
                "parallel_map_optimized": "parallel_map_unified",
                "ThreadPoolExecutor(max_workers=": "get_unified_system().execute_parallel(",
                "ProcessPoolExecutor(max_workers=": "get_unified_system().execute_parallel(",
            }
            
            for old, new in replacements.items():
                if old in content:
                    content = content.replace(old, new)
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
                
        except Exception as e:
            logger.error(f"ä¸¦åˆ—å‡¦ç†å‘¼ã³å‡ºã—ç½®æ›ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
    
    def _create_migration_report(self):
        """ç§»è¡Œãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ"""
        report_path = "PARALLEL_PROCESSING_MIGRATION_REPORT.md"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# ä¸¦åˆ—å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ç§»è¡Œãƒ¬ãƒãƒ¼ãƒˆ\n\n")
            f.write(f"ç§»è¡Œæ—¥æ™‚: {self._get_current_timestamp()}\n\n")
            
            f.write("## ç§»è¡Œå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«\n\n")
            f.write("| ãƒ•ã‚¡ã‚¤ãƒ«å | ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ |\n")
            f.write("|-----------|----------|\n")
            
            for log_entry in self.migration_log:
                if "ç§»è¡Œå®Œäº†" in log_entry:
                    f.write(f"| {log_entry.split(':')[0]} | âœ… å®Œäº† |\n")
                elif "ç§»è¡Œã‚¨ãƒ©ãƒ¼" in log_entry:
                    f.write(f"| {log_entry.split(':')[0]} | âŒ ã‚¨ãƒ©ãƒ¼ |\n")
                elif "ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“" in log_entry:
                    f.write(f"| {log_entry.split(':')[0]} | âš ï¸ æœªç™ºè¦‹ |\n")
            
            f.write("\n## ç§»è¡Œå†…å®¹\n\n")
            f.write("1. **çµ±åˆä¸¦åˆ—å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®å°å…¥**\n")
            f.write("   - `unified_parallel_processing_system.py` ã‚’æ–°è¦ä½œæˆ\n")
            f.write("   - åˆ†æ•£ã—ãŸä¸¦åˆ—å‡¦ç†è¨­å®šã‚’ä¸€å…ƒç®¡ç†\n")
            f.write("   - å‹•çš„ãªãƒ¯ãƒ¼ã‚«ãƒ¼æ•°èª¿æ•´æ©Ÿèƒ½ã‚’çµ±åˆ\n\n")
            
            f.write("2. **æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã®ç§»è¡Œ**\n")
            f.write("   - å„ã‚·ã‚¹ãƒ†ãƒ ã®ä¸¦åˆ—å‡¦ç†æ©Ÿèƒ½ã‚’çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã«ç§»è¡Œ\n")
            f.write("   - è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€å…ƒåŒ–\n")
            f.write("   - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã®çµ±åˆ\n\n")
            
            f.write("3. **æœ€é©åŒ–åŠ¹æœ**\n")
            f.write("   - CPUä½¿ç”¨ç‡ã®æœ€é©åŒ–\n")
            f.write("   - å‡¦ç†é€Ÿåº¦ã®å‘ä¸Š\n")
            f.write("   - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å‰Šæ¸›\n")
            f.write("   - è¨­å®šã®ä¸€å…ƒç®¡ç†\n\n")
            
            f.write("## ä½¿ç”¨æ–¹æ³•\n\n")
            f.write("```python\n")
            f.write("from unified_parallel_processing_system import get_unified_system, parallel_execute_unified\n\n")
            f.write("# çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®å–å¾—\n")
            f.write("system = get_unified_system()\n\n")
            f.write("# ä¸¦åˆ—å®Ÿè¡Œ\n")
            f.write("results = parallel_execute_unified(tasks, task_type='cpu_intensive')\n")
            f.write("```\n\n")
            
            f.write("## æ³¨æ„äº‹é …\n\n")
            f.write("- æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ã¯è‡ªå‹•çš„ã«ç§»è¡Œã•ã‚Œã¾ã™ãŒã€æ‰‹å‹•ã§ã®ç¢ºèªã‚’æ¨å¥¨ã—ã¾ã™\n")
            f.write("- ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã¯ `backup/parallel_migration/` ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™\n")
            f.write("- ç§»è¡Œå¾Œã¯çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„\n\n")
        
        logger.info(f"ğŸ“Š ç§»è¡Œãƒ¬ãƒãƒ¼ãƒˆä½œæˆ: {report_path}")
    
    def _get_current_timestamp(self) -> str:
        """ç¾åœ¨ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å–å¾—"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    def validate_migration(self) -> bool:
        """ç§»è¡Œã®æ¤œè¨¼"""
        logger.info("ğŸ” ç§»è¡Œã®æ¤œè¨¼é–‹å§‹")
        
        # çµ±åˆã‚·ã‚¹ãƒ†ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
        if not os.path.exists(self.unified_system_path):
            logger.error(f"âŒ çµ±åˆã‚·ã‚¹ãƒ†ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.unified_system_path}")
            return False
        
        # çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ
        try:
            from unified_parallel_processing_system import get_unified_system
            system = get_unified_system()
            logger.info("âœ… çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return False
        
        # åŸºæœ¬æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ
        try:
            def test_task(x):
                return x * 2
            
            results = system.execute_parallel([lambda: test_task(5)], "mixed")
            if results and results[0] == 10:
                logger.info("âœ… åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆæˆåŠŸ")
            else:
                logger.error("âŒ åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆå¤±æ•—")
                return False
        except Exception as e:
            logger.error(f"âŒ åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return False
        
        logger.info("âœ… ç§»è¡Œã®æ¤œè¨¼å®Œäº†")
        return True


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    logger.info("ğŸš€ ä¸¦åˆ—å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ç§»è¡Œé–‹å§‹")
    
    # ç§»è¡Œå®Ÿè¡Œ
    migration = ParallelProcessingMigration()
    success = migration.migrate_all_systems()
    
    if success:
        # ç§»è¡Œã®æ¤œè¨¼
        if migration.validate_migration():
            logger.info("âœ… ä¸¦åˆ—å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ç§»è¡ŒãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
            return True
        else:
            logger.error("âŒ ç§»è¡Œã®æ¤œè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return False
    else:
        logger.error("âŒ ä¸¦åˆ—å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ç§»è¡Œã«å¤±æ•—ã—ã¾ã—ãŸ")
        return False


if __name__ == "__main__":
    success = main()
    if success:
        print("âœ… ä¸¦åˆ—å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ç§»è¡ŒãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
    else:
        print("âŒ ä¸¦åˆ—å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ç§»è¡Œã«å•é¡ŒãŒã‚ã‚Šã¾ã™")
        sys.exit(1)
